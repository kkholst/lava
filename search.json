[{"path":"/articles/correlation.html","id":"simulation","dir":"Articles","previous_headings":"","what":"Simulation","title":"Estimating partial correlations with lava","text":"example, simulate data model single covariate. First load necessary libraries: model can specified (using pipe notation) following syntax correlation parameter given label ‘r’: simulate model can now simply use sim method. parameters models set argument p must named numeric vector parameters model. parameter names can inspected coef method default simulation parameters zero intercepts (y1, y2) one regression coefficients (y1~x, y2~x) residual variance parameters (y1~~y1, y2~~y2). Gaussian coarsening random assumptions can also consistently estimate correlation presence censoring missing data. illustrate , add left right censored data types model output using transform method.","code":"library('lava') m0 <- lvm() |>   covariance(y1 ~ y2, value='r') |>   regression(y1 + y2 ~ x) coef(m0, labels=TRUE) #>       m1       m2       p1       p2       p3       p4       p5  #>     \"y1\"     \"y2\"   \"y1~x\"   \"y2~x\" \"y1~~y1\" \"y2~~y2\"      \"r\" d <- sim(m0, 500, p=c(r=0.9), seed=1) head(d) #>           y1         y2           x #> 1  0.6452154  0.8677628  1.13496509 #> 2  1.1098723  0.9579211  1.11193185 #> 3 -2.2072258 -2.3171509 -0.87077763 #> 4  1.5684365  1.0675354  0.21073159 #> 5  0.8752209  1.0845932  0.06939565 #> 6 -1.5113072 -0.7477956 -1.66264885 cens1 <- function(threshold,type='right') {   function(x) {     x <- unlist(x)     if (type=='left')       return( survival::Surv(pmax(x,threshold), x>=threshold, type='left') )       return ( survival::Surv(pmin(x,threshold), x<=threshold) )   } }  m0 <-    transform(m0, s1 ~ y1, cens1(-2, 'left')) |>   transform(s2 ~ y2, cens1(2,  'right')) d <- sim(m0, 500, p=c(r=0.9), seed=1) head(d) #>           y1         y2           x          s1         s2 #> 1  0.6452154  0.8677628  1.13496509   0.6452154  0.8677628 #> 2  1.1098723  0.9579211  1.11193185   1.1098723  0.9579211 #> 3 -2.2072258 -2.3171509 -0.87077763 -2.0000000- -2.3171509 #> 4  1.5684365  1.0675354  0.21073159   1.5684365  1.0675354 #> 5  0.8752209  1.0845932  0.06939565   0.8752209  1.0845932 #> 6 -1.5113072 -0.7477956 -1.66264885  -1.5113072 -0.7477956"},{"path":"/articles/correlation.html","id":"estimation-and-inference","dir":"Articles","previous_headings":"","what":"Estimation and inference","title":"Estimating partial correlations with lava","text":"Maximum Likelihood Estimate can obtainted using estimate method: estimate y1~~y2 gives us estimated covariance residual terms model. estimate correlation can apply delta method using estimate method Alternatively, correlations can extracted using correlation method Note, case confidence intervals constructed using variance stabilizing transformation, Fishers zz-transform (Lehmann Romano 2023), $$z = \\arctanh(\\widehat{\\rho}) =   \\frac{1}{2}\\log\\left(\\frac{1+\\widehat{\\rho}}{1-\\widehat{\\rho}}\\right)$$ ρ̂\\widehat{\\rho} MLE. estimate approximate asymptotic normal distribution $\\mathcal{N}(\\arctanh(\\rho),\\frac{1}{n-3})$. Hence asymptotic 95% confidence interval given ẑ±1.96n−3\\widehat{z} \\pm \\frac{1.96}{\\sqrt{n-3}} confidence interval ρ̂\\widehat{\\rho} can directly calculated inverse transformation: ρ̂=tanh(z)=e2z−1e2z+1.\\widehat{\\rho} = \\tanh(z) = \\frac{e^{2z}-1}{e^{2z}+1}. equivalent direct calculations using delta method (except small sample bias correction 33) estimate confidence interval transformed back original scale using back.transform argument. transformed confidence interval generally improved coverage especially near boundary ρ≈±1\\rho \\approx \\pm 1. estimates particular model can obtained closed form, generally case example considering parameter constraints, latent variables, missing censored observations. MLE therefore obtained using iterative optimization procedures (typically Fisher scoring Newton-Raphson methods). ensure estimated variance parameters leads meaningful positive definite structure avoid potential problems convergence can often good idea parametrize model way parameter constraints naturally fulfilled. can achieved constrain method. code, first add new parameters l1 l2 hold log-variance parameters, z z-transform correlation parameter. Next label variances covariances: variance y1 called v1; variance y2 called v2; covariance y1 y2 called c. Finally, parameters tied previously defined parameters using constrain method v1 := exp(𝚕𝟷)\\exp(\\mathtt{l1})v2 := exp(𝚕𝟷)\\exp(\\mathtt{l1}) z := tanh(𝚣)𝚟𝟷𝚟𝟸\\tanh(\\mathtt{z})\\sqrt{\\mathtt{v1}\\mathtt{v2}}. way constraints actual estimated parameters l1, l2, z can take values ℝ3\\mathbb{R}^{3}, time guaranteed proper covariance matrix positive definite. correlation coefficient can obtained practice, much shorter syntax can used obtain parametrization. can simply use argument constrain specifying covariances (argument rname specifies parameter name $\\arctanh$ transformed correlation coefficient, lname, lname2 can used specify parameter names log variance parameters): alternative Wald confidence intervals (without transformation) profile likelihood. profile likelihood confidence intervals can obtained confint method: Finally, non-parametric bootstrap (practice larger number replications needed) can calculated following way","code":"m <- lvm() |>      regression(y1 + y2 ~ x) |>      covariance(y1 ~ y2)  e <- estimate(m, data=d) e #>                     Estimate Std. Error  Z-value  P-value #> Regressions:                                              #>    y1~x              0.93300    0.04443 20.99871   <1e-12 #>     y2~x             0.91652    0.04527 20.24500   <1e-12 #> Intercepts:                                               #>    y1               -0.00541    0.04482 -0.12076   0.9039 #>    y2               -0.02715    0.04566 -0.59457   0.5521 #> Residual Variances:                                       #>    y1                1.00419    0.06351 15.81139          #>    y1~~y2            0.91221    0.06130 14.88041   <1e-12 #>    y2                1.04252    0.06593 15.81139 estimate(e, function(p) p['y1~~y2']/(p['y1~~y1']*p['y2~~y2'])^.5) #>        Estimate  Std.Err   2.5%  97.5% P-value #> y1~~y2   0.8915 0.008703 0.8745 0.9086       0 correlation(e) #>       Estimate Std.Err   2.5%  97.5%   P-value #> y1~y2   0.8915         0.8721 0.9082 3.58e-224 estimate(e, function(p) atanh(p['y1~~y2']/(p['y1~~y1']*p['y2~~y2'])^.5), back.transform=tanh) #>        Estimate Std.Err   2.5%  97.5%    P-value #> y1~~y2   0.8915         0.8732 0.9074 7.445e-249 m2 <- m |>     parameter(~ l1 + l2 + z) |>     variance(~ y1 + y2, value=c('v1','v2')) |>     covariance(y1 ~ y2, value='c') |>     constrain(v1 ~ l1, fun=exp) |>     constrain(v2 ~ l2, fun=exp) |>     constrain(c ~ z+l1+l2, fun=function(x) tanh(x[1])*sqrt(exp(x[2])*exp(x[3]))) e2 <- estimate(m2, d) e2 #>                        Estimate Std. Error  Z-value  P-value #> Regressions:                                                 #>    y1~x                 0.93300    0.04443 20.99871   <1e-12 #>     y2~x                0.91652    0.04527 20.24500   <1e-12 #> Intercepts:                                                  #>    y1                  -0.00541    0.04482 -0.12076   0.9039 #>    y2                  -0.02715    0.04566 -0.59457   0.5521 #> Additional Parameters:                                       #>    l1                   0.00418    0.06325  0.06617   0.9472 #>    l2                   0.04164    0.06325  0.65832   0.5103 #>    z                    1.42942    0.04472 31.96286   <1e-12 estimate(e2, 'z', back.transform=tanh) #>     Estimate Std.Err   2.5%  97.5%    P-value #> [z]   0.8915         0.8729 0.9076 5.606e-243 #>  #>  Null Hypothesis:  #>   [z] = 0 m2 <- lvm() |>   regression(y1 + y2 ~ x) |>   covariance(y1 ~ y2, constrain=TRUE, rname='z')  e2 <- estimate(m2, data=d) e2 #>                        Estimate Std. Error  Z-value  P-value #> Regressions:                                                 #>    y1~x                 0.93300    0.04443 20.99871   <1e-12 #>     y2~x                0.91652    0.04527 20.24500   <1e-12 #> Intercepts:                                                  #>    y1                  -0.00541    0.04482 -0.12076   0.9039 #>    y2                  -0.02715    0.04566 -0.59457   0.5521 #> Additional Parameters:                                       #>    l1                   0.00418    0.06325  0.06617   0.9472 #>    l2                   0.04164    0.06325  0.65832   0.5103 #>    z                    1.42942    0.04472 31.96286   <1e-12 estimate(e2, 'z', back.transform=tanh) #>     Estimate Std.Err   2.5%  97.5%    P-value #> [z]   0.8915         0.8729 0.9076 5.606e-243 #>  #>  Null Hypothesis:  #>   [z] = 0 tanh(confint(e2, 'z', profile=TRUE)) #>       2.5 %    97.5 % #> z 0.8720834 0.9081964 set.seed(1) b <- bootstrap(e2, data=d, R=50, mc.cores=1) b #> Non-parametric bootstrap statistics (R=50): #>  #>      Estimate      Bias          Std.Err       2.5 %         97.5 %        #> y1   -0.0054119135 -0.0009992035  0.0467447038 -0.0932389998  0.0770206657 #> y2   -0.0271494916  0.0002650151  0.0467360144 -0.1211337493  0.0483704809 #> y1~x  0.9330043509 -0.0149098946  0.0515360969  0.8309736543  0.9998117487 #> y2~x  0.9165185250 -0.0054613366  0.0515815249  0.8206914258  1.0057939308 #> l1    0.0041846522 -0.0207541703  0.0680010956 -0.1521461170  0.0970349017 #> l2    0.0416361064 -0.0172477586  0.0645290353 -0.1102270167  0.1486146877 #> z     1.4294227075 -0.0086990026  0.0431164145  1.3409919820  1.4973573361 #> v1    1.0041934200 -0.0184096665  0.0664333005  0.8588861834  1.1019310023 #> v2    1.0425150452 -0.0157357318  0.0662409478  0.8956329451  1.1602357905 #> c1    0.9122097189 -0.0171972066  0.0627102019  0.7706302260  1.0085879892 quantile(tanh(b$coef[,'z']), c(.025,.975)) #>      2.5%     97.5%  #> 0.8719025 0.9046521"},{"path":"/articles/correlation.html","id":"censored-observations","dir":"Articles","previous_headings":"Estimation and inference","what":"Censored observations","title":"Estimating partial correlations with lava","text":"Letting one variables right-censored (Tobit-type model) can proceed exactly way (note, functionality available mets package installed - available CRAN). difference variables censored must defined Surv objects (survival package automatically loaded using mets package) data frame. analysis s1 left-censored s2 right-censored:","code":"m3 <- lvm() |>   regression(y1 + s2 ~ x) |>   covariance(y1 ~ s2, constrain=TRUE, rname='z')  e3 <- estimate(m3, d) e3 #>                        Estimate Std. Error  Z-value  P-value #> Regressions:                                                 #>    y1~x                 0.93301    0.04443 20.99891   <1e-12 #>     s2~x                0.92402    0.04643 19.90128   <1e-12 #> Intercepts:                                                  #>    y1                  -0.00542    0.04482 -0.12083   0.9038 #>    s2                  -0.02119    0.04638 -0.45687   0.6478 #> Additional Parameters:                                       #>    l1                   0.00418    0.06325  0.06607   0.9473 #>    l2                   0.06317    0.06492  0.97307   0.3305 #>    z                    1.42835    0.04546 31.41861   <1e-12 estimate(e3, 'z', back.transform=tanh) #>     Estimate Std.Err  2.5%  97.5%    P-value #> [z]   0.8913         0.872 0.9079 1.491e-226 #>  #>  Null Hypothesis:  #>   [z] = 0 m3b <- lvm() |>   regression(s1 + s2 ~ x) |>   covariance(s1 ~ s2, constrain=TRUE, rname='z')  e3b <- estimate(m3b, d) e3b #>                        Estimate Std. Error  Z-value  P-value #> Regressions:                                                 #>    s1~x                 0.92834    0.04479 20.72734   <1e-12 #>     s2~x                0.92466    0.04648 19.89515   <1e-12 #> Intercepts:                                                  #>    s1                  -0.00233    0.04492 -0.05185   0.9586 #>    s2                  -0.02083    0.04641 -0.44874   0.6536 #> Additional Parameters:                                       #>    l1                  -0.00075    0.06500 -0.01156   0.9908 #>    l2                   0.06425    0.06498  0.98869   0.3228 #>    z                    1.42627    0.04609 30.94282   <1e-12 e3b #>                        Estimate Std. Error  Z-value  P-value #> Regressions:                                                 #>    s1~x                 0.92834    0.04479 20.72734   <1e-12 #>     s2~x                0.92466    0.04648 19.89515   <1e-12 #> Intercepts:                                                  #>    s1                  -0.00233    0.04492 -0.05185   0.9586 #>    s2                  -0.02083    0.04641 -0.44874   0.6536 #> Additional Parameters:                                       #>    l1                  -0.00075    0.06500 -0.01156   0.9908 #>    l2                   0.06425    0.06498  0.98869   0.3228 #>    z                    1.42627    0.04609 30.94282   <1e-12 estimate(e3b, 'z', back.transform=tanh) #>     Estimate Std.Err   2.5%  97.5%    P-value #> [z]   0.8909         0.8713 0.9077 9.006e-222 #>  #>  Null Hypothesis:  #>   [z] = 0 tanh(confint(e3b, 'z', profile=TRUE)) #>       2.5 %    97.5 % #> z 0.8706426 0.9080912"},{"path":"/articles/correlation.html","id":"sessioninfo","dir":"Articles","previous_headings":"","what":"SessionInfo","title":"Estimating partial correlations with lava","text":"","code":"sessionInfo() #> R version 4.5.1 (2025-06-13) #> Platform: x86_64-pc-linux-gnu #> Running under: Ubuntu 24.04.3 LTS #>  #> Matrix products: default #> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  #> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 #>  #> locale: #>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        #>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    #>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           #> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    #>  #> time zone: UTC #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] lava_1.8.2 #>  #> loaded via a namespace (and not attached): #>  [1] Matrix_1.7-3        future.apply_1.20.0 jsonlite_2.0.0      #>  [4] compiler_4.5.1      Rcpp_1.1.0          parallel_4.5.1      #>  [7] Rgraphviz_2.52.0    jquerylib_0.1.4     globals_0.18.0      #> [10] splines_4.5.1       systemfonts_1.3.1   textshaping_1.0.4   #> [13] yaml_2.3.10         fastmap_1.2.0       lattice_0.22-7      #> [16] R6_2.6.1            generics_0.1.4      knitr_1.50          #> [19] BiocGenerics_0.54.1 htmlwidgets_1.6.4   graph_1.86.0        #> [22] future_1.67.0       desc_1.4.3          bslib_0.9.0         #> [25] rlang_1.1.6         cachem_1.1.0        xfun_0.53           #> [28] fs_1.6.6            sass_0.4.10         cli_3.6.5           #> [31] progressr_0.17.0    pkgdown_2.1.3       digest_0.6.37       #> [34] grid_4.5.1          mvtnorm_1.3-3       lifecycle_1.0.4     #> [37] timereg_2.0.7       evaluate_1.0.5      numDeriv_2016.8-1.1 #> [40] listenv_0.9.1       codetools_0.2-20    ragg_1.5.0          #> [43] survival_3.8-3      stats4_4.5.1        parallelly_1.45.1   #> [46] rmarkdown_2.30      mets_1.3.8          tools_4.5.1         #> [49] htmltools_0.5.8.1"},{"path":[]},{"path":"/articles/influencefunction.html","id":"influence-functions","dir":"Articles","previous_headings":"","what":"Influence functions","title":"The Art of Influence","text":"Estimators parametric convergence rates can often fully characterized influence function (), also referred influence curve canonical gradient (Bickel et al. 1998; Vaart 1998). allows direct estimation properties estimator, including asymptotic variance. Moreover, estimates enable simple combination transformation estimators new ones. vignette describes estimate manipulate IFs using R-package lava (Holst Budtz-Jørgensen 2013). Formally, let Z1,…,ZnZ_1,\\ldots,Z_n iid kk-dimensional stochastic variables, Zi=(Yi,Ai,Wi)∼P0Z_i=(Y_{},A_{},W_{})\\sim P_{0}, θ̂\\widehat{\\theta} consistent estimator parameter θ∈ℝp\\theta\\\\mathbb{R}^p. θ̂\\widehat{\\theta} regular asymptotic linear (RAL) estimator, unique iid decomposition n(θ̂−θ)=1n∑=1nIC(Zi;P0)+oP(1),\\begin{align*} \\sqrt{n}(\\widehat{\\theta}-\\theta) = \\frac{1}{\\sqrt{n}}\\sum_{=1}^n \\operatorname{IC}(Z_i; P_{0}) + o_{P}(1),  \\end{align*} function IC\\operatorname{IC} unique Influence Function s.t. 𝔼{IC(Zi;P0)}=0\\mathbb{E}\\{\\operatorname{IC}(Z_{}; P_{0})\\}=0 𝕍ar{IC(Zi;P0)2}<∞\\mathbb{V}\\!\\text{ar}\\{\\operatorname{IC}(Z_{}; P_{0})^{2}\\}<\\infty(Tsiatis 2006; Vaart 1998). influence function thus fully characterizes asymptotic behaviour estimator central limit theorem follows estimator converges weakly Gaussian distribution n(θ̂−θ)→𝒟𝒩(0,𝕍ar{IC(Z;P0)}), \\sqrt{n}(\\widehat{\\theta}-\\theta) \\overset{\\mathcal{D}}{\\longrightarrow} \\mathcal{N}(0, \\mathbb{V}\\!\\text{ar}\\{\\operatorname{IC}(Z; P_{0})\\}),  empirical variance plugin estimator, ℙnIC(Z;P̂)⊗2=1n∑=1nIC(Zi;P̂)IC(Zi;P̂)⊤\\mathbb{P}_{n}\\operatorname{IC}(Z; \\widehat{P})^{\\otimes 2} = \\frac{1}{n}\\sum_{=1}^n \\operatorname{IC}(Z_{}; \\widehat{P})\\operatorname{IC}(Z_{}; \\widehat{P})^{\\top} can used obtain consistent estimate asymptotic variance. Note, practice estimate P̂\\widehat{P} used plugin-estimate, needs capture parts distribution ZZ necessary evaluate . cases nuisance parameter can estimated using flexible machine learning components (parametric) cases derived directly θ̂\\widehat{\\theta}. IFs easily derived parameters many parametric statistical models illustrated next example sections. generally, can also derived smooth target parameter Ψ:𝒫→ℝ\\Psi: \\mathcal{P}\\\\mathbb{R} 𝒫\\mathcal{P} family probability distributions forming statistical model, often can left completely non-parametric. Formally, parameter must pathwise differentiable see (Vaart 1998) sense exists linear bounded function Ψ̇:L2(P0)→ℝ\\dot\\Psi\\colon L_{2}(P_{0})\\\\mathbb{R} $ [(P_{t}) - (P_{0}))]t^{-1} (P_{0})(g) $ t→0t\\0 parametric submodel PtP_t score model g(z)=∂/(∂t)log(pt)(z)|t=0g(z)= \\partial/(\\partial t) \\log (p_t)(z)|_{t=0}. Riesz’s representation theorem tells us directional derivative unique representer, ϕP0\\phi_{P_{0}} lying closure submodel score space (tangent space), s.t. Ψ̇(P0)(g)=⟨ϕP0,g⟩=∫ϕP0(Z)g(X)dP0\\begin{align*}     \\dot\\Psi(P_0)(g) = \\langle\\phi_{P_0}, g\\rangle =     \\int \\phi_{P_0}(Z)g(X)\\,dP_0 \\end{align*} unique representer exactly can found solving integral equation. details derive influence functions, refer (Laan Rose 2011; Hines et al. 2022). example might interested target parameter Ψ(P)=𝔼P(Z)\\Psi(P) = \\mathbb{E}_P(Z) can shown unique (thereby efficient) influence function Z↦Z−𝔼P(Z)Z\\mapsto Z-\\mathbb{E}_P(Z) non-parametric model. Another target parameter Ψa(P)=𝔼P[𝔼P(Y∣=,W)]\\Psi_{}(P) = \\mathbb{E}_{P}[\\mathbb{E}_{P}(Y\\mid =, W)] often key interest causal inference IC(Y,,W;P)=𝟏(=)ℙ(=∣W)(Y−𝔼P[Y∣=,W])+𝔼P[Y∣=,W]−Ψa(P)\\begin{align*} \\operatorname{IC}(Y,,W; P) = \\frac{\\mathbf{1}(=)}{\\mathbb{P}(=\\mid W)}(Y-\\mathbb{E}_{P}[Y\\mid =,W]) + \\mathbb{E}_{P}[Y\\mid =,W] - \\Psi_{}(P)     \\end{align*} See section average treatment effects.","code":""},{"path":"/articles/influencefunction.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"The Art of Influence","text":"illustrate methods consider data arising model Yij∼Bernoulli{expit(Xij+Ai+Wi)},Ai∼Bernoulli{expit(Wi)}Y_{ij} \\sim Bernoulli\\{\\operatorname{expit}(X_{ij} + A_{} + W_{})\\}, A_{} \\sim Bernoulli\\{\\operatorname{expit}(W_{})\\} independent covariates Xij∼𝒩(0,1),Wi∼𝒩(0,1)X_{ij}\\sim\\mathcal{N}(0,1), W_{}\\sim\\mathcal{N}(0,1). simulate model Y3Y_3 observed half subjects","code":"m <- lvm() |>   regression(y1 ~ x1 + a + w) |>   regression(y2 ~ x2 + a + w) |>   regression(y3 ~ x3 + a + w) |>   regression(y4 ~ x4 + a + w) |>   regression(a ~ w) |>   distribution(~ y1 + y2 + y3 + y4 + a, value = binomial.lvm()) |>   distribution(~id, value = Sequence.lvm(integer = TRUE)) n <- 4e2 dw <- sim(m, n, seed = 1) |>   transform(y3 = y3 * ifelse(id > n / 2, NA, 1)) Print(dw) #>     y1 x1       a w        y2 x2       y3 x3       y4 x4        id  #> 1   1  -0.6265  1  1.0744  0  -1.08691 1  -1.5570  1   0.34419  1   #> 2   1   0.1836  1  1.8957  1  -1.82608 1   1.9232  1   0.01272  2   #> 3   0  -0.8356  0 -0.6030  0   0.99528 0  -1.8568  0  -0.87345  3   #> 4   0   1.5953  0 -0.3909  1  -0.01186 0  -2.1061  1   0.34280  4   #> 5   0   0.3295  1 -0.4162  0  -0.59963 1   0.6976  1  -0.17739  5   #> ---                                                                 #> 396 0  -0.92431 0 -1.02939 0  -0.30825 NA -1.05037 0  -0.008056 396 #> 397 1   1.59291 1 -0.01093 1   0.01552 NA  1.63787 1   1.033784 397 #> 398 0   0.04501 0 -1.22499 0  -0.44232 NA -1.20733 0  -0.799127 398 #> 399 0  -0.71513 0 -2.59611 0  -1.63801 NA -2.62616 0   1.004233 399 #> 400 1   0.86522 1  1.16912 0  -0.64140 NA  0.01746 1  -0.311973 400 ## Data in long format dl <- reshape(dw,         varying = list(paste0(\"y\",1:4),                        paste0(\"x\",1:4)),         v.names=c(\"y\", \"x\"), direction=\"long\") |>   na.omit() dl <- dl[order(dl$id), ] ## dl <- mets::fast.reshape(dw, varying = c(\"y\", \"x\")) |> na.omit() Print(dl) #>       a w      id  time y x       #> 1.1   1 1.074  1   1    1 -0.6265 #> 1.2   1 1.074  1   2    0 -1.0869 #> 1.3   1 1.074  1   3    1 -1.5570 #> 1.4   1 1.074  1   4    1  0.3442 #> 2.1   1 1.896  2   1    1  0.1836 #> ---                               #> 399.2 0 -2.596 399 2    0 -1.6380 #> 399.4 0 -2.596 399 4    0  1.0042 #> 400.1 1  1.169 400 1    1  0.8652 #> 400.2 1  1.169 400 2    0 -0.6414 #> 400.4 1  1.169 400 4    1 -0.3120"},{"path":"/articles/influencefunction.html","id":"example-population-mean","dir":"Articles","previous_headings":"Examples","what":"Example: population mean","title":"The Art of Influence","text":"main functions working influence functions estimate prepares model object estimates corresponding robust standard errors. Can also used transform model parameters application Delta Theorem. merge, + method combining estimates via estimated IFs IC method extract estimated estimate function primary tool obtaining parameter estimates related information. returns object class type estimate, general container holding information estimated parameters. estimate function takes input either model object (first argument x), parameter vector corresponding influence function () matrix specified using coef arguments. primary goal apply delta method test linear hypotheses, also possible provide asymptotic variance estimate via vcov argument, without specifying matrix. first consider problem estimating mean. general transformation f:ℝk→ℝpf: \\mathbb{R}^k\\\\mathbb{R}^p n{ℙnf(X)−𝔼[f(X)]}=1n∑=1nf(Xi)−𝔼[f(X)] \\sqrt{n}\\{\\mathbb{P}_{n}f(X) - \\mathbb{E}[f(X)]\\} = \\frac{1}{\\sqrt{n}}\\sum_{=1}^{n}  f(X_{}) - \\mathbb{E}[f(X)]  hence problem estimating proportion binary outcome Y1Y_1, given 𝟏(Y1=1)−ℙ(Y1=1)\\mathbf{1}(Y_{1}=1) - \\mathbb{P}(Y_{1}=1). estimate parameter use estimate function reported standard errors estimate method robust standard errors obtained . variance estimate parameters can extracted vcov coef methods. can extracted IC (influence) method: also possible simultaneously estimate proportions two binary outcomes alternatively input can model object, mlm object: Different methods available inspecting estimate object","code":"estimate(x=, ...) estimate(coef=, IF=, ...) estimate(coef=, vcov=, ...) inp <- as.matrix(dw[, c(\"y1\", \"y2\")]) e <- estimate(inp[, 1, drop = FALSE], type=\"mean\")  class(e) #> [1] \"estimate\" e #>    Estimate Std.Err   2.5%  97.5%    P-value #> y1     0.61 0.02439 0.5622 0.6578 4.435e-138 IC(e) |> Print() #>     y1    #> 1    0.39 #> 2    0.39 #> 3   -0.61 #> 4   -0.61 #> 5   -0.61 #> ---       #> 396 -0.61 #> 397  0.39 #> 398 -0.61 #> 399 -0.61 #> 400  0.39 estimate(inp) #>    Estimate Std.Err   2.5%  97.5%    P-value #> y1    0.610 0.02439 0.5622 0.6578 4.435e-138 #> y2    0.535 0.02494 0.4861 0.5839 4.316e-102 e <- lm(cbind(y1, y2) ~ 1, data = dw) |>   estimate() IC(e) |> head() #>   y1:(Intercept) y2:(Intercept) #> 1           0.39         -0.535 #> 2           0.39          0.465 #> 3          -0.61         -0.535 #> 4          -0.61          0.465 #> 5          -0.61         -0.535 #> 6          -0.61          0.465 summary(e) #> Call: estimate.default(x = x, coef = pars(x)) #> ──────────────────────────────────────────────────────────────────────────────── #>                Estimate Std.Err   2.5%  97.5%    P-value #> y1:(Intercept)    0.610 0.02439 0.5622 0.6578 4.435e-138 #> y2:(Intercept)    0.535 0.02494 0.4861 0.5839 4.316e-102 #>  #>  Null Hypothesis:  #>   [y1:(Intercept)] = 0 #>   [y2:(Intercept)] = 0  #>   #> chisq = 955.6986, df = 2, p-value < 2.2e-16 ## extract parameter coefficients coef(e) #> y1:(Intercept) y2:(Intercept)  #>          0.610          0.535 ## ## Asymptotic (robust) variance estimate vcov(e) #>                y1:(Intercept) y2:(Intercept) #> y1:(Intercept)     5.9475e-04   0.0000841250 #> y2:(Intercept)     8.4125e-05   0.0006219375 ## Matrix with estimates and confidence limits estimate(e, level = 0.99) |> parameter() #>                Estimate    Std.Err      0.5%     99.5%       P-value #> y1:(Intercept)    0.610 0.02438750 0.5471820 0.6728180 4.434692e-138 #> y2:(Intercept)    0.535 0.02493867 0.4707622 0.5992378 4.316104e-102 ## Influence curve IC(e) |> head() #>   y1:(Intercept) y2:(Intercept) #> 1           0.39         -0.535 #> 2           0.39          0.465 #> 3          -0.61         -0.535 #> 4          -0.61          0.465 #> 5          -0.61         -0.535 #> 6          -0.61          0.465 ## Join estimates e + e # Same as merge(e,e) #>                  Estimate Std.Err   2.5%  97.5%    P-value #> y1:(Intercept)      0.610 0.02439 0.5622 0.6578 4.435e-138 #> y2:(Intercept)      0.535 0.02494 0.4861 0.5839 4.316e-102 #> ────────────────                                           #> y1:(Intercept).1    0.610 0.02439 0.5622 0.6578 4.435e-138 #> y2:(Intercept).1    0.535 0.02494 0.4861 0.5839 4.316e-102"},{"path":"/articles/influencefunction.html","id":"example-generalized-linear-model","dir":"Articles","previous_headings":"Examples","what":"Example: generalized linear model","title":"The Art of Influence","text":"ZZ-estimator defined score equation E[U(Z;θ)]=0E[U(Z; \\theta)] = 0, given IC(Z;θ)=𝔼{∂∂θ⊤U(θ;Z)}−1U(Z;θ)\\begin{align*} IC(Z; \\theta) = \\mathbb{E}\\Big\\{\\frac{\\partial}{\\partial\\theta^\\top}U(\\theta; Z)\\Big\\}^{-1}U(Z; \\theta) \\end{align*} particular, maximum likelihood estimator score, UU, given partial derivative log-likelihood function. example, can obtain estimates robust standard errors logistic regression model: can compare usual (non-robust) standard errors: can extracted estimate object directly model object estimates can obtained cumulative link regression model also generalizes ordinal outcomes. consider proportional odds model given log(ℙ(Y≤j∣x)1−ℙ(Y≤j∣x))=αj+βtx,j=1,…,J\\begin{align*} \\log\\left(\\frac{\\mathbb{P}(Y\\leq j\\mid x)}{1-\\mathbb{P}(Y\\leq j\\mid x)}\\right) = \\alpha_{j} + \\beta^{t}x, \\quad j=1,\\ldots,J \\end{align*} Note sandwich::estfun function sandwich library (Zeileis, Köll, Graham 2020) can also estimate different parametric models, provide tools combining transforming .","code":"g <- glm(y1 ~ a + x1, data = dw, family = binomial) estimate(g) #>             Estimate Std.Err    2.5%   97.5%   P-value #> (Intercept)  -0.2687  0.1622 -0.5867 0.04931 9.772e-02 #> a             1.5595  0.2428  1.0835 2.03545 1.348e-10 #> x1            0.9728  0.1435  0.6916 1.25397 1.198e-11 estimate(g, robust = FALSE) #>             Estimate Std.Err    2.5%   97.5%   P-value #> (Intercept)  -0.2687  0.1589 -0.5802 0.04281 9.091e-02 #> a             1.5595  0.2423  1.0846 2.03433 1.220e-10 #> x1            0.9728  0.1396  0.6992 1.24634 3.177e-12 IC(g) |> head() #>   (Intercept)          a         x1 #> 1  0.09816353   3.715892 -0.8478763 #> 2 -0.08203584   2.562573  0.7085752 #> 3 -2.74896196   3.316937  1.8772112 #> 4 -6.78328520   4.052090 -9.0268560 #> 5  0.47533946 -11.818085 -4.1056905 #> 6 -2.77584564   3.340948  1.8677174 ordreg(y1 ~ a + x1, dw, family=binomial(logit)) |> estimate() #>     Estimate Std.Err     2.5%  97.5%   P-value #> 0|1   0.2687  0.1622 -0.04932 0.5867 9.772e-02 #> a     1.5595  0.2429  1.08349 2.0355 1.350e-10 #> x1    0.9728  0.1435  0.69157 1.2540 1.200e-11"},{"path":"/articles/influencefunction.html","id":"example-right-censored-outcomess","dir":"Articles","previous_headings":"Examples","what":"Example: right-censored outcomess","title":"The Art of Influence","text":"illustrate methods survival data use Mayo Clinic Primary Biliary Cholangitis Data (Therneau Grambsch 2000) Cox proportional hazards model can fitted mets::phreg method can estimate partial likelihood parameters baseline hazard. fit survival model right-censored event times baseline cumulative hazard specific time point Λ0(t)=∫0tλ0(u)du,\\begin{align*} \\Lambda_0(t) = \\int_0^t \\lambda_0(u)\\,du,  \\end{align*} λ0(t)\\lambda_0(t) baseline hazard, can estimated similar way: estimate methods also available parametric survival models via survival::survreg, Weibull model:","code":"library(\"survival\") data(pbc, package=\"survival\") fit.phreg <- mets::phreg(Surv(time, status > 0) ~ age + sex, data = pbc) fit.phreg #> Call: #> mets::phreg(formula = Surv(time, status > 0) ~ age + sex, data = pbc) #>  #>    n events #>  418    186 #> coeffients: #>        Estimate       S.E.    dU^-1/2 P-value #> age   0.0220977  0.0070372  0.0072712  0.0017 #> sexf -0.2999507  0.2022144  0.2097533  0.1380 #>  #> exp(coeffients): #>      Estimate    2.5%  97.5% #> age   1.02234 1.00834 1.0365 #> sexf  0.74085 0.49843 1.1012 IC(fit.phreg) |> head() #>           age       sexf #> 1  0.12691175  2.9551968 #> 2 -0.16011629 -4.3755455 #> 3  0.19322595 -8.1786480 #> 4  0.04668109  0.8548021 #> 5 -0.22936186  0.9721761 #> 6  0.07015171  0.5644414 baseline <- function(object, time, ...) {   ic <- mets::IC(object, baseline = TRUE, time = time, ...)   est <- mets::predictCumhaz(object$cumhaz, new.time = time)[1, 2]   estimate(NULL, coef = est, IC = ic, labels = paste0(\"chaz:\", time)) } tt <- 2000 baseline(fit.phreg, tt) #>           Estimate Std.Err    2.5%  97.5% P-value #> chaz:2000    0.178 0.07597 0.02913 0.3269 0.01911 survival::survreg(Surv(time, status > 0) ~ age + sex, data = pbc, dist=\"weibull\") |>   estimate() #>             Estimate  Std.Err     2.5%     97.5%    P-value #> (Intercept)  9.02697 0.382437  8.27741  9.776530 3.521e-123 #> age         -0.01919 0.006362 -0.03166 -0.006723  2.554e-03 #> sexf         0.28170 0.174338 -0.06000  0.623392  1.061e-01 #> scale        0.87751 0.070693  0.73896  1.016067  2.220e-35"},{"path":"/articles/influencefunction.html","id":"example-random-effects-model-structural-equation-model","dir":"Articles","previous_headings":"Examples","what":"Example: random effects model / structural equation model","title":"The Art of Influence","text":"General structural equation models (SEMs) can estimated lava::lvm. fit random effects probit model ℙ(Yij=1∣Ui,Wij)=Φ(μj+βjWij+Ui),Ui∼𝒩(0,σu2),j=1,2 \\mathbb{P}(Y_{ij} = 1 \\mid U_{}, W_{ij})=\\Phi(\\mu_{j} + \\beta_{j} W_{ij} + U_{}), \\quad U_{}\\sim\\mathcal{N}(0,\\sigma_{u}^{2}),\\quad j=1,2  simulated dataset","code":"sem <- lvm(y1 + y2 ~ 1 * u + w) |>   latent(~ u) |>   ordinal(K=2, ~ y1 + y2) semfit <- estimate(sem, data = dw)  ## Robust standard errors estimate(semfit) #>      Estimate Std.Err    2.5%    97.5%   P-value #> y2   -0.21037 0.09391 -0.3944 -0.02630 2.509e-02 #> u     0.36025 0.06659  0.2297  0.49075 6.295e-08 #> y1~w  0.55425 0.06930  0.4184  0.69008 1.272e-15 #> y2~w  0.59388 0.07510  0.4467  0.74108 2.623e-15 #> u~~u -0.09496 0.07360 -0.2392  0.04929 1.970e-01"},{"path":"/articles/influencefunction.html","id":"example-quantile","dir":"Articles","previous_headings":"Examples","what":"Example: quantile","title":"The Art of Influence","text":"Let β\\beta denote τ\\tauth quantile XX, IC(x;P0)=τ−𝟏(x≤β)f0(β)−1\\begin{align*} \\operatorname{IC}(x; P_{0}) = \\tau - \\mathbf{1}(x\\leq \\beta)f_{0}(\\beta)^{-1}  \\end{align*} f0f_{0} density function XX. calculate variance estimate, estimate density thus needed can obtained kernel estimate. Alternatively, resampling method (Zeng Lin 2008) can applied. use kernel smoother (additional arguments estimate function parsed stats::density.default) estimate quantiles 25%, 50%, 75% quantiles WW X1X_1","code":"eq <- estimate(dw[, c(\"w\", \"x1\")], type = \"quantile\", probs = c(0.25, 0.5, 0.75)) eq #>        Estimate Std.Err    2.5%    97.5%   P-value #> w.25%  -0.81214 0.07277 -0.9548 -0.66951 6.390e-29 #> w.50%  -0.11062 0.07201 -0.2518  0.03052 1.245e-01 #> w.75%   0.67716 0.07784  0.5246  0.82973 3.353e-18 #> x1.25% -0.57510 0.06340 -0.6994 -0.45084 1.177e-19 #> x1.50% -0.02664 0.06078 -0.1458  0.09249 6.611e-01 #> x1.75%  0.69590 0.06696  0.5647  0.82715 2.683e-25 IC(eq) |> head() #>          w.25%     w.50%      w.75%    x1.25%    x1.50%     x1.75% #> [1,] 0.8402973  1.440254  2.6966215 -2.196201 -1.215663 -0.7732142 #> [2,] 0.8402973  1.440254  2.6966215  0.732067  1.215663 -0.7732142 #> [3,] 0.8402973 -1.440254 -0.8988738 -2.196201 -1.215663 -0.7732142 #> [4,] 0.8402973 -1.440254 -0.8988738  0.732067  1.215663  2.3196427 #> [5,] 0.8402973 -1.440254 -0.8988738  0.732067  1.215663 -0.7732142 #> [6,] 0.8402973 -1.440254 -0.8988738 -2.196201 -1.215663 -0.7732142"},{"path":"/articles/influencefunction.html","id":"combining-influence-functions","dir":"Articles","previous_headings":"","what":"Combining influence functions","title":"The Art of Influence","text":"key benefit working IFs estimators allows transforming combining different estimates easily deriving resulting thereby asymptotic distribution new estimator. Let θ̂1,…,θ̂M\\widehat{\\theta}_{1}, \\ldots, \\widehat{\\theta}_{M} MM different estimators decompositions n(θ̂m−θm)=1n∑=1nICm(Zi;P0)+oP(1)\\begin{align*} \\sqrt{n}(\\widehat{\\theta}_{m}-\\theta_{m}) = \\frac{1}{\\sqrt{n}}\\sum_{=1}^{n} \\operatorname{IC}_m(Z_i; P_{0}) + o_{P}(1) \\end{align*} based iid data Z1,…,ZnZ_1,\\ldots,Z_n. follows immediately (Vaart 1998 Theorem 18.10[vi]) joint distribution $ - {}= ({1}{},,{M}{})- ({}{1}{},,{}{M}{}) $ given n(θ̂−θ)=1n∑=1n[IC1(Zi;P0)⊤,…,ICM(Zi;P0)⊤]⊤⏟IC¯(Zi;P0)+oP(1)→𝒟𝒩(0,Σ)\\begin{align*} \\sqrt{n}(\\widehat{\\theta}-\\theta) &= \\frac{1}{\\sqrt{n}}\\sum_{=1}^{n} \\underbrace{[\\operatorname{IC}_{1}(Z_i; P_{0})^\\top,\\ldots,\\operatorname{IC}_{M}(Z_i; P_{0})^\\top]^{\\top}}_{\\overline{\\operatorname{IC}}(Z_i; P_{0})} + o_{P}(1) \\\\ &\\overset{\\mathcal{D}}{\\longrightarrow}\\mathcal{N}(0,\\Sigma) \\end{align*} CLT, regulatory conditions ℙnIC¯(Zi;P̂)⊗2→PΣ\\mathbb{P}_{n}\\overline{\\operatorname{IC}}(Z_i; \\widehat{P})^{\\otimes 2} \\overset{P}{\\longrightarrow}\\Sigma n→∞n\\\\infty. illustrate consider two marginal logistic regression models fitted separately Y1Y_1 Y2Y_2 combine estimates IFs using merge method access joint asymptotic distribution can example test whether odds-ratio two responses: details found Section hypothesis testing.","code":"g1 <- glm(y1 ~ a, family=binomial, data=dw) g2 <- glm(y2 ~ a, family=binomial, data=dw) e <- merge(g1, g2) summary(e) #> Call: estimate.default(x = NULL, data = NULL, id = id, stack = FALSE,  #>     IC = ic0, keep = keep, coef = coefs) #> ──────────────────────────────────────────────────────────────────────────────── #>               Estimate Std.Err    2.5%    97.5%   P-value #> (Intercept)    -0.1861  0.1442 -0.4688  0.09655 1.969e-01 #> a               1.3239  0.2173  0.8981  1.74978 1.105e-09 #> ─────────────                                             #> (Intercept).1  -0.6168  0.1505 -0.9117 -0.32185 4.152e-05 #> a.1             1.5060  0.2148  1.0849  1.92712 2.385e-12 #>  #>  Null Hypothesis:  #>   [(Intercept)] = 0 #>   [a] = 0 #>   [(Intercept).1] = 0 #>   [a.1] = 0  #>   #> chisq = 96.4362, df = 4, p-value < 2.2e-16 estimate(e, cbind(0,1,0,-1), null=0) #>             Estimate Std.Err    2.5%  97.5% P-value #> [a] - [a.1]  -0.1821  0.3003 -0.7707 0.4065  0.5443 #>  #>  Null Hypothesis:  #>   [a] - [a.1] = 0"},{"path":"/articles/influencefunction.html","id":"imbalanced-data","dir":"Articles","previous_headings":"Combining influence functions","what":"Imbalanced data","title":"The Art of Influence","text":"Let O1=(Z1R1,R1),…,=(ZNRN,RN)O_{1} = (Z_{1}R_{1}, R_{1}), \\ldots, O_{N}=(Z_{N}R_{N}, R_{N}) iid Ri⊥⊥ZiR_{}\\!\\perp\\!\\!\\!\\!\\perp\\!Z_i let full-data estimator parameter θ∈ℝp\\theta\\\\mathbb{R}^p IC(⋅;P0)IC(\\cdot; P_{0}). convenience let data ordered Ri=𝟏(≤n)R_{}=\\mathbf{1}(\\leq n) nn number observed data points, complete-case estimator consistent based n(θ̂−θ)=1n∑=1nIC(Zi;P0)+oP(1).\\begin{align*} \\sqrt{n}(\\widehat{\\theta}-\\theta) = \\frac{1}{\\sqrt{n}}\\sum_{=1}^n IC(Z_i; P_{0}) + o_{P}(1). \\end{align*} estimator can also decomposed terms observed data O1,…,ONO_1,\\ldots,O_N noting N(θ̂−θ)=1N∑=1NIC(Zi;P)RiNn+oP(1).\\begin{align*} \\sqrt{N}(\\widehat{\\theta}-\\theta) = \\frac{1}{\\sqrt{N}}\\sum_{=1}^N IC(Z_i; P)\\frac{R_i N}{n} + o_{P}(1). \\end{align*} term RiNn\\frac{R_i N}{n} corresponds inverse probability weighting empirical plugin estimate proportion observed data R=1R=1. missing completely random assumption can therefore combine estimators estimated different datasets. Let observed data (Z11R11,R11,Z21R21,R21),…,(Z1NR1N,R1N,Z2NR2N,R2N))(Z_{11}R_{11}, R_{11}, Z_{21}R_{21}, R_{21}), \\ldots, (Z_{1N}R_{1N}, R_{1N}, Z_{2N}R_{2N}, R_{2N})) complete-case estimators θ̂1\\widehat{\\theta}_1 θ̂2\\widehat{\\theta}_2 parameters θ1\\theta_1 θ2\\theta_2 based (Z11R11,…,Z1NR1N)(Z_{11}R_{11}, \\ldots, Z_{1N}R_{1N}) (Z21R21,…,Z2NR2N)(Z_{21}R_{21}, \\ldots, Z_{2N}R_{2N}), respectively, let corresponding IFs IC1(⋅;P0)IC_{1}(\\cdot; P_{0}) IC2(⋅;P)IC_{2}(\\cdot;\\ P). follows $$\\begin{align*} \\sqrt{N}\\left\\{ \\begin{pmatrix} \\widehat{\\theta}_1 \\\\ \\widehat{\\theta}_2 \\end{pmatrix} - \\begin{pmatrix} \\vphantom{\\widehat{\\theta}_1}\\theta_1 \\\\ \\vphantom{\\widehat{\\theta}_1}\\theta_2 \\end{pmatrix} \\right\\} = \\frac{1}{\\sqrt{N}}\\sum_{=1}^N \\begin{pmatrix} IC_1(Z_{1i}; P_{0})\\frac{R_{1i}N}{R_{1\\bullet}} \\\\ IC_2(Z_{2i}; P_{0})\\frac{R_{2i}N}{R_{2\\bullet}} \\end{pmatrix} + o_{P}(1) \\end{align*}$$ Rk•=∑=1NRki.R_{k\\bullet} = \\sum_{=1}^{N}R_{ki}. Returning example, can combine marginal estimates two model objects estimated different datasets (outcome Y3Y_3 available half data). use overloaded + operator Note, also possible directly specify id-variables merge call: example id argument defines identifier makes possible link rows different IFs glued together. omitted id automatically extracted model-specific IC method (deriving original data.frame used estimating model). automatically works models IC methods described document. force id variables overlapping merged model objects, .e., assuming complete independence estimates, argument id=NULL can used","code":"g2 <- glm(y2 ~ 1, family = binomial, data = dw) summary(g2) #>  #> Call: #> glm(formula = y2 ~ 1, family = binomial, data = dw) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|) #> (Intercept)   0.1402     0.1002   1.399    0.162 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 552.56  on 399  degrees of freedom #> Residual deviance: 552.56  on 399  degrees of freedom #> AIC: 554.56 #>  #> Number of Fisher Scoring iterations: 3 dwc <- na.omit(dw)  g3 <- glm(y3 ~ 1, family = binomial, data = dwc) summary(g3) #>  #> Call: #> glm(formula = y3 ~ 1, family = binomial, data = dwc) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)   #> (Intercept)   0.2615     0.1426   1.833   0.0668 . #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 273.87  on 199  degrees of freedom #> Residual deviance: 273.87  on 199  degrees of freedom #> AIC: 275.87 #>  #> Number of Fisher Scoring iterations: 3  e2 <- estimate(g2, id = dw$id) e3 <- estimate(g3, id = \"id\", data=dwc)  merge(e2,e3) |> IC() |> Print() #>     (Intercept) (Intercept).1 #> 1   -2.151       3.540        #> 2    1.869       3.540        #> 3   -2.151      -4.598        #> 4    1.869      -4.598        #> 5   -2.151       3.540        #> ---                           #> 396 -2.151       0.000        #> 397  1.869       0.000        #> 398 -2.151       0.000        #> 399 -2.151       0.000        #> 400 -2.151       0.000 vcov(e2 + e3) #>               (Intercept) (Intercept).1 #> (Intercept)   0.010049191   0.002102598 #> (Intercept).1 0.002102598   0.020342639 ## Same marginals as list(vcov(e2), vcov(e3)) #> [[1]] #>             (Intercept) #> (Intercept)  0.01004919 #>  #> [[2]] #>             (Intercept) #> (Intercept)  0.02034264 merge(e2, e3, id = list(dw$id, dwc$id)) #>               Estimate Std.Err     2.5%  97.5% P-value #> (Intercept)     0.1402  0.1002 -0.05625 0.3367 0.16186 #> ─────────────                                          #> (Intercept).1   0.2615  0.1426 -0.01807 0.5410 0.06676 estimate(g2) |>   IC() |> head() #>   (Intercept) #> 1   -2.150532 #> 2    1.869154 #> 3   -2.150532 #> 4    1.869154 #> 5   -2.150532 #> 6    1.869154 vcov(estimate(g2) + estimate(g3)) #>               (Intercept) (Intercept).1 #> (Intercept)   0.010049191   0.002102598 #> (Intercept).1 0.002102598   0.020342639 (estimate(g2) + estimate(g3)) |>   (rownames %++% head %++% IC)() #> [1] \"1\"   \"10\"  \"100\" \"101\" \"102\" \"103\" merge(g1, g2, id = NULL) |> (Print %++% IC)() #>     (Intercept) a          (Intercept).1 #> 1    1.104e-15   5.128e+00  0.000e+00    #> 2    1.104e-15   5.128e+00  0.000e+00    #> 3   -7.547e+00   7.547e+00  0.000e+00    #> 4   -7.547e+00   7.547e+00  0.000e+00    #> 5   -2.200e-15  -1.600e+01  0.000e+00    #> ---                                      #> 796  0.000       0.000      3.738        #> 797  0.000       0.000      3.738        #> 798  0.000       0.000     -4.301        #> 799  0.000       0.000     -4.301        #> 800  0.000       0.000     -4.301 merge(g1, g2, id = NULL) |> vcov() #>                 (Intercept)             a (Intercept).1 #> (Intercept)    2.079760e-02 -2.079760e-02 -1.600942e-29 #> a             -2.079760e-02  4.720777e-02 -1.554863e-25 #> (Intercept).1 -1.600942e-29 -1.554863e-25  1.004919e-02"},{"path":"/articles/influencefunction.html","id":"renaming-and-subsetting-parameters","dir":"Articles","previous_headings":"Combining influence functions","what":"Renaming and subsetting parameters","title":"The Art of Influence","text":"keep subset parameters keep argument can used. argument can given either character vector vector indices: vector perl-style regular expressions merging estimates unique parameter names created. also possible rename parameters labels argument Finally, subset argument can used subset parameters IFs actual merging done","code":"merge(g1, g2, keep = c(\"(Intercept)\", \"(Intercept).1\")) #>               Estimate Std.Err     2.5%   97.5% P-value #> (Intercept)    -0.1861  0.1442 -0.46876 0.09655  0.1969 #> (Intercept).1   0.1402  0.1002 -0.05625 0.33671  0.1619 merge(g1,g2, keep=c(1, 3)) #>               Estimate Std.Err     2.5%   97.5% P-value #> (Intercept)    -0.1861  0.1442 -0.46876 0.09655  0.1969 #> (Intercept).1   0.1402  0.1002 -0.05625 0.33671  0.1619 merge(g1, g2, keep = \"cept\", regex = TRUE) #>               Estimate Std.Err     2.5%   97.5% P-value #> (Intercept)    -0.1861  0.1442 -0.46876 0.09655  0.1969 #> (Intercept).1   0.1402  0.1002 -0.05625 0.33671  0.1619 merge(g1, g2, keep = c(\"\\\\)$\", \"^a$\"), regex = TRUE, ignore.case = TRUE) #>             Estimate Std.Err    2.5%   97.5%   P-value #> (Intercept)  -0.1861  0.1442 -0.4688 0.09655 1.969e-01 #> a             1.3239  0.2173  0.8981 1.74978 1.105e-09 merge(g1, g2, labels = c(\"a\", \"b\", \"c\")) |> estimate(keep = c(\"a\", \"c\")) #>   Estimate Std.Err     2.5%   97.5% P-value #> a  -0.1861  0.1442 -0.46876 0.09655  0.1969 #> c   0.1402  0.1002 -0.05625 0.33671  0.1619 merge(g1, g2,       labels = c(\"a\", \"b\", \"c\"),       keep = c(\"a\", \"c\") ) #>   Estimate Std.Err     2.5%   97.5% P-value #> a  -0.1861  0.1442 -0.46876 0.09655  0.1969 #> c   0.1402  0.1002 -0.05625 0.33671  0.1619 estimate(g1, labels=c(\"a\", \"b\")) #>   Estimate Std.Err    2.5%   97.5%   P-value #> a  -0.1861  0.1442 -0.4688 0.09655 1.969e-01 #> b   1.3239  0.2173  0.8981 1.74978 1.105e-09 merge(g1, g2, subset=\"(Intercept)\") #>               Estimate Std.Err     2.5%   97.5% P-value #> (Intercept)    -0.1861  0.1442 -0.46876 0.09655  0.1969 #> ─────────────                                           #> (Intercept).1   0.1402  0.1002 -0.05625 0.33671  0.1619"},{"path":"/articles/influencefunction.html","id":"clustered-data-non-iid-case","dir":"Articles","previous_headings":"Combining influence functions","what":"Clustered data (non-iid case)","title":"The Art of Influence","text":"Let Zi=(Zi1,…,ZiNi)Z_i = (Z_{i1},\\ldots,Z_{iN_{}}) assume (Zi,Ni)∼P(Z_{}, N_{}) \\sim P, =1,…,ni=1,\\ldots,n iid Ni⊥⊥ZijN_i\\!\\perp\\!\\!\\!\\!\\perp\\!Z_{ij}. variables Zi1,…,ZiNiZ_{i1},\\ldots,Z_{iN_{}} assume exchangeable necessarily independent. Define N=∑=1nNiN = \\sum_{=1}^{n} N_i, assume parameter estimate, θ̂∈ℝp\\widehat{\\theta}\\\\mathbb{R}^p decomposition N(θ̂−θ)=1N∑=1n∑k=1NiIC(Zik;P0)+oP(1). \\sqrt{N}(\\widehat{\\theta}-\\theta) = \\frac{1}{\\sqrt{N}} \\sum_{=1}^{n} \\sum_{k=1}^{N_{}} IC(Z_{ik}; P_{0}) + o_{P}(1).  follows n(θ̂−θ)=1n∑=1nIC̃(Zi;P0)+oP(1) \\sqrt{n}(\\widehat{\\theta}-\\theta) =  \\frac{1}{\\sqrt{n}} \\sum_{=1}^{n} \\widetilde{\\operatorname{IC}}(Z_{}; P_{0}) + o_{P}(1)  IC̃(Zi;P0)=∑k=1NinNIC(Zik;P0)\\widetilde{\\operatorname{IC}}(Z_{}; P_{0}) = \\sum_{k=1}^{N_{}} \\frac{n}{N}IC(Z_{ik}; P_{0}), =1,…,ni=1,\\ldots,n iid therefore admits usual CLT derive asymptotic variance θ̂\\widehat{\\theta}. Turning back example data, can estimate marginal model asymptotic variance estimate ignoring observations independent consistent. Instead can calculate cluster robust standard errors iid decomposition can confirm situation equivalent variance estimates obtain GEE marginal model working independence correlation structure (Halekoh, Højsgaard, Yan 2006)","code":"g0 <- glm(y ~ a + w + x, data = dl, family = binomial()) estimate(g0, id=dl$id) #>             Estimate Std.Err    2.5%   97.5%   P-value #> (Intercept)  -0.1147 0.09351 -0.2979 0.06862 2.201e-01 #> a             1.0178 0.13016  0.7627 1.27288 5.303e-15 #> w             0.9825 0.07421  0.8370 1.12791 5.278e-40 #> x             0.9485 0.07835  0.7949 1.10203 9.976e-34 gee0 <- geepack::geeglm(y ~ a + w + x, data = dl, id = dl$id, family=binomial) summary(gee0) #>  #> Call: #> geepack::geeglm(formula = y ~ a + w + x, family = binomial, data = dl,  #>     id = dl$id) #>  #>  Coefficients: #>             Estimate  Std.err    Wald Pr(>|W|)     #> (Intercept) -0.11466  0.09351   1.504     0.22     #> a            1.01777  0.13016  61.145 5.33e-15 *** #> w            0.98246  0.07421 175.250  < 2e-16 *** #> x            0.94845  0.07835 146.523  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Correlation structure = independence  #> Estimated Scale Parameters: #>  #>             Estimate Std.err #> (Intercept)   0.9538   0.098 #> Number of clusters:   400  Maximum cluster size: 4"},{"path":"/articles/influencefunction.html","id":"computational-aspects","dir":"Articles","previous_headings":"Combining influence functions","what":"Computational aspects","title":"The Art of Influence","text":"Working large potentially multiple different IFs can memory-intensive. remedy use idea aggregating IFs introducing random coarser grouping variable. Following arguments previous section, aggregated still iid allows us estimate asymptotic variance. Obviously, grouping must used across estimates combining IFs.","code":"set.seed(1) y <- cbind(rnorm(1e5)) N <- 2e2 ## Number of aggregated groups, the number of observations in the new IF id <- foldr(nrow(y), N, list=FALSE) Print(cbind(table(id))) #>     [,1] #> 1   500  #> 2   500  #> 3   500  #> 4   500  #> 5   500  #> ---      #> 196 500  #> 197 500  #> 198 500  #> 199 500  #> 200 500  ## Aggregated IF e <- estimate(cbind(y), id = id)  object.size(e) #> 18992 bytes e #>     Estimate Std.Err      2.5%    97.5% P-value #> p1 -0.002244 0.00332 -0.008751 0.004263  0.4991"},{"path":"/articles/influencefunction.html","id":"if-building-blocks-transformations-and-the-delta-theorem","dir":"Articles","previous_headings":"","what":"IF building blocks: transformations and the delta theorem","title":"The Art of Influence","text":"Let ϕ:ℝp→ℝm\\phi\\colon \\mathbb{R}^p\\\\mathbb{R}^m differentiable θ\\theta assume θ̂n\\widehat{\\theta}_n RAL estimator given IC(⋅;P0)\\operatorname{IC}(\\cdot; P_{0}) n(θ̂n−θ)=1n∑=1nIC(Zi;P0)+oP(1),\\begin{align*}  \\sqrt{n}(\\widehat{\\theta}_n - \\theta) = \\frac{1}{\\sqrt{n}}\\sum_{=1}^n \\operatorname{IC}(Z_i; P_{0}) + o_{P}(1),  \\end{align*} delta method (Vaart 1998 Theorem 3.1) n{ϕ(θ̂n)−ϕ(θ)}=1n∑=1n∇ϕ(θ)IC(Zi;P0)+oP(1),\\begin{align*}  \\sqrt{n}\\{\\phi(\\widehat{\\theta}_n) - \\phi(\\theta)\\}  = \\frac{1}{\\sqrt{n}}\\sum_{=1}^n \\nabla\\phi(\\theta)\\operatorname{IC}(Z_i; P_{0}) + o_{P}(1),  \\end{align*} ϕ:θ↦(ϕ1(θ),…,ϕm(θ))⊤\\phi\\colon \\theta\\mapsto (\\phi_{1}(\\theta),\\ldots,\\phi_{m}(\\theta))^\\top ∇\\nabla partial derivative operator ∇ϕ(θ)=(∂∂θ1ϕ1(θ)⋯∂∂θpϕ1(θ)⋮⋱⋮∂∂θ1ϕm(θ)⋯∂∂θpϕm(θ)).\\begin{align*} \\nabla\\phi(\\theta) =  \\begin{pmatrix} \\tfrac{\\partial}{\\partial\\theta_1}\\phi_1(\\theta) & \\cdots & \\tfrac{\\partial}{\\partial\\theta_p}\\phi_1(\\theta) \\\\ \\vdots & \\ddots & \\vdots \\\\ \\tfrac{\\partial}{\\partial\\theta_1}\\phi_m(\\theta) & \\cdots & \\tfrac{\\partial}{\\partial\\theta_p}\\phi_m(\\theta) \\\\ \\end{pmatrix}. \\end{align*} Together ability derive joint marginal IFs, provides us powerful tool constructing new estimates using IFs fundamental building blocks. apply delta method transformation parameters function must supplied estimate method (argument f) gradient can provided attribute grad otherwise numerical differentiation applied.","code":"estimate(g1, sum) #>    Estimate Std.Err   2.5% 97.5%   P-value #> p1    1.138  0.1625 0.8193 1.456 2.532e-12 estimate(g1, function(p) list(a = sum(p))) # named list #>   Estimate Std.Err   2.5% 97.5%   P-value #> a    1.138  0.1625 0.8193 1.456 2.532e-12 ## Multiple parameters estimate(g1, function(x) c(x, x[1] + exp(x[2]), inv = 1 / x[2])) #>               Estimate Std.Err    2.5%   97.5%   P-value #> (Intercept)    -0.1861  0.1442 -0.4688 0.09655 1.969e-01 #> a               1.3239  0.2173  0.8981 1.74978 1.105e-09 #> (Intercept).1   3.5721  0.7289  2.1435 5.00062 9.539e-07 #> inv.a           0.7553  0.1240  0.5124 0.99828 1.105e-09 estimate(g1, exp)          #>             Estimate Std.Err   2.5% 97.5%   P-value #> (Intercept)   0.8302  0.1197 0.5955 1.065 4.087e-12 #> a             3.7582  0.8166 2.1578 5.359 4.175e-06"},{"path":"/articles/influencefunction.html","id":"example-pearson-correlation","dir":"Articles","previous_headings":"IF building blocks: transformations and the delta theorem","what":"Example: Pearson correlation","title":"The Art of Influence","text":"simple toy example consider problem estimating covariance two variables X1X_1 X2X_2ℂov̂(X1,X2)=ℙn(X1−ℙnX1)(Y1−ℙnY1).\\begin{align*} \\widehat{\\mathbb{C}\\!\\text{ov}}(X_1,X_2) = \\mathbb{P}_n(X_1-\\mathbb{P}_n X_1)(Y_1-\\mathbb{P}_n Y_1). \\end{align*} easily verified sample estimate (𝔼X1,𝔼X2,𝔼{X1X2})⊤(\\mathbb{E}X_{1}, \\mathbb{E}X_{2}, \\mathbb{E}\\{X_{1}X_{2}\\})^\\top given IC(X1,X2;P0)=(X1−𝔼X1,X2−𝔼X2,X1X2−𝔼{X1X2})⊤\\operatorname{IC}(X1,X2; P_{0}) = (X_{1}-\\mathbb{E}X_{1}, X_{2}-\\mathbb{E}X_{2}, X_{1}X_{2}-\\mathbb{E}\\{X_{1}X_{2}\\})^\\top. delta theorem ϕ(x,y,z)=z−xy\\phi(x,y,z) = z-xy ∇ϕ(x,y,z)=(−y−x1)\\nabla\\phi(x,y,z) = (-y -x 1) thus sample covariance estimate becomes ICx1,x2(X1,X2;P0)=(X1−𝔼X1)(X2−𝔼X2)−ℂov(X1,X2)\\begin{align*} \\operatorname{IC}_{x_1, x_2}(X_1, X_2; P_{0}) = (X_1 - \\mathbb{E}X_1)(X_2 - \\mathbb{E}X_2) - \\mathbb{C}\\!\\text{ov}(X_1,X_2) \\end{align*} can implement directly using estimate function via IC argument allows us provide user-specificed point estimate given coef argument illustration also derive estimate simpler building blocks 𝔼X1\\mathbb{E}X_{1}, 𝔼X2\\mathbb{E}X_{2}, 𝔼(X1X2)\\mathbb{E}(X_{1}X_{2}). variance estimates can estimated way combined estimates used estimate correlation using variance stabilizing transformation, Fishers zz-transform (Lehmann Romano 2023), z=arctanh(ρ̂)=12log(1+ρ̂1−ρ̂)z = \\operatorname{arctanh}(\\widehat{\\rho}) = \\frac{1}{2}\\log\\left(\\frac{1+\\widehat{\\rho}}{1-\\widehat{\\rho}}\\right), confidence limits general better coverage can obtained confidence limits calculated arctanh\\operatorname{arctanh}-scale transformed back original correlation scale via back.transform argument. case, estimates far away boundary parameter space, variance stabilizing transform almost impact, confidence limits agrees original symmetric confidence limits.","code":"Cov <- function(x, y, ...) {   est <- mean(x * y)-mean(x)*mean(y)     estimate(       coef = est,       IC = (x - mean(x)) * (y - mean(y)) - est,       ...     ) } with(dw, Cov(x1, x2)) #>  Estimate Std.Err     2.5%  97.5% P-value #>  0.004043 0.04976 -0.09349 0.1016  0.9352 e1 <- lm(cbind(x1, x2, x1 * x2) ~ 1, data = dw) |>   estimate(labels = c(\"Ex1\", \"Ex2\", \"Ex1x2\")) e1 #>        Estimate Std.Err     2.5%   97.5% P-value #> Ex1    0.038089 0.04842 -0.05681 0.13298  0.4315 #> Ex2   -0.037026 0.05187 -0.13869 0.06464  0.4753 #> Ex1x2  0.002633 0.05003 -0.09541 0.10068  0.9580 estimate(e1, function(x) c(x, cov=with(as.list(x), Ex1x2 - Ex2* Ex1))) #>        Estimate Std.Err     2.5%   97.5% P-value #> Ex1    0.038089 0.04842 -0.05681 0.13298  0.4315 #> Ex2   -0.037026 0.05187 -0.13869 0.06464  0.4753 #> Ex1x2  0.002633 0.05003 -0.09541 0.10068  0.9580 #> cov    0.004043 0.04976 -0.09349 0.10158  0.9352 e2 <- with(dw, Cov(x1, x2, labels = \"c\", id = id) +                Cov(x1, x1, labels = \"v1\", id = id) +                Cov(x2, x2, labels = \"v2\", id = id)) rho <- estimate(e2, function(x) list(rho = x[1] / (x[2] * x[3])^.5)) rho #>     Estimate Std.Err     2.5%  97.5% P-value #> rho 0.004025 0.04953 -0.09306 0.1011  0.9352 estimate(rho, atanh, back.transform = tanh) #>     Estimate Std.Err     2.5%  97.5% P-value #> rho 0.004025         -0.09279 0.1008  0.9352"},{"path":"/articles/influencefunction.html","id":"linear-contrasts-and-hypothesis-testing","dir":"Articles","previous_headings":"IF building blocks: transformations and the delta theorem","what":"Linear contrasts and hypothesis testing","title":"The Art of Influence","text":"important special case parameter transformations linear transformations. particular interest may formulated around testing null-hypotheses form H0:𝐁θ=𝐛0\\begin{align*} H_0\\colon\\quad \\mathbf{B}\\theta = \\mathbf{b}_0 \\end{align*} 𝐁∈ℝm×p\\mathbf{B}\\\\mathbb{R}^{m\\times p} matrix estimable contrasts 𝐛0∈ℝm\\mathbf{b}_0\\\\mathbb{R}^{m}. example consider marginal models binary response variables Y1,Y2,Y3,Y4Y_1, Y_2, Y_3, Y_4 linear transformation can specified via f matrix argument instead function object 𝐛0\\mathbf{b}_0 vector (default assumed zero) can specified via null argument testing multiple hypotheses use (𝐁θ̂−𝐛0)⊤(𝐁Σ̂𝐁⊤)−1(𝐁θ̂−𝐛0)∼χrank(B)2(\\mathbf{B}\\widehat{\\theta}-\\mathbf{b}_0)^{\\top} (\\mathbf{B}\\widehat{\\Sigma}\\mathbf{B}^{\\top})^{-1} (\\mathbf{B}\\widehat{\\theta}-\\mathbf{b}_0) \\sim  \\chi^2_{\\operatorname{rank}(B)} null hypothesis Σ̂\\widehat{\\Sigma} estimated variance θ\\theta (.e., vcov(gg)) linear statistics can also specified directly expressions parameter names refer function lava::contr lava::parsedesigns defining contrast matrices. particular useful contrast following considering pairwise comparisons different exposure estimates: conducting multiple tests nominal-level α\\alpha overall type error controlled α\\alpha-level. influence function also allows adjusting multiple comparisons. Let Z1,…,ZpZ_{1},\\ldots,Z_{p} denote ZZ-statistics pp distinct two-sided hypothesis tests assume asymptotically distributed null hypothesis zero-mean Gaussian distribution correlation matrix R.R. Let $ Z_{max} = _{=1,,p} |Z_i|$ family-wise error rate (FWER) null can approximated P(Zmax>z)=1−∫−zz⋯∫−zzϕR(x1,…,xp)dx1⋯dxp P(Z_{max} > z) = 1-\\int_{-z}^{z} \\cdots \\int_{-z}^{z} \\phi_{R}(x_{1},\\ldots,x_{p}) \\,dx_{1}\\cdots\\,dx_{p}  ϕR\\phi_{R} multivariate normal density function mean 0 variance given correlation matrix RR. adjusted pp-values can calculated P(Zmax>Φ−1(1−p/2)) P(Z_{max} > \\Phi^{-1}(1-p/2))  Φ\\Phi standard Gaussian CDF. described (Pipper, Ritz, Bisgaard 2012) joint distribution Z1,…,ZpZ_{1},\\ldots,Z_{p} can estimated IFs. implemented alpha_zmax method always yields powerful test compared Bonferroni adjustments, powerful closed-testing procedure (Marcus, Eric, Gabriel 1976), can generally obtained considering intersection hypotheses. reject H1H_{1} correct α\\alpha-level test intersection hypotheses involving H1H_{1} check rejected α\\alpha-level. adjusted pp-values can obtained maximum pp-value across composite hypothesis tests. Unfortunately, works relatively comparisons number tests grows exponentially.","code":"g <- lapply(   list(y1 ~ a, y2 ~ a, y3 ~ a), #, y4 ~ a+x4),   function(f) glm(f, family = binomial, data = dw) ) gg <- Reduce(merge, g) gg #>               Estimate Std.Err    2.5%    97.5%   P-value #> (Intercept)    -0.1861  0.1442 -0.4688  0.09655 1.969e-01 #> a               1.3239  0.2173  0.8981  1.74978 1.105e-09 #> ─────────────                                             #> (Intercept).1  -0.6168  0.1505 -0.9117 -0.32185 4.152e-05 #> a.1             1.5060  0.2148  1.0849  1.92712 2.385e-12 #> ─────────────                                             #> (Intercept).2  -0.2938  0.2063 -0.6982  0.11064 1.545e-01 #> a.2             1.1047  0.2962  0.5242  1.68515 1.914e-04 B <- cbind(0,1, 0,-1, 0,0) estimate(gg, B) #>             Estimate Std.Err    2.5%  97.5% P-value #> [a] - [a.1]  -0.1821  0.3003 -0.7707 0.4065  0.5443 #>  #>  Null Hypothesis:  #>   [a] - [a.1] = 0 estimate(gg, B, null=1) #>             Estimate Std.Err    2.5%  97.5%   P-value #> [a] - [a.1]  -0.1821  0.3003 -0.7707 0.4065 8.281e-05 #>  #>  Null Hypothesis:  #>   [a] - [a.1] = 1 B <- rbind(cbind(0,1, 0,-1, 0,0),            cbind(0,1, 0,0, 0,-1)) estimate(gg, B) #>             Estimate Std.Err    2.5%  97.5% P-value #> [a] - [a.1]  -0.1821  0.3003 -0.7707 0.4065  0.5443 #> [a] - [a.2]   0.2192  0.3637 -0.4936 0.9321  0.5466 #>  #>  Null Hypothesis:  #>   [a] - [a.1] = 0 #>   [a] - [a.2] = 0  #>   #> chisq = 1.343, df = 2, p-value = 0.5109 estimate(gg, a + a.1, 2*a - a.2, a, null=c(2,1,1)) #>              Estimate Std.Err   2.5% 97.5%  P-value #> [a] + [a.1]     2.830  0.3107 2.2210 3.439 0.007557 #> 2[a] - [a.2]    1.543  0.5208 0.5224 2.564 0.296991 #> [a]             1.324  0.2173 0.8981 1.750 0.135985 #>  #>  Null Hypothesis:  #>   [a] + [a.1] = 2 #>   2[a] - [a.2] = 1 #>   [a] = 1  #>   #> chisq = 7.557, df = 3, p-value = 0.05612 contr(list(1, c(1, 2), c(1, 4)), n = 5) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    0    0    0    0 #> [2,]    1   -1    0    0    0 #> [3,]    1    0    0   -1    0 pairwise.diff(3) #>      [,1] [,2] [,3] #> [1,]    1   -1    0 #> [2,]    1    0   -1 #> [3,]    0    1   -1 estimate(gg, pairwise.diff(3), null=c(1,1,1), use=c(2,4,6)) #>               Estimate Std.Err    2.5%  97.5%   P-value #> [a] - [a.1]    -0.1821  0.3003 -0.7707 0.4065 8.281e-05 #> [a] - [a.2]     0.2192  0.3637 -0.4936 0.9321 3.182e-02 #> [a.1] - [a.2]   0.4013  0.3506 -0.2858 1.0885 8.773e-02 #>  #>  Null Hypothesis:  #>   [a] - [a.1] = 1 #>   [a] - [a.2] = 1 #>   [a.1] - [a.2] = 1  #>   #> chisq = 11.96, df = 2, p-value = 0.002523 gg0 <- estimate(gg, use=\"^a\", regex=TRUE, null=rep(.8, 3)) alpha_zmax(gg0) #>       Estimate  P-value Adj.P-value #> [a]      1.324 0.015891    0.046870 #> [a.1]    1.506 0.001015    0.003043 #> [a.2]    1.105 0.303571    0.661497 #> attr(,\"adjusted.significance.level\") #> [1] 0.01698 closed_testing(gg0) #> Call: closed_testing(object = gg0) #>  #>     Estimate     adj.p #> a      1.324 1.105e-09 #> a.1    1.506 2.385e-12 #> a.2    1.105 1.914e-04"},{"path":"/articles/influencefunction.html","id":"averaging","dir":"Articles","previous_headings":"IF building blocks: transformations and the delta theorem","what":"Averaging","title":"The Art of Influence","text":"parameters interest expressed averages functions observed data estimated parameters model. asymptotic distribution can cases also derived influence function. Let Z1,…,ZnZ_{1},\\ldots,Z_{n} iid observations, Z1∼P0Z_{1}\\sim P_{0} let Xi⊂ZiX_{}\\subset Z_{}. Assume θ̂\\widehat{\\theta} RAL estimator θ∈Ω⊂ℝp\\theta\\\\Omega\\subset \\mathbb{R}^{p}n(θ̂−θ)=1n∑=1nϕ(Zi;P0)+oP(1).\\sqrt{n}(\\widehat{\\theta}-\\theta) = \\frac{1}{\\sqrt{n}}\\sum_{=1}^{n}\\phi(Z_{}; P_{0}) + o_{P}(1).  Let f:𝒳×Ω→ℝf:\\mathcal{X}\\times\\Omega\\\\mathbb{R} continuous differentiable θ\\thetan{f(X;θ̂)−f(X;θ)}=1n∇θf(X;θ)∑=1nϕ(Zi;P)+oP(1).\\sqrt{n}\\{f(X; \\widehat{\\theta})-f(X; \\theta)\\} = \\frac{1}{\\sqrt{n}}\\nabla_{\\theta}f(X;\\theta)\\sum_{=1}^{n}\\phi(Z_{}; P) + o_{P}(1). Let Ψ=P0f(X;θ)\\Psi = P_{0}f(X;\\theta) Ψ̂=Pnf(X;θ̂)\\widehat{\\Psi} = P_{n} f(X;\\widehat{\\theta}). P0P_{0} PnP_{n} everywhere integrals wrt. XX. easily verified Ψ̂−Ψ=(Pn−P0)(f(X;θ)−Ψ)+P[f(X;θ̂)−f(X;θ)]+(Pn−P0)[f(X;θ̂)−f(X;θ)]\\begin{align*} \\widehat{\\Psi}-\\Psi &= (P_{n}-P_{0})(f(X; \\theta)-\\Psi) + P[f(X;\\widehat{\\theta})-f(X;\\theta)] \\\\ &\\quad + (P_{n}-P_{0})[f(X;\\widehat{\\theta})-f(X;\\theta)] \\end{align*} Lemma 19.24 (Vaart 1998) follows last term n(Pn−P0)[f(X;θ̂)−f(X;θ)]=oP(1)\\begin{align*} \\sqrt{n}(P_{n}-P_{0})[f(X;\\widehat{\\theta})-f(X;\\theta)] = o_{P}(1) \\end{align*} ff example Lipschitz generally f(X;θ)f(X;\\theta) forms P0P_{0}-Donsker class. therefore follows n(Ψ̂−Ψ)=nPn(f(X;θ)−Ψ)+1nP∇θf(X;θ)∑=1nϕ(Zi;P0)+oP(1)=1n∑=1n{f(X;θ)−Ψ}+1nP∇θf(X;θ)∑=1nϕ(Zi,P0)+oP(1)\\begin{align*} \\sqrt{n}(\\widehat{\\Psi}-\\Psi) &= \\sqrt{n}P_{n}(f(X; \\theta)-\\Psi) + \\frac{1}{\\sqrt{n}}P\\nabla_{\\theta}f(X;\\theta)\\sum_{=1}^{n}\\phi(Z_{}; P_{0}) + o_{P}(1) \\\\ &= \\frac{1}{\\sqrt{n}}\\sum_{=1}^{n}\\{f(X;\\theta)-\\Psi\\} + \\frac{1}{\\sqrt{n}}P\\nabla_{\\theta}f(X;\\theta)\\sum_{=1}^{n}\\phi(Z_{}, P_{0}) + o_{P}(1) \\end{align*} Hence Ψ̂\\widehat{\\Psi} becomes IC(Z;P0)=f(X;θ)−Ψ+[P0∇θf(X;θ)]ϕ(Z). IC(Z; P_{0}) = f(X;\\theta)-\\Psi + [P_{0}\\nabla_{\\theta}f(X;\\theta)]\\phi(Z). Turning back example can estimate logistic regression model logit(E{Y1|,X1,W})=β0+βaA+βx1X1+βwW\\operatorname{logit}(E\\{Y_1 | ,X_1,W\\}) = \\beta_0 + \\beta_a + \\beta_{x_1} X_1 + \\beta_w W, want estimate target parameter θ(P)=𝔼P[E(Y∣=1,X1,W)]. \\theta(P) = \\mathbb{E}_{P}[E(Y\\mid =1, X_{1}, W)].  need first estimate model define function gives predicted probability ℙ(Y=1∣,=,X1,W)\\mathbb{P}(Y=1\\mid,=,X_{1},W) observed values X1,WX_1,W treatment variable AA kept fixed value 11 target parameter can now estimated syntax","code":"g <- glm(y1 ~ a + x1 + w, data=dw, family=binomial) pr <- function(p, data, ...)   with(data, expit(p[1] + p[\"a\"] + p[\"x1\"]*x1 + p[\"w\"]*w)) pr(coef(g), dw) |> head() #> [1] 0.8307 0.9651 0.4234 0.9337 0.7669 0.4834 id <- foldr(NROW(dw), 100, list=FALSE) ea <- estimate(g, pr, average=TRUE, id=id) ea #>     Estimate Std.Err   2.5%  97.5%    P-value #> val   0.7006 0.02966 0.6425 0.7587 2.561e-123 IC(ea) |> head() #>        val #> 1 -0.41685 #> 2 -0.22444 #> 3  0.34679 #> 4  0.03143 #> 5  0.02478 #> 6 -0.61997"},{"path":"/articles/influencefunction.html","id":"sessioninfo","dir":"Articles","previous_headings":"","what":"SessionInfo","title":"The Art of Influence","text":"","code":"sessionInfo() #> R version 4.5.1 (2025-06-13) #> Platform: x86_64-pc-linux-gnu #> Running under: Ubuntu 24.04.3 LTS #>  #> Matrix products: default #> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  #> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 #>  #> locale: #>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        #>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    #>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           #> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    #>  #> time zone: UTC #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] survival_3.8-3 lava_1.8.2     #>  #> loaded via a namespace (and not attached): #>  [1] tidyr_1.3.1         sass_0.4.10         future_1.67.0       #>  [4] generics_0.1.4      lattice_0.22-7      listenv_0.9.1       #>  [7] digest_0.6.37       magrittr_2.0.4      evaluate_1.0.5      #> [10] grid_4.5.1          mvtnorm_1.3-3       fastmap_1.2.0       #> [13] jsonlite_2.0.0      Matrix_1.7-3        backports_1.5.0     #> [16] purrr_1.1.0         codetools_0.2-20    numDeriv_2016.8-1.1 #> [19] textshaping_1.0.4   jquerylib_0.1.4     cli_3.6.5           #> [22] rlang_1.1.6         mets_1.3.8          parallelly_1.45.1   #> [25] future.apply_1.20.0 splines_4.5.1       geepack_1.3.13      #> [28] cachem_1.1.0        yaml_2.3.10         tools_4.5.1         #> [31] parallel_4.5.1      dplyr_1.1.4         globals_0.18.0      #> [34] broom_1.0.10        vctrs_0.6.5         R6_2.6.1            #> [37] lifecycle_1.0.4     fs_1.6.6            htmlwidgets_1.6.4   #> [40] MASS_7.3-65         ragg_1.5.0          pkgconfig_2.0.3     #> [43] desc_1.4.3          timereg_2.0.7       pkgdown_2.1.3       #> [46] bslib_0.9.0         pillar_1.11.1       glue_1.8.0          #> [49] Rcpp_1.1.0          systemfonts_1.3.1   tidyselect_1.2.1    #> [52] xfun_0.53           tibble_3.3.0        knitr_1.50          #> [55] htmltools_0.5.8.1   rmarkdown_2.30      compiler_4.5.1"},{"path":[]},{"path":"/articles/nonlinear.html","id":"estimation","dir":"Articles","previous_headings":"","what":"Estimation","title":"Non-linear latent variable models and error-in-variable models","text":"estimate parameters using two-stage estimator described (Klaus Kähler Holst Budtz-Jørgensen 2020), first step now specify measurement models Next, specify quadratic relationship two latent variables model can estimated using two-stage estimator see clear statistically significant effect second order term (eta2~eta1_2). comparison can also estimate full MLE linear model: Next, calculate predictions quadratic model using estimated parameter coefficients 𝔼θ̂2(η2∣η1,Z=0), \\mathbb{E}_{\\widehat{\\theta}_{2}}(\\eta_{2} \\mid \\eta_{1}, Z=0), obtain potential better fit next proceed natural cubic spline Confidence limits can obtained via Delta method using estimate method: fitted function can obtained following code:","code":"m1 <- lvm(x1+x2+x3 ~ eta1, eta1 ~ z, latent=~eta1) m2 <- lvm(y1+y2+y3 ~ eta2, eta2 ~ z, latent=~eta2) nonlinear(m2, type=\"quadratic\") <- eta2 ~ eta1 e1 <- twostage(m1, m2, data=d) e1 #>                     Estimate Std. Error  Z-value   P-value #> Measurements:                                              #>    y2~eta2           0.97686    0.03451 28.30873    <1e-12 #>    y3~eta2           1.04485    0.03485 29.98162    <1e-12 #> Regressions:                                               #>    eta2~z            0.88513    0.20778  4.25996 2.045e-05 #>    eta2~eta1_1       1.14072    0.17410  6.55194 5.679e-11 #>    eta2~eta1_2      -0.45055    0.07161 -6.29195 3.135e-10 #> Intercepts:                                                #>    y2               -0.12198    0.10915 -1.11749    0.2638 #>    y3               -0.09879    0.10545 -0.93680    0.3489 #>    eta2              0.67814    0.17363  3.90567 9.396e-05 #> Residual Variances:                                        #>    y1                1.30730    0.17743  7.36790           #>    y2                1.11056    0.14478  7.67064           #>    y3                0.80961    0.13203  6.13219           #>    eta2              2.08483    0.28986  7.19258 e0 <- estimate(regression(m1%++%m2, eta2~eta1), d) estimate(e0,keep=\"^eta2~[a-z]\",regex=TRUE) ## Extract coef. matching reg.ex. #>           Estimate Std.Err    2.5% 97.5%   P-value #> eta2~eta1   1.4140  0.2261 0.97083 1.857 4.014e-10 #> eta2~z      0.6374  0.2778 0.09291 1.182 2.177e-02 newd <- expand.grid(eta1=seq(-4, 4, by=0.1), z=0) pred1 <- predict(e1, newdata=newd, x=TRUE) head(pred1) #>              y1         y2         y3       eta2 #> [1,] -11.093569 -10.958869 -11.689950 -11.093569 #> [2,] -10.623561 -10.499736 -11.198861 -10.623561 #> [3,] -10.162565 -10.049406 -10.717187 -10.162565 #> [4,]  -9.710579  -9.607878 -10.244928  -9.710579 #> [5,]  -9.267605  -9.175153  -9.782084  -9.267605 #> [6,]  -8.833641  -8.751230  -9.328656  -8.833641 kn <- seq(-3,3,length.out=5) nonlinear(m2, type=\"spline\", knots=kn) <- eta2 ~ eta1 e2 <- twostage(m1, m2, data=d) e2 #>                     Estimate Std. Error  Z-value   P-value #> Measurements:                                              #>    y2~eta2           0.97752    0.03453 28.31279    <1e-12 #>    y3~eta2           1.04508    0.03487 29.97132    <1e-12 #> Regressions:                                               #>    eta2~z            0.86729    0.20272  4.27816 1.884e-05 #>    eta2~eta1_1       2.86231    0.67275  4.25464 2.094e-05 #>    eta2~eta1_2       0.00344    0.10097  0.03409    0.9728 #>    eta2~eta1_3      -0.26270    0.29398 -0.89362    0.3715 #>    eta2~eta1_4       0.50778    0.35189  1.44301     0.149 #> Intercepts:                                                #>    y2               -0.12185    0.10922 -1.11563    0.2646 #>    y3               -0.09874    0.10545 -0.93638    0.3491 #>    eta2              1.83814    1.66430  1.10445    0.2694 #> Residual Variances:                                        #>    y1                1.31286    0.17750  7.39636           #>    y2                1.10412    0.14455  7.63858           #>    y3                0.81124    0.13184  6.15312           #>    eta2              1.99404    0.26939  7.40217 p <- cbind(eta1=newd$eta1,       estimate(e2,f=function(p) predict(e2,p=p,newdata=newd))$coefmat) head(p) #>    eta1  Estimate   Std.Err      2.5%     97.5%      P-value #> p1 -4.0 -9.611119 1.2647437 -12.08997 -7.132266 2.978251e-14 #> p2 -3.9 -9.324887 1.2051236 -11.68689 -6.962889 1.012296e-14 #> p3 -3.8 -9.038656 1.1463510 -11.28546 -6.791849 3.152439e-15 #> p4 -3.7 -8.752425 1.0885635 -10.88597 -6.618879 8.958702e-16 #> p5 -3.6 -8.466193 1.0319265 -10.48873 -6.443654 2.320153e-16 #> p6 -3.5 -8.179962 0.9766401 -10.09414 -6.265782 5.493600e-17 plot(I(eta2-z) ~ eta1, data=d, col=Col(\"black\",0.5), pch=16,      xlab=expression(eta[1]), ylab=expression(eta[2]), xlim=c(-4,4)) lines(Estimate ~ eta1, data=as.data.frame(p), col=\"darkblue\", lwd=5) confband(p[,1], lower=p[,4], upper=p[,5], polygon=TRUE,      border=NA, col=Col(\"darkblue\",0.2))"},{"path":"/articles/nonlinear.html","id":"cross-validation","dir":"Articles","previous_headings":"","what":"Cross-validation","title":"Non-linear latent variable models and error-in-variable models","text":"formal comparison different models can obtained cross-validation. specify linear, quadratic cubic spline models 4 9 degrees freedom. assess model fit average RMSE estimated 5-fold cross-validation repeated two times RMSE favour splines model 4 degrees freedom:  convenience, function twostageCV can used cross-validation (also choosing mixture distribution via ``nmix`` argument, see section ). example, applies cross-validation (just 2 folds simplicity) select best splines degrees freedom varying 1-3 (linear model automatically included)","code":"m2a <- nonlinear(m2, type=\"linear\", eta2~eta1) m2b <- nonlinear(m2, type=\"quadratic\", eta2~eta1) kn1 <- seq(-3,3,length.out=5) kn2 <- seq(-3,3,length.out=8) m2c <- nonlinear(m2, type=\"spline\", knots=kn1, eta2~eta1) m2d <- nonlinear(m2, type=\"spline\", knots=kn2, eta2~eta1) ## Scale models in stage 2 to allow for a fair RMSE comparison d0 <- d for (i in endogenous(m2))     d0[,i] <- scale(d0[,i],center=TRUE,scale=TRUE) ## Repeated 5-fold cross-validation: ff <- lapply(list(linear=m2a,quadratic=m2b,spline4=m2c,spline6=m2d),         function(m) function(data,...) twostage(m1,m,data=data,stderr=FALSE,control=list(start=coef(e0),contrain=TRUE))) fit.cv <- lava:::cv(ff,data=d,K=5,rep=2,mc.cores=parallel::detectCores(),seed=1) summary(fit.cv) #>       Length Class  Mode      #> cv    40     -none- numeric   #> call   7     -none- call      #> names  4     -none- character #> rep    1     -none- numeric   #> folds  1     -none- numeric fit <- lapply(list(m2a,m2b,m2c,m2d),          function(x) {          e <- twostage(m1,x,data=d)          pr <- cbind(eta1=newd$eta1,predict(e,newdata=newd$eta1,x=TRUE))          return(list(estimate=e,predict=as.data.frame(pr)))          })  plot(I(eta2-z) ~ eta1, data=d, col=Col(\"black\",0.5), pch=16,      xlab=expression(eta[1]), ylab=expression(eta[2]), xlim=c(-4,4)) col <- c(\"orange\",\"darkred\",\"darkgreen\",\"darkblue\") lty <- c(3,4,1,5) for (i in seq_along(fit)) {     with(fit[[i]]$pr, lines(eta2 ~ eta1, col=col[i], lwd=4, lty=lty[i])) } legend(\"bottomright\",       c(\"linear\",\"quadratic\",\"spline(df=4)\",\"spline(df=6)\"),       col=col, lty=lty, lwd=3) selmod <- twostageCV(m1, m2, data=d, df=2:4, nmix=1:2,         nfolds=2, rep=1, mc.cores=parallel::detectCores()) selmod #>        Length Class               Mode    #> model1 11     summary.lvm.mixture list    #> AIC1    2     -none-              numeric #> cv      4     -none-              numeric #> knots   4     -none-              list    #> model2 11     summary.lvmfit      list"},{"path":"/articles/nonlinear.html","id":"specification-of-general-functional-forms","dir":"Articles","previous_headings":"","what":"Specification of general functional forms","title":"Non-linear latent variable models and error-in-variable models","text":"Next, show specify general functional relation multiple different latent exogenous variables. achieved via predict.fun argument. illustrate include interactions latent variable η1\\eta_{1} dichotomized version covariate zz formal test show statistically significant effect interaction","code":"d$g <- (d$z<0)*1 ## Group variable mm1 <- regression(m1, ~g)  # Add grouping variable as exogenous variable (effect specified via 'predict.fun') mm2 <- regression(m2, eta2~ u1+u2+u1:g+u2:g+z) pred <- function(mu,var,data,...) {     cbind(\"u1\"=mu[,1],\"u2\"=mu[,1]^2+var[1],       \"u1:g\"=mu[,1]*data[,\"g\"],\"u2:g\"=(mu[,1]^2+var[1])*data[,\"g\"]) } ee1 <- twostage(mm1, model2=mm2, data=d, predict.fun=pred) estimate(ee1,keep=\"eta2~u\",regex=TRUE) #>           Estimate Std.Err    2.5%   97.5%  P-value #> eta2~u1     0.9891  0.3020  0.3971  1.5810 0.001057 #> eta2~u2    -0.3962  0.1443 -0.6791 -0.1133 0.006047 #> eta2~u1:g   0.4487  0.4620 -0.4568  1.3543 0.331409 #> eta2~u2:g   0.0441  0.2166 -0.3804  0.4686 0.838667 summary(estimate(ee1,keep=\"(:g)\", regex=TRUE)) #> Call: estimate.default(x = ee1, keep = \"(:g)\", regex = TRUE) #> ──────────────────────────────────────────────────────────────────────────────── #>           Estimate Std.Err    2.5%  97.5% P-value #> eta2~u1:g   0.4487  0.4620 -0.4568 1.3543  0.3314 #> eta2~u2:g   0.0441  0.2166 -0.3804 0.4686  0.8387 #>  #>  Null Hypothesis:  #>   [eta2~u1:g] = 0 #>   [eta2~u2:g] = 0  #>   #> chisq = 0.9441, df = 2, p-value = 0.6237"},{"path":"/articles/nonlinear.html","id":"mixture-models","dir":"Articles","previous_headings":"","what":"Mixture models","title":"Non-linear latent variable models and error-in-variable models","text":"Lastly, demonstrate distributional assumptions stage 1 model can relaxed letting conditional distribution latent variable given covariates follow Gaussian mixture distribution. following code explictly defines parameter constraints model setting intercept first indicator variable, x1x_{1}, zero factor loading parameter variable one. mixture model may estimated using mixture method (note, requires mets package installed), Parameter names shared across different mixture components given list constrained identical mixture model. Thus, intercept η1\\eta_{1} allowed vary mixtures. decrease risk using local maximizer likelihood can rerun estimation different random starting values Measured AIC slight improvement model fit using mixture model spline model may estimated two-stage method example results similar Gaussian model:","code":"m1 <- baptize(m1)  ## Label all parameters intercept(m1, ~x1+eta1) <- list(0,NA) ## Set intercept of x1 to zero. Remove the label of eta1 regression(m1,x1~eta1) <- 1 ## Factor loading fixed to 1 set.seed(1) em0 <- mixture(m1, k=2, data=d) em0 <- NULL ll <- c() for (i in 1:5) {     set.seed(i)     em <- mixture(m1, k=2, data=d, control=list(trace=0))     ll <- c(ll,logLik(em))     if (is.null(em0) || logLik(em0)<tail(ll,1))     em0 <- em } summary(em0) #> Cluster 1 (n=162, Prior=0.776): #> -------------------------------------------------- #>                     Estimate Std. Error Z value  Pr(>|z|) #> Measurements:                                             #>    x1~eta1           1.00000                              #>    x2~eta1           0.99581  0.07940   12.54099   <1e-12 #>    x3~eta1           1.06345  0.08436   12.60541   <1e-12 #> Regressions:                                              #>    eta1~z            1.06675  0.08527   12.50989   <1e-12 #> Intercepts:                                               #>    x1                0.00000                              #>    x2                0.03845  0.09890    0.38883 0.6974   #>    x3               -0.02549  0.10333   -0.24667 0.8052   #>    eta1              0.20925  0.13162    1.58984 0.1119   #> Residual Variances:                                       #>    x1                0.98540  0.13316    7.40025          #>    x2                0.97180  0.13156    7.38695          #>    x3                1.01316  0.14294    7.08815          #>    eta1              0.29046  0.11129    2.61004          #>  #> Cluster 2 (n=38, Prior=0.224): #> -------------------------------------------------- #>                     Estimate Std. Error Z value  Pr(>|z|)  #> Measurements:                                              #>    x1~eta1           1.00000                               #>    x2~eta1           0.99581  0.07940   12.54099   <1e-12  #>    x3~eta1           1.06345  0.08436   12.60541   <1e-12  #> Regressions:                                               #>    eta1~z            1.06675  0.08527   12.50989   <1e-12  #> Intercepts:                                                #>    x1                0.00000                               #>    x2                0.03845  0.09890    0.38883 0.6974    #>    x3               -0.02549  0.10333   -0.24667 0.8052    #>    eta1             -1.44290  0.25867   -5.57812 2.431e-08 #> Residual Variances:                                        #>    x1                0.98540  0.13316    7.40025           #>    x2                0.97180  0.13156    7.38695           #>    x3                1.01316  0.14294    7.08815           #>    eta1              0.29046  0.11129    2.61004           #> -------------------------------------------------- #> AIC= 1958.803  #> ||score||^2= 8.81839e-06 e0 <- estimate(m1,data=d) AIC(e0,em0) #>     df      AIC #> e0  10 1961.839 #> em0 12 1958.803 em2 <- twostage(em0,m2,data=d) em2 #>                     Estimate Std. Error  Z-value   P-value #> Measurements:                                              #>    y2~eta2           0.97823    0.03464 28.23707    <1e-12 #>    y3~eta2           1.04530    0.03480 30.04033    <1e-12 #> Regressions:                                               #>    eta2~z            1.02884    0.22333  4.60676  4.09e-06 #>    eta2~eta1_1       2.80413    0.65543  4.27831 1.883e-05 #>    eta2~eta1_2      -0.02249    0.09997 -0.22496     0.822 #>    eta2~eta1_3      -0.17333    0.28932 -0.59909    0.5491 #>    eta2~eta1_4       0.38672    0.33978  1.13816    0.2551 #> Intercepts:                                                #>    y2               -0.12171    0.10925 -1.11401    0.2653 #>    y3               -0.09870    0.10546 -0.93588    0.3493 #>    eta2              2.12372    1.66609  1.27467    0.2024 #> Residual Variances:                                        #>    y1                1.31872    0.17654  7.46974           #>    y2                1.09690    0.14502  7.56379           #>    y3                0.81345    0.13259  6.13511           #>    eta2              1.99590    0.28291  7.05501 plot(I(eta2-z) ~ eta1, data=d, col=Col(\"black\",0.5), pch=16,      xlab=expression(eta[1]), ylab=expression(eta[2]))  lines(Estimate ~ eta1, data=as.data.frame(p), col=\"darkblue\", lwd=5) confband(p[,1], lower=p[,4], upper=p[,5], polygon=TRUE,      border=NA, col=Col(\"darkblue\",0.2))  pm <- cbind(eta1=newd$eta1,         estimate(em2, f=function(p) predict(e2,p=p,newdata=newd))$coefmat) lines(Estimate ~ eta1, data=as.data.frame(pm), col=\"darkred\", lwd=5) confband(pm[,1], lower=pm[,4], upper=pm[,5], polygon=TRUE,      border=NA, col=Col(\"darkred\",0.2)) legend(\"bottomright\", c(\"Gaussian\",\"Mixture\"),        col=c(\"darkblue\",\"darkred\"), lwd=2, bty=\"n\")"},{"path":"/articles/nonlinear.html","id":"sessioninfo","dir":"Articles","previous_headings":"","what":"SessionInfo","title":"Non-linear latent variable models and error-in-variable models","text":"","code":"sessionInfo() #> R version 4.5.1 (2025-06-13) #> Platform: x86_64-pc-linux-gnu #> Running under: Ubuntu 24.04.3 LTS #>  #> Matrix products: default #> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  #> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 #>  #> locale: #>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        #>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    #>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           #> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    #>  #> time zone: UTC #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] lava_1.8.2 #>  #> loaded via a namespace (and not attached): #>  [1] Matrix_1.7-3        future.apply_1.20.0 jsonlite_2.0.0      #>  [4] compiler_4.5.1      Rcpp_1.1.0          parallel_4.5.1      #>  [7] Rgraphviz_2.52.0    jquerylib_0.1.4     globals_0.18.0      #> [10] splines_4.5.1       systemfonts_1.3.1   textshaping_1.0.4   #> [13] yaml_2.3.10         fastmap_1.2.0       lattice_0.22-7      #> [16] R6_2.6.1            generics_0.1.4      knitr_1.50          #> [19] BiocGenerics_0.54.1 htmlwidgets_1.6.4   graph_1.86.0        #> [22] future_1.67.0       desc_1.4.3          bslib_0.9.0         #> [25] rlang_1.1.6         cachem_1.1.0        xfun_0.53           #> [28] fs_1.6.6            sass_0.4.10         cli_3.6.5           #> [31] pkgdown_2.1.3       digest_0.6.37       grid_4.5.1          #> [34] mvtnorm_1.3-3       lifecycle_1.0.4     timereg_2.0.7       #> [37] evaluate_1.0.5      numDeriv_2016.8-1.1 listenv_0.9.1       #> [40] codetools_0.2-20    ragg_1.5.0          survival_3.8-3      #> [43] stats4_4.5.1        parallelly_1.45.1   rmarkdown_2.30      #> [46] mets_1.3.8          tools_4.5.1         htmltools_0.5.8.1"},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Klaus K. Holst. Author, maintainer. Brice Ozenne. Contributor. Thomas Gerds. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Klaus K. Holst Esben Budtz-Joergensen (2013). Linear Latent Variable Models: lava-package. Computational Statistics, 28 (4), pp. 1385-1452. doi: 10.1007/s00180-012-0344-y. Klaus K. Holst Esben Budtz-Joergensen (2020). two-stage estimation procedure non-linear structural equation models. Biostatistics, 21 (4), pp. 676-691. doi: 10.1093/biostatistics/kxy082.","code":"@Article{,   title = {Linear Latent Variable Models: The lava-package},   author = {Klaus K. Holst and Esben Budtz-Joergensen},   year = {2013},   volume = {28},   number = {4},   pages = {1385-1452},   journal = {Computational Statistics},   doi = {10.1007/s00180-012-0344-y}, } @Article{,   title = {A two-stage estimation procedure for non-linear structural equation models},   author = {Klaus K. Holst and Esben Budtz-Joergensen},   year = {2020},   volume = {21},   number = {4},   pages = {676-691},   journal = {Biostatistics},   doi = {10.1093/biostatistics/kxy082}, }"},{"path":"/index.html","id":"latent-variable-models-lava-","dir":"","previous_headings":"","what":"Latent Variable Models","title":"Latent Variable Models","text":"general implementation Structural Equation Models latent variables (MLE, 2SLS, composite likelihood estimators) continuous, censored, ordinal outcomes (Holst Budtz-Joergensen (2013) <10.1007/s00180-012-0344-y>). Mixture latent variable models non-linear latent variable models (Holst Budtz-Joergensen (2020) <10.1093/biostatistics/kxy082>). package also provides methods graph exploration (d-separation, back-door criterion), simulation general non-linear latent variable models, estimation influence functions broad range statistical models.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Latent Variable Models","text":"graphical capabilities Rgraphviz package needed (first install BiocManager package) igraph visNetwork packages development version lava may also installed directly github:","code":"install.packages(\"lava\", dependencies=TRUE) library(\"lava\") demo(\"lava\") # install.packages(\"BiocManager\") BiocManager::install(\"Rgraphviz\") install.packages(\"igraph\") install.packages(\"visNetwork\") # install.packages(\"remotes\") remotes::install_github(\"kkholst/lava\")"},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Latent Variable Models","text":"cite lava package please use one following references Klaus K. Holst Esben Budtz-Joergensen (2013). Linear Latent Variable Models: lava-package. Computational Statistics 28 (4), pp 1385-1453. http://dx.doi.org/10.1007/s00180-012-0344-y Klaus K. Holst Esben Budtz-Jørgensen (2020). two-stage estimation procedure non-linear structural equation models. Biostatistics 21 (4), pp 676-691. http://dx.doi.org/10.1093/biostatistics/kxy082","code":"@article{lava,   title = {Linear Latent Variable Models: The lava-package},   author = {Klaus Kähler Holst and Esben Budtz-Jørgensen},   year = {2013},   volume = {28},   number = {4},   pages = {1385-1452},   journal = {Computational Statistics},   doi = {10.1007/s00180-012-0344-y} } @article{lava_nlin,   title = {A two-stage estimation procedure for non-linear structural equation models},   author = {Klaus Kähler Holst and Esben Budtz-Jørgensen},   journal = {Biostatistics},   year = {2020},   volume = {21},   number = {4},   pages = {676-691},   doi = {10.1093/biostatistics/kxy082}, }"},{"path":[]},{"path":"/index.html","id":"structural-equation-model","dir":"","previous_headings":"Examples","what":"Structural Equation Model","title":"Latent Variable Models","text":"Specify structural equation models two factors  Simulation Estimation","code":"m <- lvm() regression(m) <- y1 + y2 + y3 ~ eta1 regression(m) <- z1 + z2 + z3 ~ eta2 latent(m) <- ~ eta1 + eta2 regression(m) <- eta2 ~ eta1 + x regression(m) <- eta1 ~ x  labels(m) <- c(eta1=expression(eta[1]), eta2=expression(eta[2])) plot(m) d <- sim(m, 100, seed=1) e <- estimate(m, d) e #>                     Estimate Std. Error  Z-value   P-value #> Measurements:                                              #>    y2~eta1           0.95462    0.08083 11.80993    <1e-12 #>    y3~eta1           0.98476    0.08922 11.03722    <1e-12 #>     z2~eta2          0.97038    0.05368 18.07714    <1e-12 #>     z3~eta2          0.95608    0.05643 16.94182    <1e-12 #> Regressions:                                               #>    eta1~x            1.24587    0.11486 10.84694    <1e-12 #>     eta2~eta1        0.95608    0.18008  5.30910 1.102e-07 #>     eta2~x           1.11495    0.25228  4.41951 9.893e-06 #> Intercepts:                                                #>    y2               -0.13896    0.12458 -1.11537    0.2647 #>    y3               -0.07661    0.13869 -0.55241    0.5807 #>    eta1              0.15801    0.12780  1.23644    0.2163 #>    z2               -0.00441    0.14858 -0.02969    0.9763 #>    z3               -0.15900    0.15731 -1.01076    0.3121 #>    eta2             -0.14143    0.18380 -0.76949    0.4416 #> Residual Variances:                                        #>    y1                0.69684    0.14858  4.69004           #>    y2                0.89804    0.16630  5.40026           #>    y3                1.22456    0.21182  5.78109           #>    eta1              0.93620    0.19623  4.77084           #>    z1                1.41422    0.26259  5.38570           #>    z2                0.87569    0.19463  4.49934           #>    z3                1.18155    0.22640  5.21883           #>    eta2              1.24430    0.28992  4.29195"},{"path":"/index.html","id":"model-assessment","dir":"","previous_headings":"Examples","what":"Model assessment","title":"Latent Variable Models","text":"Assessing goodness--fit, linearity eta2 eta1 (requires gof package)","code":"# install.packages(\"gof\", repos=\"https://kkholst.github.io/r_repo/\") library(\"gof\") set.seed(1) g <- cumres(e, eta2 ~ eta1) plot(g)"},{"path":"/index.html","id":"non-linear-measurement-error-model","dir":"","previous_headings":"Examples","what":"Non-linear measurement error model","title":"Latent Variable Models","text":"Simulate non-linear model Stage 1: Stage 2","code":"m <- lvm(y1 + y2 + y3 ~ u, u ~ x) transform(m,u2 ~ u) <- function(x) x^2 regression(m) <- z~u2+u  d <- sim(m,200,p=c(\"z\"=-1, \"z~u2\"=-0.5), seed=1) m1 <- lvm(c(y1[0:s], y2[0:s], y3[0:s]) ~ 1*u, u ~ x) latent(m1) <- ~ u (e1 <- estimate(m1, d)) #>                     Estimate Std. Error  Z-value  P-value #> Regressions:                                              #>    u~x               1.06998    0.08208 13.03542   <1e-12 #> Intercepts:                                               #>    u                -0.08871    0.08753 -1.01344   0.3108 #> Residual Variances:                                       #>    y1                1.00054    0.07075 14.14214          #>    u                 1.19873    0.15503  7.73233 pp <- function(mu,var,data,...) cbind(u=mu[,\"u\"], u2=mu[,\"u\"]^2+var[\"u\",\"u\"]) (e <- measurement.error(e1, z~1+x, data=d, predictfun=pp)) #>             Estimate Std.Err    2.5%   97.5%   P-value #> (Intercept)  -1.1181 0.13795 -1.3885 -0.8477 5.273e-16 #> x            -0.0537 0.13213 -0.3127  0.2053 6.844e-01 #> u             1.0039 0.11504  0.7785  1.2294 2.609e-18 #> u2           -0.4718 0.05213 -0.5740 -0.3697 1.410e-19 f <- function(p) p[1]+p[\"u\"]*u+p[\"u2\"]*u^2 u <- seq(-1, 1, length.out=100) plot(e, f, data=data.frame(u))"},{"path":"/index.html","id":"simulation","dir":"","previous_headings":"Examples","what":"Simulation","title":"Latent Variable Models","text":"Studying small-sample properties mediation analysis  Simulate model estimate indirect effects Add additional simulations visualize results","code":"m <- lvm(y~x, c~1) regression(m) <- y+x ~ z eventTime(m) <- t~min(y=1, c=0) transform(m,S~t+status) <- function(x) survival::Surv(x[,1],x[,2]) plot(m) onerun <- function(...) {     d <- sim(m, 100)     m0 <- lvm(S~x+z, x~z)     e <- estimate(m0, d, estimator=\"glm\")     vec(summary(effects(e, S~z))$coef[,1:2]) } val <- sim(onerun, 100) summary(val, estimate=1:4, se=5:8, short=TRUE) #> 100 replications                 Time: 3.667s #>  #>         Total.Estimate Direct.Estimate Indirect.Estimate S~x~z.Estimate #> Mean           1.97292         0.96537           1.00755        1.00755 #> SD             0.16900         0.18782           0.15924        0.15924 #> SE             0.18665         0.18090           0.16431        0.16431 #> SE/SD          1.10446         0.96315           1.03183        1.03183 #>                                                                         #> Min            1.47243         0.54497           0.54554        0.54554 #> 2.5%           1.63496         0.61228           0.64914        0.64914 #> 50%            1.95574         0.97154           0.99120        0.99120 #> 97.5%          2.27887         1.32443           1.27807        1.27807 #> Max            2.45746         1.49491           1.33446        1.33446 #>                                                                         #> Missing        0.00000         0.00000           0.00000        0.00000 val <- sim(val,500) ## Add 500 simulations plot(val, estimate=c(\"Total.Estimate\", \"Indirect.Estimate\"),      true=c(2, 1), se=c(\"Total.Std.Err\", \"Indirect.Std.Err\"),      scatter.plot=TRUE)"},{"path":"/reference/By.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a Function to a Data Frame Split by Factors — By","title":"Apply a Function to a Data Frame Split by Factors — By","text":"Apply Function Data Frame Split Factors","code":""},{"path":"/reference/By.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a Function to a Data Frame Split by Factors — By","text":"","code":"By(x, INDICES, FUN, COLUMNS, array = FALSE, ...)"},{"path":"/reference/By.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a Function to a Data Frame Split by Factors — By","text":"x Data frame INDICES Indices (vector list indices, vector column names, formula column names) FUN function applied data frame subsets 'data'. COLUMNS (Optional) subset columns x work array TRUE array/matrix always returned ... Additional arguments lower-level functions","code":""},{"path":"/reference/By.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply a Function to a Data Frame Split by Factors — By","text":"Simple wrapper '' function","code":""},{"path":"/reference/By.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Apply a Function to a Data Frame Split by Factors — By","text":"Klaus K. Holst","code":""},{"path":"/reference/By.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a Function to a Data Frame Split by Factors — By","text":"","code":"By(datasets::CO2,~Treatment+Type,colMeans,~conc) #>             Type #> Treatment    Quebec Mississippi #>   nonchilled    435         435 #>   chilled       435         435 By(datasets::CO2,~Treatment+Type,colMeans,~conc+uptake) #> Treatment: nonchilled #> Type: Quebec #>      conc    uptake  #> 435.00000  35.33333  #> ------------------------------------------------------------  #> Treatment: chilled #> Type: Quebec #>      conc    uptake  #> 435.00000  31.75238  #> ------------------------------------------------------------  #> Treatment: nonchilled #> Type: Mississippi #>      conc    uptake  #> 435.00000  25.95238  #> ------------------------------------------------------------  #> Treatment: chilled #> Type: Mississippi #>      conc    uptake  #> 435.00000  15.81429"},{"path":"/reference/Col.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a transparent RGB color — Col","title":"Generate a transparent RGB color — Col","text":"function transforms standard color (e.g. \"red\") transparent RGB-color (.e. alpha-blend<1).","code":""},{"path":"/reference/Col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a transparent RGB color — Col","text":"","code":"Col(col, alpha = 0.2, locate = 0)"},{"path":"/reference/Col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a transparent RGB color — Col","text":"col Color (numeric character) alpha Degree transparency (0,1) locate Choose colour (mouse)","code":""},{"path":"/reference/Col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a transparent RGB color — Col","text":"character vector elements 7 9 characters, `#`  followed red, blue, green optionally alpha values  hexadecimal (rescaling '0 ... 255').","code":""},{"path":"/reference/Col.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a transparent RGB color — Col","text":"works certain graphics devices (Cairo-X11 (x11 R>=2.7), quartz, pdf, ...).","code":""},{"path":"/reference/Col.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate a transparent RGB color — Col","text":"Klaus K. Holst","code":""},{"path":"/reference/Col.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a transparent RGB color — Col","text":"","code":"plot(runif(1000),cex=runif(1000,0,4),col=Col(c(\"darkblue\",\"orange\"),0.5),pch=16)"},{"path":"/reference/Combine.html","id":null,"dir":"Reference","previous_headings":"","what":"Report estimates across different models — Combine","title":"Report estimates across different models — Combine","text":"Report estimates across different models","code":""},{"path":"/reference/Combine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Report estimates across different models — Combine","text":"","code":"Combine(x, ...)"},{"path":"/reference/Combine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Report estimates across different models — Combine","text":"x list model objects ... additional arguments lower-level functions","code":""},{"path":"/reference/Combine.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Report estimates across different models — Combine","text":"Klaus K. Holst","code":""},{"path":"/reference/Combine.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Report estimates across different models — Combine","text":"","code":"data(serotonin) m1 <- lm(cau ~ age*gene1 + age*gene2,data=serotonin) m2 <- lm(cau ~ age + gene1,data=serotonin) m3 <- lm(cau ~ age*gene2,data=serotonin)  Combine(list(A=m1,B=m2,C=m3),fun=function(x)      c(\"_____\"=\"\",R2=\" \"%++%format(summary(x)$r.squared,digits=2))) #>             A                            B                           #> (Intercept)  0.88  [0.85;0.91]   p<0.001  0.89  [0.86;0.91]  p<0.001 #> age          0.02  [-0.01;0.05]  p=0.108 -0.01  [-0.02;0.01] p=0.414 #> gene1       -0.02  [-0.06;0.01]  p=0.228 -0.02  [-0.06;0.01] p=0.219 #> gene2        0     [-0.03;0.04]  p=0.93                              #> age:gene1   -0.04  [-0.07;-0.01] p=0.019                             #> age:gene2   -0.02  [-0.05;0.01]  p=0.218                             #> _____                                                                #> R2           0.039                        0.0083                     #>             C                           #> (Intercept)  0.88  [0.85;0.9]   p<0.001 #> age          0.01  [-0.02;0.03] p=0.549 #> gene1                                   #> gene2        0     [-0.03;0.04] p=0.99  #> age:gene1                               #> age:gene2   -0.03  [-0.06;0.01] p=0.126 #> _____                                   #> R2           0.012"},{"path":"/reference/Expand.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Data Frame from All Combinations of Factors — Expand","title":"Create a Data Frame from All Combinations of Factors — Expand","text":"Create Data Frame Combinations Factors","code":""},{"path":"/reference/Expand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Data Frame from All Combinations of Factors — Expand","text":"","code":"Expand(`_data`, ...)"},{"path":"/reference/Expand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Data Frame from All Combinations of Factors — Expand","text":"_data Data.frame ... vectors, factors list containing ","code":""},{"path":"/reference/Expand.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Data Frame from All Combinations of Factors — Expand","text":"Simple wrapper 'expand.grid' function.  x table data frame returned one row pr individual observation.","code":""},{"path":"/reference/Expand.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create a Data Frame from All Combinations of Factors — Expand","text":"Klaus K. Holst","code":""},{"path":"/reference/Expand.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Data Frame from All Combinations of Factors — Expand","text":"","code":"dd <- Expand(iris, Sepal.Length=2:8, Species=c(\"virginica\",\"setosa\")) summary(dd) #>   Sepal.Length        Species  #>  Min.   :2.00   setosa    :7   #>  1st Qu.:3.25   versicolor:0   #>  Median :5.00   virginica :7   #>  Mean   :5.00                  #>  3rd Qu.:6.75                  #>  Max.   :8.00                   T <- with(warpbreaks, table(wool, tension)) Expand(T) #>     wool tension #> 1      A       L #> 1.1    A       L #> 1.2    A       L #> 1.3    A       L #> 1.4    A       L #> 1.5    A       L #> 1.6    A       L #> 1.7    A       L #> 1.8    A       L #> 2      B       L #> 2.1    B       L #> 2.2    B       L #> 2.3    B       L #> 2.4    B       L #> 2.5    B       L #> 2.6    B       L #> 2.7    B       L #> 2.8    B       L #> 3      A       M #> 3.1    A       M #> 3.2    A       M #> 3.3    A       M #> 3.4    A       M #> 3.5    A       M #> 3.6    A       M #> 3.7    A       M #> 3.8    A       M #> 4      B       M #> 4.1    B       M #> 4.2    B       M #> 4.3    B       M #> 4.4    B       M #> 4.5    B       M #> 4.6    B       M #> 4.7    B       M #> 4.8    B       M #> 5      A       H #> 5.1    A       H #> 5.2    A       H #> 5.3    A       H #> 5.4    A       H #> 5.5    A       H #> 5.6    A       H #> 5.7    A       H #> 5.8    A       H #> 6      B       H #> 6.1    B       H #> 6.2    B       H #> 6.3    B       H #> 6.4    B       H #> 6.5    B       H #> 6.6    B       H #> 6.7    B       H #> 6.8    B       H"},{"path":"/reference/Graph.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract graph — Graph","title":"Extract graph — Graph","text":"Extract replace graph object","code":""},{"path":"/reference/Graph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract graph — Graph","text":"","code":"Graph(x, ...)  Graph(x, ...) <- value"},{"path":"/reference/Graph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract graph — Graph","text":"x Model object ... Additional arguments passed low level functions value New graphNEL object","code":""},{"path":[]},{"path":"/reference/Graph.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract graph — Graph","text":"Klaus K. Holst","code":""},{"path":"/reference/Graph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract graph — Graph","text":"","code":"m <- lvm(y~x) Graph(m) #> NULL"},{"path":"/reference/Grep.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds elements in vector or column-names in data.frame/matrix — Grep","title":"Finds elements in vector or column-names in data.frame/matrix — Grep","text":"Pattern matching vector column names data.frame matrix.","code":""},{"path":"/reference/Grep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds elements in vector or column-names in data.frame/matrix — Grep","text":"","code":"Grep(x, pattern, subset = TRUE, ignore.case = TRUE, ...)"},{"path":"/reference/Grep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds elements in vector or column-names in data.frame/matrix — Grep","text":"x vector, matrix data.frame. pattern regular expression search subset TRUE returns subset data.frame/matrix otherwise just matching column names ignore.case Default ignore case ... Additional arguments 'grep'","code":""},{"path":"/reference/Grep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds elements in vector or column-names in data.frame/matrix — Grep","text":"data.frame 2 columns indices first matching names second.","code":""},{"path":[]},{"path":"/reference/Grep.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Finds elements in vector or column-names in data.frame/matrix — Grep","text":"Klaus K. Holst","code":""},{"path":"/reference/Grep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds elements in vector or column-names in data.frame/matrix — Grep","text":"","code":"data(iris) head(Grep(iris,\"(len)|(sp)\")) #>   Sepal.Length Petal.Length Species #> 1          5.1          1.4  setosa #> 2          4.9          1.4  setosa #> 3          4.7          1.3  setosa #> 4          4.6          1.5  setosa #> 5          5.0          1.4  setosa #> 6          5.4          1.7  setosa"},{"path":"/reference/IC.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract i.i.d. decomposition (influence function) from model object — IC","title":"Extract i.i.d. decomposition (influence function) from model object — IC","text":"Extract ..d. decomposition (influence function) model object","code":""},{"path":"/reference/IC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract i.i.d. decomposition (influence function) from model object — IC","text":"","code":"IC(x,...)  # Default S3 method IC(x, bread, id=NULL, folds=0, maxsize=(folds>0)*1e6,...)"},{"path":"/reference/IC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract i.i.d. decomposition (influence function) from model object — IC","text":"x model object ... additional arguments id (optional) id/cluster variable bread (optional) Inverse derivative mean score function folds (optional) Calculate aggregated iid decomposition (0:=disabled) maxsize (optional) Data split groups size 'maxsize' (0:=disabled)","code":""},{"path":"/reference/IC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract i.i.d. decomposition (influence function) from model object — IC","text":"","code":"m <- lvm(y~x+z) distribution(m, ~y+z) <- binomial.lvm(\"logit\") d <- sim(m,1e3) g <- glm(y~x+z,data=d,family=binomial) var_ic(IC(g)) #>               (Intercept)            x            z #> (Intercept)  0.0100840889 0.0001332637 -0.010037414 #> x            0.0001332637 0.0072057194  0.002127181 #> z           -0.0100374144 0.0021271814  0.022159399"},{"path":"/reference/Missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Missing value generator — Missing","title":"Missing value generator — Missing","text":"Missing value generator","code":""},{"path":"/reference/Missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Missing value generator — Missing","text":"","code":"Missing(object, formula, Rformula, missing.name, suffix = \"0\", ...)"},{"path":"/reference/Missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Missing value generator — Missing","text":"object lvm-object. formula right hand side specifies name latent variable always observed. left hand side specifies name new variable equal latent variable missing values.  given string used name latent (full-data) name, observed data name 'missing.data' Rformula Missing data mechanism left hand side specifying name observed data indicator (may also just given character instead formula) missing.name Name observed data variable (used 'formula' given character specifying name full-data variable) suffix missing.name missing, name oberved data variable name full-data variable + suffix ... Passed binomial.lvm.","code":""},{"path":"/reference/Missing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Missing value generator — Missing","text":"lvm object","code":""},{"path":"/reference/Missing.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Missing value generator — Missing","text":"function adds binary variable given lvm model also variable equal original variable binary variable equal zero","code":""},{"path":"/reference/Missing.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Missing value generator — Missing","text":"Thomas . Gerds <tag@biostat.ku.dk>","code":""},{"path":"/reference/Missing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Missing value generator — Missing","text":"","code":"library(lava) set.seed(17) m <- lvm(y0~x01+x02+x03) m <- Missing(m,formula=x1~x01,Rformula=R1~0.3*x02+-0.7*x01,p=0.4) sim(m,10) #>            y0         x01        x02         x03 R1        x1 #> 1  -0.3307614  1.18078924  0.6810276 -1.17756957  0        NA #> 2  -1.0786445  0.64319207 -0.6820334 -0.96016651  0        NA #> 3  -0.5398741  1.29532187 -0.7232567 -0.87895224  0        NA #> 4  -2.5119604  0.18791807  1.6735260 -3.55613648  1 0.1879181 #> 5   0.3507905  1.59120510 -0.5957556 -1.41674984  0        NA #> 6   0.4902836 -0.05517906  1.1598438 -0.44876927  0        NA #> 7   1.1528003  0.83847112  0.1174224 -0.77596771  1 0.8384711 #> 8   1.3032974  0.15937013  0.2592214 -0.83182805  0        NA #> 9   1.3153836  0.62595440  0.3823621  0.05183012  1 0.6259544 #> 10 -0.3278672  0.63358473 -0.7114817 -0.61655131  0        NA   m <- lvm(y~1) m <- Missing(m,\"y\",\"r\") ## same as ## m <- Missing(m,y~1,r~1) sim(m,10) #>              y r          y0 #> 1   0.07419352 1  0.07419352 #> 2   1.75169617 0          NA #> 3  -0.23148744 0          NA #> 4   0.54345248 0          NA #> 5  -0.98900140 0          NA #> 6   0.31553146 1  0.31553146 #> 7   2.44232746 1  2.44232746 #> 8   0.54969286 1  0.54969286 #> 9  -0.02924337 1 -0.02924337 #> 10 -0.83078338 0          NA  ## same as m <- lvm(y~1) Missing(m,\"y\") <- r~x sim(m,10) #>              y r          y0          x #> 1   0.03054575 1  0.03054575  0.5602348 #> 2  -0.78551741 0          NA -1.7924178 #> 3   0.32544056 0          NA -1.5654169 #> 4  -0.88084355 0          NA -3.3203189 #> 5   0.20932594 0          NA  0.1547216 #> 6   0.15103295 1  0.15103295 -0.3646267 #> 7  -0.34347879 0          NA -2.4336839 #> 8   0.90587760 0          NA  0.3364643 #> 9   0.91895485 0          NA -0.6404528 #> 10 -0.55598749 1 -0.55598749  1.8211204  m <- lvm(y~1) m <- Missing(m,\"y\",\"r\",suffix=\".\") ## same as ## m <- Missing(m,\"y\",\"r\",missing.name=\"y.\") ## same as ## m <- Missing(m,y.~y,\"r\") sim(m,10) #>              y r          y. #> 1   0.46345064 1  0.46345064 #> 2   0.88066627 1  0.88066627 #> 3   0.13942195 0          NA #> 4  -0.37505483 0          NA #> 5   0.04253903 0          NA #> 6   0.63388029 1  0.63388029 #> 7  -1.70748846 1 -1.70748846 #> 8   0.01968655 1  0.01968655 #> 9  -0.29879637 0          NA #> 10 -0.44176283 1 -0.44176283"},{"path":"/reference/Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract model — Model","title":"Extract model — Model","text":"Extract replace model object","code":""},{"path":"/reference/Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract model — Model","text":"","code":"Model(x, ...)  Model(x, ...) <- value"},{"path":"/reference/Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract model — Model","text":"x Fitted model ... Additional arguments passed low level functions value New model object (e.g. lvm multigroup)","code":""},{"path":"/reference/Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract model — Model","text":"Returns model object (e.g. lvm multigroup)","code":""},{"path":[]},{"path":"/reference/Model.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract model — Model","text":"Klaus K. Holst","code":""},{"path":"/reference/Model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract model — Model","text":"","code":"m <- lvm(y~x) e <- estimate(m, sim(m,100)) Model(e) #> Latent Variable Model #>                    #>   y ~ x   gaussian #>  #> Exogenous variables:                    #>   x        gaussian #>"},{"path":"/reference/NA2x.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert to/from NA — NA2x","title":"Convert to/from NA — NA2x","text":"Convert vector /NA","code":""},{"path":"/reference/NA2x.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert to/from NA — NA2x","text":"","code":"NA2x(s, x = 0)"},{"path":"/reference/NA2x.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert to/from NA — NA2x","text":"s input vector (arbitrary class) x elements transform NA resp. transform NA .","code":""},{"path":"/reference/NA2x.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert to/from NA — NA2x","text":"vector dimension class s.","code":""},{"path":"/reference/NA2x.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert to/from NA — NA2x","text":"Klaus K. Holst","code":""},{"path":"/reference/NA2x.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert to/from NA — NA2x","text":"","code":"##'  x2NA(1:10, 1:5) #>  [1] NA NA NA NA NA  6  7  8  9 10 NA2x(x2NA(c(1:10),5),5)##' #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"/reference/NR.html","id":null,"dir":"Reference","previous_headings":"","what":"Newton-Raphson method — NR","title":"Newton-Raphson method — NR","text":"Newton-Raphson method","code":""},{"path":"/reference/NR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Newton-Raphson method — NR","text":"","code":"NR(   start,   objective = NULL,   gradient = NULL,   hessian = NULL,   control,   args = NULL,   ... )"},{"path":"/reference/NR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Newton-Raphson method — NR","text":"start Starting value objective Optional objective function (used selecting step length) gradient gradient hessian hessian (NULL numerical derivative used) control optimization arguments (see details) args Optional list arguments parsed objective, gradient hessian ... additional arguments parsed lower level functions","code":""},{"path":"/reference/NR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Newton-Raphson method — NR","text":"control list one following components: trace integer output printed 'trace'th iteration iter.max number iterations stepsize: Step size (default 1) nstepsize: Increase stepsize every nstepsize iteration (stepsize 1) tol: Convergence criterion (gradient) epsilon: threshold used pseudo-inverse backtrack: iteration reduce stepsize unless solution improved according criterion (gradient, armijo, curvature, wolfe)","code":""},{"path":"/reference/NR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Newton-Raphson method — NR","text":"","code":"# Objective function with gradient and hessian as attributes f <- function(z) {    x <- z[1]; y <- z[2]    val <- x^2 + x*y^2 + x + y    structure(val, gradient=c(2*x+y^2+1, 2*y*x+1),              hessian=rbind(c(2,2*y),c(2*y,2*x))) } NR(c(0,0),f) #> $par #> [1] -0.7324166  0.6825751 #>  #> $iterations #> [1] 12 #>  #> $method #> [1] \"NR\" #>  #> $gradient #> [1] 2.451187e-07 7.301897e-07 #>  #> $iH #>            [,1]       [,2] #> [1,] -0.3054540 -0.2849143 #> [2,] -0.2849143  0.4172596 #> attr(,\"det\") #> [1] 1.937717 #> attr(,\"pseudo\") #> [1] FALSE #> attr(,\"minSV\") #> [1] -2.473621 #>   # Parsing arguments to the function and g <- function(x,y) (x*y+1)^2 NR(0, gradient=g, args=list(y=2), control=list(trace=1,tol=1e-20)) #>  #> Iter=0\t;\t #>  \tp= 0  #> [1] \"Numerical Hessian\" #> Iter=1\t; #> \tD= 1  #> \tp= -0.25  #> [1] \"Numerical Hessian\" #> Iter=2\t; #> \tD= 0.25  #> \tp= -0.375  #> [1] \"Numerical Hessian\" #> Iter=3\t; #> \tD= 0.06254  #> \tp= -0.4375  #> [1] \"Numerical Hessian\" #> Iter=4\t; #> \tD= 0.01565  #> \tp= -0.4687  #> [1] \"Numerical Hessian\" #> Iter=5\t; #> \tD= 0.003918  #> \tp= -0.4843  #> [1] \"Numerical Hessian\" #> Iter=6\t; #> \tD= 0.0009826  #> \tp= -0.4921  #> [1] \"Numerical Hessian\" #> Iter=7\t; #> \tD= 0.0002472  #> \tp= -0.496  #> [1] \"Numerical Hessian\" #> Iter=8\t; #> \tD= 6.259e-05  #> \tp= -0.498  #> [1] \"Numerical Hessian\" #> Iter=9\t; #> \tD= 1.604e-05  #> \tp= -0.499  #> [1] \"Numerical Hessian\" #> Iter=10\t; #> \tD= 4.208e-06  #> \tp= -0.4995  #> [1] \"Numerical Hessian\" #> Iter=11\t; #> \tD= 1.152e-06  #> \tp= -0.4997  #> [1] \"Numerical Hessian\" #> Iter=12\t; #> \tD= 3.392e-07  #> \tp= -0.4998  #> [1] \"Numerical Hessian\" #> Iter=13\t; #> \tD= 1.115e-07  #> \tp= -0.4999  #> [1] \"Numerical Hessian\" #> Iter=14\t; #> \tD= 4.219e-08  #> \tp= -0.4999  #> [1] \"Numerical Hessian\" #> Iter=15\t; #> \tD= 1.859e-08  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=16\t; #> \tD= 9.411e-09  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=17\t; #> \tD= 5.347e-09  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=18\t; #> \tD= 3.327e-09  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=19\t; #> \tD= 2.221e-09  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=20\t; #> \tD= 1.567e-09  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=21\t; #> \tD= 1.154e-09  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=22\t; #> \tD= 8.799e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=23\t; #> \tD= 6.901e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=24\t; #> \tD= 5.54e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=25\t; #> \tD= 4.535e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=26\t; #> \tD= 3.774e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=27\t; #> \tD= 3.185e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=28\t; #> \tD= 2.721e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=29\t; #> \tD= 2.349e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=30\t; #> \tD= 2.047e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=31\t; #> \tD= 1.799e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=32\t; #> \tD= 1.593e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=33\t; #> \tD= 1.419e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=34\t; #> \tD= 1.272e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=35\t; #> \tD= 1.146e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=36\t; #> \tD= 1.038e-10  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=37\t; #> \tD= 9.444e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=38\t; #> \tD= 8.626e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=39\t; #> \tD= 7.909e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=40\t; #> \tD= 7.276e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=41\t; #> \tD= 6.716e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=42\t; #> \tD= 6.217e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=43\t; #> \tD= 5.77e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=44\t; #> \tD= 5.37e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=45\t; #> \tD= 5.01e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=46\t; #> \tD= 4.684e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=47\t; #> \tD= 4.389e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=48\t; #> \tD= 4.12e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=49\t; #> \tD= 3.876e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=50\t; #> \tD= 3.652e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=51\t; #> \tD= 3.447e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=52\t; #> \tD= 3.258e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=53\t; #> \tD= 3.085e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=54\t; #> \tD= 2.925e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=55\t; #> \tD= 2.776e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=56\t; #> \tD= 2.639e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=57\t; #> \tD= 2.512e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=58\t; #> \tD= 2.393e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=59\t; #> \tD= 2.283e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=60\t; #> \tD= 2.18e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=61\t; #> \tD= 2.084e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=62\t; #> \tD= 1.994e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=63\t; #> \tD= 1.91e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=64\t; #> \tD= 1.83e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=65\t; #> \tD= 1.756e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=66\t; #> \tD= 1.686e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=67\t; #> \tD= 1.62e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=68\t; #> \tD= 1.558e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=69\t; #> \tD= 1.5e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=70\t; #> \tD= 1.444e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=71\t; #> \tD= 1.392e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=72\t; #> \tD= 1.342e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=73\t; #> \tD= 1.295e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=74\t; #> \tD= 1.251e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=75\t; #> \tD= 1.208e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=76\t; #> \tD= 1.168e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=77\t; #> \tD= 1.13e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=78\t; #> \tD= 1.093e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=79\t; #> \tD= 1.059e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=80\t; #> \tD= 1.026e-11  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=81\t; #> \tD= 9.939e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=82\t; #> \tD= 9.638e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=83\t; #> \tD= 9.35e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=84\t; #> \tD= 9.075e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=85\t; #> \tD= 8.811e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=86\t; #> \tD= 8.559e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=87\t; #> \tD= 8.317e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=88\t; #> \tD= 8.086e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=89\t; #> \tD= 7.864e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=90\t; #> \tD= 7.651e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=91\t; #> \tD= 7.446e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=92\t; #> \tD= 7.25e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=93\t; #> \tD= 7.061e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=94\t; #> \tD= 6.879e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=95\t; #> \tD= 6.705e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=96\t; #> \tD= 6.537e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=97\t; #> \tD= 6.375e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=98\t; #> \tD= 6.219e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=99\t; #> \tD= 6.068e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=100\t; #> \tD= 5.923e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=101\t; #> \tD= 5.783e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=102\t; #> \tD= 5.648e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=103\t; #> \tD= 5.518e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=104\t; #> \tD= 5.392e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=105\t; #> \tD= 5.27e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=106\t; #> \tD= 5.153e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=107\t; #> \tD= 5.039e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=108\t; #> \tD= 4.929e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=109\t; #> \tD= 4.822e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=110\t; #> \tD= 4.719e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=111\t; #> \tD= 4.62e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=112\t; #> \tD= 4.523e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=113\t; #> \tD= 4.429e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=114\t; #> \tD= 4.338e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=115\t; #> \tD= 4.25e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=116\t; #> \tD= 4.165e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=117\t; #> \tD= 4.082e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=118\t; #> \tD= 4.002e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=119\t; #> \tD= 3.923e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=120\t; #> \tD= 3.848e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=121\t; #> \tD= 3.774e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=122\t; #> \tD= 3.702e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=123\t; #> \tD= 3.633e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=124\t; #> \tD= 3.565e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=125\t; #> \tD= 3.499e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=126\t; #> \tD= 3.435e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=127\t; #> \tD= 3.373e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=128\t; #> \tD= 3.313e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=129\t; #> \tD= 3.254e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=130\t; #> \tD= 3.196e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=131\t; #> \tD= 3.14e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=132\t; #> \tD= 3.086e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=133\t; #> \tD= 3.033e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=134\t; #> \tD= 2.981e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=135\t; #> \tD= 2.931e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=136\t; #> \tD= 2.882e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=137\t; #> \tD= 2.834e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=138\t; #> \tD= 2.787e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=139\t; #> \tD= 2.742e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=140\t; #> \tD= 2.697e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=141\t; #> \tD= 2.654e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=142\t; #> \tD= 2.611e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=143\t; #> \tD= 2.57e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=144\t; #> \tD= 2.53e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=145\t; #> \tD= 2.49e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=146\t; #> \tD= 2.452e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=147\t; #> \tD= 2.414e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=148\t; #> \tD= 2.377e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=149\t; #> \tD= 2.341e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=150\t; #> \tD= 2.306e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=151\t; #> \tD= 2.272e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=152\t; #> \tD= 2.238e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=153\t; #> \tD= 2.205e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=154\t; #> \tD= 2.173e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=155\t; #> \tD= 2.142e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=156\t; #> \tD= 2.111e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=157\t; #> \tD= 2.081e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=158\t; #> \tD= 2.051e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=159\t; #> \tD= 2.022e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=160\t; #> \tD= 1.994e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=161\t; #> \tD= 1.966e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=162\t; #> \tD= 1.939e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=163\t; #> \tD= 1.913e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=164\t; #> \tD= 1.887e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=165\t; #> \tD= 1.861e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=166\t; #> \tD= 1.836e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=167\t; #> \tD= 1.812e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=168\t; #> \tD= 1.788e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=169\t; #> \tD= 1.764e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=170\t; #> \tD= 1.741e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=171\t; #> \tD= 1.719e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=172\t; #> \tD= 1.697e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=173\t; #> \tD= 1.675e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=174\t; #> \tD= 1.653e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=175\t; #> \tD= 1.633e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=176\t; #> \tD= 1.612e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=177\t; #> \tD= 1.592e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=178\t; #> \tD= 1.572e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=179\t; #> \tD= 1.553e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=180\t; #> \tD= 1.534e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=181\t; #> \tD= 1.515e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=182\t; #> \tD= 1.497e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=183\t; #> \tD= 1.479e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=184\t; #> \tD= 1.461e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=185\t; #> \tD= 1.443e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=186\t; #> \tD= 1.426e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=187\t; #> \tD= 1.41e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=188\t; #> \tD= 1.393e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=189\t; #> \tD= 1.377e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=190\t; #> \tD= 1.361e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=191\t; #> \tD= 1.345e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=192\t; #> \tD= 1.33e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=193\t; #> \tD= 1.315e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=194\t; #> \tD= 1.3e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=195\t; #> \tD= 1.285e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=196\t; #> \tD= 1.271e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=197\t; #> \tD= 1.257e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=198\t; #> \tD= 1.243e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=199\t; #> \tD= 1.229e-12  #> \tp= -0.5  #> [1] \"Numerical Hessian\" #> Iter=200\t; #> \tD= 1.216e-12  #> \tp= -0.5  #> $par #> [1] -0.4999995 #>  #> $iterations #> [1] 200 #>  #> $method #> [1] \"NR\" #>  #> $gradient #> [1] 1.215822e-12 #>  #> $iH #>           [,1] #> [1,] -2472.735 #> attr(,\"det\") #>               [,1] #> [1,] -0.0004044106 #>"},{"path":"/reference/PD.html","id":null,"dir":"Reference","previous_headings":"","what":"Dose response calculation for binomial regression models — PD","title":"Dose response calculation for binomial regression models — PD","text":"Dose response calculation binomial regression models","code":""},{"path":"/reference/PD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dose response calculation for binomial regression models — PD","text":"","code":"PD(   model,   intercept = 1,   slope = 2,   prob = NULL,   x,   level = 0.5,   ci.level = 0.95,   vcov,   family,   EB = NULL )"},{"path":"/reference/PD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dose response calculation for binomial regression models — PD","text":"model Model object vector parameter estimates intercept Index intercept parameters slope Index intercept parameters prob Index mixture parameters (relevant zibreg models) x Optional weights length(x)=length(intercept)+length(slope)+length(prob) level Probability level calculate dose ci.level Level confidence limits vcov Optional estimate variance matrix parameter estimates family Optional distributional family argument EB Optional ratio treatment effect adverse effects used find optimal dose (regret-function argument)","code":""},{"path":"/reference/PD.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dose response calculation for binomial regression models — PD","text":"Klaus K. Holst","code":""},{"path":"/reference/Print.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic print method — Print","title":"Generic print method — Print","text":"Nicer print method tabular data. Falls back standard print method data types.","code":""},{"path":"/reference/Print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic print method — Print","text":"","code":"Print(x, n = 5, digits = max(3, getOption(\"digits\") - 3), ...)"},{"path":"/reference/Print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic print method — Print","text":"x object print n number rows show top bottom tabular data digits precision ... additional arguments print method","code":""},{"path":"/reference/Range.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Define range constraints of parameters — Range.lvm","title":"Define range constraints of parameters — Range.lvm","text":"Define range constraints parameters","code":""},{"path":"/reference/Range.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define range constraints of parameters — Range.lvm","text":"","code":"Range.lvm(a = 0, b = 1)"},{"path":"/reference/Range.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define range constraints of parameters — Range.lvm","text":"Lower bound b Upper bound","code":""},{"path":"/reference/Range.lvm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define range constraints of parameters — Range.lvm","text":"function","code":""},{"path":"/reference/Range.lvm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Define range constraints of parameters — Range.lvm","text":"Klaus K. Holst","code":""},{"path":"/reference/addvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Add variable to (model) object — addvar","title":"Add variable to (model) object — addvar","text":"Generic method adding variables model object","code":""},{"path":"/reference/addvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add variable to (model) object — addvar","text":"","code":"addvar(x, ...)"},{"path":"/reference/addvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add variable to (model) object — addvar","text":"x Model object ... Additional arguments","code":""},{"path":"/reference/addvar.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add variable to (model) object — addvar","text":"Klaus K. Holst","code":""},{"path":"/reference/backdoor.html","id":null,"dir":"Reference","previous_headings":"","what":"Backdoor criterion — backdoor","title":"Backdoor criterion — backdoor","text":"Check backdoor criterion lvm object","code":""},{"path":"/reference/backdoor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Backdoor criterion — backdoor","text":"","code":"backdoor(object, f, cond, ..., return.graph = FALSE)"},{"path":"/reference/backdoor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Backdoor criterion — backdoor","text":"object lvm object f formula. Conditioning, z, set can given y~x|z cond Vector variables conditon ... Additional arguments lower level functions return.graph Return moral ancestral graph z effects x removed","code":""},{"path":"/reference/backdoor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Backdoor criterion — backdoor","text":"","code":"m <- lvm(y~c2,c2~c1,x~c1,m1~x,y~m1, v1~c3, x~c3,v1~y,          x~z1, z2~z1, z2~z3, y~z3+z2+g1+g2+g3) ll <- backdoor(m, y~x) backdoor(m, y~x|c1+z1+g1) #> [1] TRUE"},{"path":"/reference/baptize.html","id":null,"dir":"Reference","previous_headings":"","what":"Label elements of object — baptize","title":"Label elements of object — baptize","text":"Generic method labeling elements object","code":""},{"path":"/reference/baptize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Label elements of object — baptize","text":"","code":"baptize(x, ...)"},{"path":"/reference/baptize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Label elements of object — baptize","text":"x Object ... Additional arguments","code":""},{"path":"/reference/baptize.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Label elements of object — baptize","text":"Klaus K. Holst","code":""},{"path":"/reference/binomial.rd.html","id":null,"dir":"Reference","previous_headings":"","what":"Define constant risk difference or relative risk association for binary exposure — binomial.rd","title":"Define constant risk difference or relative risk association for binary exposure — binomial.rd","text":"Set model defined Richardson, Robins Wang (2017).","code":""},{"path":"/reference/binomial.rd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define constant risk difference or relative risk association for binary exposure — binomial.rd","text":"","code":"binomial.rd(   x,   response,   exposure,   target.model,   nuisance.model,   exposure.model = binomial.lvm(),   ... )"},{"path":"/reference/binomial.rd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define constant risk difference or relative risk association for binary exposure — binomial.rd","text":"x model response response variable (character formula) exposure exposure variable (character formula) target.model variable defining linear predictor target model nuisance.model variable defining linear predictor nuisance model exposure.model model exposure (default binomial logit link) ... additional arguments lower level functions","code":""},{"path":"/reference/blockdiag.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine matrices to block diagonal structure — blockdiag","title":"Combine matrices to block diagonal structure — blockdiag","text":"Combine matrices block diagonal structure","code":""},{"path":"/reference/blockdiag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine matrices to block diagonal structure — blockdiag","text":"","code":"blockdiag(x, ..., pad = 0)"},{"path":"/reference/blockdiag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine matrices to block diagonal structure — blockdiag","text":"x Matrix ... Additional matrices pad Vyalue outside block-diagonal","code":""},{"path":"/reference/blockdiag.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Combine matrices to block diagonal structure — blockdiag","text":"Klaus K. Holst","code":""},{"path":"/reference/blockdiag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine matrices to block diagonal structure — blockdiag","text":"","code":"A <- diag(3)+1 blockdiag(A,A,A,pad=NA) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] #>  [1,]    2    1    1   NA   NA   NA   NA   NA   NA #>  [2,]    1    2    1   NA   NA   NA   NA   NA   NA #>  [3,]    1    1    2   NA   NA   NA   NA   NA   NA #>  [4,]   NA   NA   NA    2    1    1   NA   NA   NA #>  [5,]   NA   NA   NA    1    2    1   NA   NA   NA #>  [6,]   NA   NA   NA    1    1    2   NA   NA   NA #>  [7,]   NA   NA   NA   NA   NA   NA    2    1    1 #>  [8,]   NA   NA   NA   NA   NA   NA    1    2    1 #>  [9,]   NA   NA   NA   NA   NA   NA    1    1    2"},{"path":"/reference/bmd.html","id":null,"dir":"Reference","previous_headings":"","what":"Longitudinal Bone Mineral Density Data (Wide format) — bmd","title":"Longitudinal Bone Mineral Density Data (Wide format) — bmd","text":"Bone Mineral Density Data consisting 112 girls randomized receive calcium og placebo. Longitudinal measurements bone mineral density (g/cm^2) measured approximately every 6th month 3 years.","code":""},{"path":"/reference/bmd.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Longitudinal Bone Mineral Density Data (Wide format) — bmd","text":"data.frame","code":""},{"path":"/reference/bmd.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Longitudinal Bone Mineral Density Data (Wide format) — bmd","text":"Vonesh & Chinchilli (1997), Table 5.4.1 page 228.","code":""},{"path":[]},{"path":"/reference/bmidata.html","id":null,"dir":"Reference","previous_headings":"","what":"Data — bmidata","title":"Data — bmidata","text":"Description","code":""},{"path":"/reference/bmidata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data — bmidata","text":"data.frame","code":""},{"path":"/reference/bootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic bootstrap method — bootstrap","title":"Generic bootstrap method — bootstrap","text":"Generic method calculating bootstrap statistics","code":""},{"path":"/reference/bootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic bootstrap method — bootstrap","text":"","code":"bootstrap(x, ...)"},{"path":"/reference/bootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic bootstrap method — bootstrap","text":"x Model object ... Additional arguments","code":""},{"path":[]},{"path":"/reference/bootstrap.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generic bootstrap method — bootstrap","text":"Klaus K. Holst","code":""},{"path":"/reference/bootstrap.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate bootstrap estimates of a lvm object — bootstrap.lvm","title":"Calculate bootstrap estimates of a lvm object — bootstrap.lvm","text":"Draws non-parametric bootstrap samples","code":""},{"path":"/reference/bootstrap.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate bootstrap estimates of a lvm object — bootstrap.lvm","text":"","code":"# S3 method for class 'lvm' bootstrap(x,R=100,data,fun=NULL,control=list(),                           p, parametric=FALSE, bollenstine=FALSE,                           constraints=TRUE,sd=FALSE, mc.cores,                           future.args=list(future.seed=TRUE),                           ...)  # S3 method for class 'lvmfit' bootstrap(x,R=100,data=model.frame(x),                              control=list(start=coef(x)),                              p=coef(x), parametric=FALSE, bollenstine=FALSE,                              estimator=x$estimator,weights=Weights(x),...)"},{"path":"/reference/bootstrap.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate bootstrap estimates of a lvm object — bootstrap.lvm","text":"x lvm-object. R Number bootstrap samples data data resample fun Optional function (bootstrapped) model-fit defining statistic interest control Options optimization routine p Parameter vector null model parametric bootstrap parametric TRUE parametric bootstrap calculated. FALSE non-parametric (row-sampling) bootstrap computed. bollenstine Bollen-Stine transformation (non-parametric bootstrap) bootstrap hypothesis testing. constraints Logical indicating whether non-linear parameter constraints included bootstrap procedure sd Logical indicating whether standard error estimates included bootstrap procedure mc.cores Optional number cores parallel computing. omitted future.apply used (see future::plan) future.args arguments future.apply::future_lapply ... Additional arguments, e.g. choice estimator. estimator String definining estimator, e.g. 'gaussian' (see estimator) weights Optional weights matrix used estimator","code":""},{"path":"/reference/bootstrap.lvm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate bootstrap estimates of a lvm object — bootstrap.lvm","text":"bootstrap.lvm object.","code":""},{"path":[]},{"path":"/reference/bootstrap.lvm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate bootstrap estimates of a lvm object — bootstrap.lvm","text":"Klaus K. Holst","code":""},{"path":"/reference/bootstrap.lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate bootstrap estimates of a lvm object — bootstrap.lvm","text":"","code":"m <- lvm(y~x) d <- sim(m,100) e <- estimate(lvm(y~x), data=d)  ## Reduce Ex.Timings B <- bootstrap(e,R=50,mc.cores=1) B #> Non-parametric bootstrap statistics (R=50): #>  #>      Estimate     Bias         Std.Err      2.5 %        97.5 %       #> y    -0.053821882  0.003045923  0.101716706 -0.197865173  0.162723203 #> y~x   0.900266219  0.023337709  0.085382077  0.750455514  1.086770784 #> y~~y  1.054489157 -0.026246424  0.126152114  0.807799324  1.290297648 #>"},{"path":"/reference/brisa.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data — brisa","title":"Simulated data — brisa","text":"Simulated data","code":""},{"path":"/reference/brisa.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data — brisa","text":"data.frame","code":""},{"path":"/reference/brisa.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated data — brisa","text":"Simulated","code":""},{"path":"/reference/calcium.html","id":null,"dir":"Reference","previous_headings":"","what":"Longitudinal Bone Mineral Density Data — calcium","title":"Longitudinal Bone Mineral Density Data — calcium","text":"Bone Mineral Density Data consisting 112 girls randomized receive calcium og placebo. Longitudinal measurements bone mineral density (g/cm^2) measured approximately every 6th month 3 years.","code":""},{"path":"/reference/calcium.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Longitudinal Bone Mineral Density Data — calcium","text":"data.frame containing 560 (incomplete) observations. 'person' column defines individual girls study measurements visiting times 'visit', age years 'age' time visit. bone mineral density variable 'bmd' (g/cm^2).","code":""},{"path":"/reference/calcium.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Longitudinal Bone Mineral Density Data — calcium","text":"Vonesh & Chinchilli (1997), Table 5.4.1 page 228.","code":""},{"path":"/reference/cancel.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic cancel method — cancel","title":"Generic cancel method — cancel","text":"Generic cancel method","code":""},{"path":"/reference/cancel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic cancel method — cancel","text":"","code":"cancel(x, ...)"},{"path":"/reference/cancel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic cancel method — cancel","text":"x Object ... Additioal arguments","code":""},{"path":"/reference/cancel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generic cancel method — cancel","text":"Klaus K. Holst","code":""},{"path":"/reference/children.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract children or parent elements of object — children","title":"Extract children or parent elements of object — children","text":"Generic method memberships object (e.g. graph)","code":""},{"path":"/reference/children.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract children or parent elements of object — children","text":"","code":"children(object, ...)"},{"path":"/reference/children.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract children or parent elements of object — children","text":"object Object ... Additional arguments","code":""},{"path":"/reference/children.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract children or parent elements of object — children","text":"Klaus K. Holst","code":""},{"path":"/reference/click.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify points on plot — click","title":"Identify points on plot — click","text":"Extension identify function","code":""},{"path":"/reference/click.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify points on plot — click","text":"","code":"# Default S3 method click(x, y=NULL, label=TRUE, n=length(x), pch=19, col=\"orange\", cex=3, ...) idplot(x, y ,..., id=list(), return.data=FALSE)"},{"path":"/reference/click.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify points on plot — click","text":"x X coordinates ... Additional arguments parsed plot function y Y coordinates label labels added? n Max number inputs expect pch Symbol col Colour cex Size id List arguments parsed click function return.data Boolean indicating selected points returned","code":""},{"path":"/reference/click.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify points on plot — click","text":"usual 'X11' device identification process terminated pressing mouse button first. 'quartz' device process terminated pressing either pop-menu equivalent (usually second mouse button 'Ctrl'-click) 'ESC' key.","code":""},{"path":[]},{"path":"/reference/click.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Identify points on plot — click","text":"Klaus K. Holst","code":""},{"path":"/reference/click.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify points on plot — click","text":"","code":"if (interactive()) {     n <- 10; x <- seq(n); y <- runif(n)     plot(y ~ x); click(x,y)      data(iris)     l <- lm(Sepal.Length ~ Sepal.Width*Species,iris)     res <- plotConf(l,var2=\"Species\")## ylim=c(6,8), xlim=c(2.5,3.3))     with(res, click(x,y))      with(iris, idplot(Sepal.Length,Petal.Length)) }"},{"path":"/reference/closed_testing.html","id":null,"dir":"Reference","previous_headings":"","what":"Closed testing procedure — closed_testing","title":"Closed testing procedure — closed_testing","text":"Given p hypotheses H1, ..., Hp 2^p-1 intersection hypotheses calculated adjusted p-values obtained Hj calculated max p-value intersection hypotheses containing Hj. Example, p=3, adjusted p-value H1 obtained {(H1, H2, H3), (H1,H2), (H1,H3), (H1)}.","code":""},{"path":"/reference/closed_testing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Closed testing procedure — closed_testing","text":"","code":"closed_testing(object, test = test_wald, ...)"},{"path":"/reference/closed_testing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Closed testing procedure — closed_testing","text":"object `estimate` object test function conducts hypothesis test. See details . ... Additional arguments passed `test`","code":""},{"path":"/reference/closed_testing.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Closed testing procedure — closed_testing","text":"function `test` function `function(object, index,   ...)` first argument takes `estimate` object wit   argument `index` integer vector specifying   subcomponents `object` test. ellipsis argument can   arguments used test function. function test_wald   example valid test function (additional argument `null`   reference mentioned ellipsis arguments).","code":""},{"path":"/reference/closed_testing.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Closed testing procedure — closed_testing","text":"Marcus, R; Peritz, E; Gabriel, KR (1976).   \"closed testing procedures special reference ordered analysis   variance\". Biometrika. 63 (3): 655–660.","code":""},{"path":"/reference/closed_testing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Closed testing procedure — closed_testing","text":"","code":"m <- lvm() regression(m, c(y1,y2,y3,y4)~x) <- c(0, 0.25, 0, 0.25) regression(m, to=endogenous(m), from=\"u\") <- 1 variance(m,endogenous(m)) <- 1 set.seed(1) d <- sim(m, 200) l1 <- lm(y1~x,d) l2 <- lm(y2~x,d) l3 <- lm(y3~x,d) l4 <- lm(y4~x,d)  (a <- merge(l1, l2, l3, l4, subset=2)) #>     Estimate Std.Err     2.5%  97.5% P-value #> x   -0.04472 0.08929 -0.21971 0.1303 0.61650 #> ───                                          #> x.1  0.23835 0.09337  0.05536 0.4213 0.01068 #> ───                                          #> x.2 -0.04900 0.09372 -0.23269 0.1347 0.60111 #> ───                                          #> x.3  0.22272 0.09225  0.04191 0.4035 0.01577 if (requireNamespace(\"mets\",quietly=TRUE)) {    alpha_zmax(a) } #>        Estimate    P-value Adj.P-value #> x   -0.04471577 0.61649927  0.96215399 #> x.1  0.23835177 0.01068488  0.03639110 #> x.2 -0.04899862 0.60110873  0.95610026 #> x.3  0.22271748 0.01576576  0.05254759 #> attr(,\"adjusted.significance.level\") #> [1] 0.01486995 adj <- closed_testing(a) adj #> Call: closed_testing(object = a) #>  #>        Estimate      adj.p #> x   -0.04471577 0.84238106 #> x.1  0.23835177 0.01928037 #> x.2 -0.04899862 0.84238106 #> x.3  0.22271748 0.01928037 adj$p.value #>          x        x.1        x.2        x.3  #> 0.84238106 0.01928037 0.84238106 0.01928037  summary(adj) #> Call: closed_testing(object = a) #>  #> ── Adjusted p-values ── #>  #>        Estimate      adj.p #> x   -0.04471577 0.84238106 #> x.1  0.23835177 0.01928037 #> x.2 -0.04899862 0.84238106 #> x.3  0.22271748 0.01928037 #>  #> ── Raw p-values for intersection hypotheses ── #>  #> 1-way intersections: #>   {x}                                      p = 0.6165 #>   {x.1}                                    p = 0.0107 #>   {x.2}                                    p = 0.6011 #>   {x.3}                                    p = 0.0158 #>  #> 2-way intersections: #>   {x, x.1}                                 p = 0.0036 #>   {x, x.2}                                 p = 0.8424 #>   {x, x.3}                                 p = 0.0086 #>   {x.1, x.2}                               p = 0.0032 #>   {x.1, x.3}                               p = 0.0193 #>   {x.2, x.3}                               p = 0.0046 #>  #> 3-way intersections: #>   {x, x.1, x.2}                            p = 0.0033 #>   {x, x.1, x.3}                            p = 0.0022 #>   {x, x.2, x.3}                            p = 0.0068 #>   {x.1, x.2, x.3}                          p = 0.0012 #>  #> 4-way intersections: #>   {x, x.1, x.2, x.3}                       p = 0.0006 #>"},{"path":"/reference/colorbar.html","id":null,"dir":"Reference","previous_headings":"","what":"Add color-bar to plot — colorbar","title":"Add color-bar to plot — colorbar","text":"Add color-bar plot","code":""},{"path":"/reference/colorbar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add color-bar to plot — colorbar","text":"","code":"colorbar(   clut = Col(rev(rainbow(11, start = 0, end = 0.69)), alpha),   x.range = c(-0.5, 0.5),   y.range = c(-0.1, 0.1),   values = seq(clut),   digits = 2,   label.offset,   srt = 45,   cex = 0.5,   border = NA,   alpha = 0.5,   position = 1,   direction = c(\"horizontal\", \"vertical\"),   ... )"},{"path":"/reference/colorbar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add color-bar to plot — colorbar","text":"clut Color look-table x.range x range y.range y range values label values digits number digits label.offset label offset srt rotation labels cex text size border border color bar rectangles alpha Alpha (transparency) level 0-1 position Label position left/bottom (1) top/right (2) text (0) direction horizontal vertical color bars ... additional low level arguments (.e. parsed text)","code":""},{"path":"/reference/colorbar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add color-bar to plot — colorbar","text":"","code":"if (FALSE) { # \\dontrun{ plotNeuro(x,roi=R,mm=-18,range=5) colorbar(clut=Col(rev(rainbow(11,start=0,end=0.69)),0.5),          x=c(-40,40),y.range=c(84,90),values=c(-5:5))  colorbar(clut=Col(rev(rainbow(11,start=0,end=0.69)),0.5),          x=c(-10,10),y.range=c(-100,50),values=c(-5:5),          direction=\"vertical\",border=1) } # }"},{"path":"/reference/commutation.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds the unique commutation matrix — commutation","title":"Finds the unique commutation matrix — commutation","text":"Finds unique commutation matrix K: \\(K vec() = vec(^t)\\)","code":""},{"path":"/reference/commutation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds the unique commutation matrix — commutation","text":"","code":"commutation(m, n = m)"},{"path":"/reference/commutation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds the unique commutation matrix — commutation","text":"m rows n columns","code":""},{"path":"/reference/commutation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Finds the unique commutation matrix — commutation","text":"Klaus K. Holst","code":""},{"path":"/reference/compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical tests — compare","title":"Statistical tests — compare","text":"Performs Likelihood-ratio, Wald score tests","code":""},{"path":"/reference/compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical tests — compare","text":"","code":"compare(object, ...)"},{"path":"/reference/compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical tests — compare","text":"object lvmfit-object ... Additional arguments low-level functions","code":""},{"path":"/reference/compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical tests — compare","text":"Matrix test-statistics p-values","code":""},{"path":[]},{"path":"/reference/compare.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Statistical tests — compare","text":"Klaus K. Holst","code":""},{"path":"/reference/compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical tests — compare","text":"","code":"m <- lvm(); regression(m) <- c(y1,y2,y3) ~ eta; latent(m) <- ~eta regression(m) <- eta ~ x m2 <- regression(m, c(y3,eta) ~ x) set.seed(1) d <- sim(m,1000) e <- estimate(m,d) e2 <- estimate(m2,d)  compare(e) #>  #> \t- Likelihood ratio test - #>  #> data:   #> chisq = 2.7373, df = 2, p-value = 0.2544 #> sample estimates: #>           log likelihood (model) log likelihood (saturated model)  #>                        -5045.863                        -5044.494  #>   compare(e,e2) ## LRT, H0: y3<-x=0 #>  #> \t- Likelihood ratio test - #>  #> data:   #> chisq = 1.6297, df = 1, p-value = 0.2017 #> sample estimates: #> log likelihood (model 1) log likelihood (model 2)  #>                -5045.863                -5045.048  #>  compare(e,scoretest=y3~x) ## Score-test, H0: y3~x=0 #>  #> \t- Score test - #>  #> data:  y3 ~ x #> chisq = 1.6059, df = 1, p-value = 0.2051 #>  compare(e2,par=c(\"y3~x\")) ## Wald-test, H0: y3~x=0 #>  #> \t- Wald test - #>  #> \tNull Hypothesis: #> \t[y3~x] = 0 #>  #> data:   #> chisq = 1.5752, df = 1, p-value = 0.2095 #> sample estimates: #>           Estimate    Std.Err     2.5%      97.5% #> [y3~x] -0.08157255 0.06499477 -0.20896 0.04581487 #>   B <- diag(2); colnames(B) <- c(\"y2~eta\",\"y3~eta\") compare(e2,contrast=B,null=c(1,1)) #>  #> \t- Wald test - #>  #> \tNull Hypothesis: #> \t[y2~eta] = 1 #> \t[y3~eta] = 1 #>  #> data:   #> chisq = 0.40264, df = 2, p-value = 0.8177 #> sample estimates: #>          Estimate    Std.Err      2.5%    97.5% #> [y2~eta] 1.019845 0.03770718 0.9459398 1.093749 #> [y3~eta] 1.028685 0.05598807 0.9189509 1.138420 #>   B <- rep(0,length(coef(e2))); B[1:3] <- 1 compare(e2,contrast=B) #>  #> \t- Wald test - #>  #> \tNull Hypothesis: #> \t[y2] + [y3] + [eta] = 0 #>  #> data:   #> chisq = 0.15653, df = 1, p-value = 0.6924 #> sample estimates: #>                       Estimate    Std.Err       2.5%     97.5% #> [y2] + [y3] + [eta] 0.02605068 0.06584406 -0.1030013 0.1551027 #>   compare(e,scoretest=list(y3~x,y2~x)) #>  #> \t- Score test - #>  #> data:  y3 ~ xy2 ~ x #> chisq = 2.7607, df = 2, p-value = 0.2515 #>"},{"path":"/reference/complik.html","id":null,"dir":"Reference","previous_headings":"","what":"Composite Likelihood for probit latent variable models — complik","title":"Composite Likelihood for probit latent variable models — complik","text":"Estimate parameters probit latent variable model via composite likelihood decomposition.","code":""},{"path":"/reference/complik.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Composite Likelihood for probit latent variable models — complik","text":"","code":"complik(   x,   data,   k = 2,   type = c(\"all\", \"nearest\"),   pairlist,   messages = 0,   estimator = \"normal\",   quick = FALSE,   ... )"},{"path":"/reference/complik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Composite Likelihood for probit latent variable models — complik","text":"x lvm-object data data.frame k Size composite groups type Determines number groups. type=\"nearest\" (default) neighboring items grouped, e.g. k=2 (y1,y2),(y2,y3),... type=\"\" combinations size k included pairlist list indices specifying composite groups. Optional argument overrides k type gives complete flexibility specification composite likelihood messages Control amount messages printed estimator Model (pseudo-likelihood) use pairs/groups quick TRUE parameter estimates calculated additional information standard errors skipped ... Additional arguments parsed lower-level functions","code":""},{"path":"/reference/complik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Composite Likelihood for probit latent variable models — complik","text":"object class estimate.complik inheriting methods lvm","code":""},{"path":[]},{"path":"/reference/complik.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Composite Likelihood for probit latent variable models — complik","text":"Klaus K. Holst","code":""},{"path":"/reference/complik.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Composite Likelihood for probit latent variable models — complik","text":"","code":"m <- lvm(c(y1,y2,y3)~b*x+1*u[0],latent=~u) ordinal(m,K=2) <- ~y1+y2+y3 d <- sim(m,50,seed=1) if (requireNamespace(\"mets\", quietly=TRUE)) {    e1 <- complik(m,d,control=list(trace=1),type=\"all\") } #>   0:     194.34186: 0.604480 0.584480 0.484480  0.00000 0.900000 #>   1:     163.15053: 0.540600 0.484448 0.209475 0.939309  1.06729 #>   2:     160.91018: 0.418339 0.334648 -0.188107  1.05711  1.14818 #>   3:     160.77829: 0.376957 0.300830 -0.155237  1.00706  1.18949 #>   4:     160.76097: 0.369541 0.291889 -0.159621  1.03751  1.20710 #>   5:     160.74923: 0.370653 0.293179 -0.167035  1.02015  1.23923 #>   6:     160.73532: 0.376191 0.296936 -0.168307  1.04656  1.26468 #>   7:     160.72558: 0.379780 0.299688 -0.168631  1.04345  1.30158 #>   8:     160.72091: 0.369539 0.303131 -0.165350  1.05346  1.33569 #>   9:     160.71897: 0.382701 0.295562 -0.170712  1.05926  1.33925 #>  10:     160.71733: 0.379230 0.296353 -0.167731  1.05972  1.35609 #>  11:     160.71701: 0.379746 0.299743 -0.170560  1.06152  1.35778 #>  12:     160.71683: 0.380300 0.298684 -0.169147  1.06113  1.36250 #>  13:     160.71663: 0.380886 0.299718 -0.170369  1.06381  1.36647 #>  14:     160.71650: 0.380928 0.300399 -0.170596  1.06425  1.37148 #>  15:     160.71645: 0.381806 0.299785 -0.170466  1.06543  1.37630 #>  16:     160.71643: 0.381561 0.300967 -0.170583  1.06589  1.37944 #>  17:     160.71643: 0.381542 0.300509 -0.170678  1.06575  1.37858 #>  18:     160.71643: 0.381620 0.300565 -0.170579  1.06575  1.37852 #>  19:     160.71643: 0.381587 0.300550 -0.170619  1.06575  1.37856 #>  20:     160.71643: 0.381587 0.300550 -0.170619  1.06575  1.37856"},{"path":"/reference/confband.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Confidence limits bar to plot — confband","title":"Add Confidence limits bar to plot — confband","text":"Add Confidence limits bar plot","code":""},{"path":"/reference/confband.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Confidence limits bar to plot — confband","text":"","code":"confband(   x,   lower,   upper,   center = NULL,   line = TRUE,   delta = 0.07,   centermark = 0.03,   pch,   blank = TRUE,   vert = TRUE,   polygon = FALSE,   step = FALSE,   ... )"},{"path":"/reference/confband.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Confidence limits bar to plot — confband","text":"x Position (x-coordinate vert=TRUE, y-coordinate otherwise) lower Lower limit (NULL limits added, center drawn (NULL)) upper Upper limit center Center point line FALSE add line upper lower bound delta Length limit bars centermark Length center bar pch Center symbol (missing line drawn) blank TRUE white ball plotted center added plot vert TRUE vertical bar plotted. Otherwise horizontal bar used polygon TRUE polygons added 'lower' 'upper'. step Type polygon (step-function piecewise linear) ... Additional low level arguments (e.g. col, lwd, lty,...)","code":""},{"path":[]},{"path":"/reference/confband.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add Confidence limits bar to plot — confband","text":"Klaus K. Holst","code":""},{"path":"/reference/confband.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Confidence limits bar to plot — confband","text":"","code":"plot(0,0,type=\"n\",xlab=\"\",ylab=\"\") confband(0.5,-0.5,0.5,0,col=\"darkblue\") confband(0.8,-0.5,0.5,0,col=\"darkred\",vert=FALSE,pch=1,cex=1.5)   set.seed(1) K <- 20 est <- rnorm(K) se <- runif(K,0.2,0.4) x <- cbind(est,est-2*se,est+2*se,runif(K,0.5,2)) x[c(3:4,10:12),] <- NA rownames(x) <- unlist(lapply(letters[seq(K)],function(x) paste(rep(x,4),collapse=\"\"))) rownames(x)[which(is.na(est))] <- \"\" signif <- sign(x[,2])==sign(x[,3]) forestplot(x,text.right=FALSE)  forestplot(x[,-4],sep=c(2,15),col=signif+1,box1=TRUE,delta=0.2,pch=16,cex=1.5)  forestplot(x,vert=TRUE,text=FALSE)  forestplot(x,vert=TRUE,text=FALSE,pch=NA)  ##forestplot(x,vert=TRUE,text.vert=FALSE) ##forestplot(val,vert=TRUE,add=TRUE)  z <- seq(10) zu <- c(z[-1],10) plot(z,type=\"n\") confband(z,zu,rep(0,length(z)),col=Col(\"darkblue\"),polygon=TRUE,step=TRUE) confband(z,zu,zu-2,col=Col(\"darkred\"),polygon=TRUE,step=TRUE)   z <- seq(0,1,length.out=100) plot(z,z,type=\"n\") confband(z,z,z^2,polygon=\"TRUE\",col=Col(\"darkblue\"))   set.seed(1) k <- 10 x <- seq(k) est <- rnorm(k) sd <- runif(k) val <- cbind(x,est,est-sd,est+sd) par(mfrow=c(1,2)) plot(0,type=\"n\",xlim=c(0,k+1),ylim=range(val[,-1]),axes=FALSE,xlab=\"\",ylab=\"\") axis(2) confband(val[,1],val[,3],val[,4],val[,2],pch=16,cex=2) plot(0,type=\"n\",ylim=c(0,k+1),xlim=range(val[,-1]),axes=FALSE,xlab=\"\",ylab=\"\") axis(1) confband(val[,1],val[,3],val[,4],val[,2],pch=16,cex=2,vert=FALSE)   x <- seq(0, 3, length.out=20) y <- cos(x) yl <- y - 1 yu <- y + 1 plot_region(x, y, yl, yu) plot_region(x, y, yl, yu, type='s', col=\"darkblue\", add=TRUE)"},{"path":"/reference/confint.lvmfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate confidence limits for parameters — confint.lvmfit","title":"Calculate confidence limits for parameters — confint.lvmfit","text":"Calculate Wald og Likelihood based (profile likelihood) confidence intervals","code":""},{"path":"/reference/confint.lvmfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate confidence limits for parameters — confint.lvmfit","text":"","code":"# S3 method for class 'lvmfit' confint(   object,   parm = seq_len(length(coef(object))),   level = 0.95,   profile = FALSE,   curve = FALSE,   n = 20,   interval = NULL,   lower = TRUE,   upper = TRUE,   ... )"},{"path":"/reference/confint.lvmfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate confidence limits for parameters — confint.lvmfit","text":"object lvm-object. parm Index parameters calculate confidence limits . level Confidence level profile Logical expression defining whether calculate confidence limits via profile log likelihood curve FALSE profile TRUE, confidence limits returned. Otherwise, profile curve returned. n Number points evaluate profile log-likelihood interval defined interval interval Interval profiling done lower FALSE lower limit estimated (profile intervals ) upper FALSE upper limit estimated (profile intervals ) ... Additional arguments passed low level functions","code":""},{"path":"/reference/confint.lvmfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate confidence limits for parameters — confint.lvmfit","text":"2xp matrix columns lower upper confidence limits","code":""},{"path":"/reference/confint.lvmfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate confidence limits for parameters — confint.lvmfit","text":"Calculates either Wald confidence limits: $$\\hat{\\theta} \\pm z_{\\alpha/2}*\\hat\\sigma_{\\hat\\theta}$$ profile likelihood confidence limits, defined set value \\(\\tau\\): $$logLik(\\hat\\theta_{\\tau},\\tau)-logLik(\\hat\\theta)< q_{\\alpha}/2$$ \\(q_{\\alpha}\\) \\(\\alpha\\) fractile \\(\\chi^2_1\\) distribution, \\(\\hat\\theta_{\\tau}\\) obtained maximizing log-likelihood tau fixed.","code":""},{"path":[]},{"path":"/reference/confint.lvmfit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate confidence limits for parameters — confint.lvmfit","text":"Klaus K. Holst","code":""},{"path":"/reference/confint.lvmfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate confidence limits for parameters — confint.lvmfit","text":"","code":"m <- lvm(y~x) d <- sim(m,100) e <- estimate(lvm(y~x), d) confint(e,3,profile=TRUE) #>          2.5 %   97.5 % #> y~~y 0.5914658 1.030886 confint(e,3) #>          2.5 %    97.5 % #> y~~y 0.5572218 0.9845795  ## Reduce Ex.timings B <- bootstrap(e,R=50) B #> Non-parametric bootstrap statistics (R=50): #>  #>      Estimate     Bias         Std.Err      2.5 %        97.5 %       #> y     0.119837374 -0.006845587  0.086472357 -0.040118667  0.289097490 #> y~x   1.052101422  0.006742617  0.072663722  0.919824486  1.169691110 #> y~~y  0.770900690 -0.014345058  0.098669023  0.581444406  0.971146502 #>"},{"path":"/reference/confpred.html","id":null,"dir":"Reference","previous_headings":"","what":"Conformal prediction — confpred","title":"Conformal prediction — confpred","text":"Conformal predicions using locally weighted conformal inference split-conformal algorithm","code":""},{"path":"/reference/confpred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conformal prediction — confpred","text":"","code":"confpred(object, data, newdata = data, alpha = 0.05, mad, ...)"},{"path":"/reference/confpred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conformal prediction — confpred","text":"object Model object (lm, glm similar predict method) formula (lm) data data.frame newdata New data.frame make predictions alpha Level prediction interval mad Conditional model (formula) MAD (locally-weighted CP) ... Additional arguments lower level functions","code":""},{"path":"/reference/confpred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conformal prediction — confpred","text":"data.frame fitted (fit), lower (lwr) upper (upr) predictions bands.","code":""},{"path":"/reference/confpred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conformal prediction — confpred","text":"","code":"set.seed(123) n <- 200 x <- seq(0,6,length.out=n) delta <- 3 ss <- exp(-1+1.5*cos((x-delta))) ee <- rnorm(n,sd=ss) y <- (x-delta)+3*cos(x+4.5-delta)+ee d <- data.frame(y=y,x=x)  newd <- data.frame(x=seq(0,6,length.out=50)) cc <- confpred(lm(y~splines::ns(x,knots=c(1,3,5)),data=d), data=d, newdata=newd) if (interactive()) { plot(y~x,pch=16,col=lava::Col(\"black\"),ylim=c(-10,10),xlab=\"X\",ylab=\"Y\") with(cc,      lava::confband(newd$x,lwr,upr,fit,         lwd=3,polygon=TRUE,col=Col(\"blue\"),border=FALSE)) }"},{"path":"/reference/constrain-set.html","id":null,"dir":"Reference","previous_headings":"","what":"Add non-linear constraints to latent variable model — constrain<-","title":"Add non-linear constraints to latent variable model — constrain<-","text":"Add non-linear constraints latent variable model","code":""},{"path":"/reference/constrain-set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add non-linear constraints to latent variable model — constrain<-","text":"","code":"# Default S3 method constrain(x, par, args, endogenous = TRUE, ...) <- value  # S3 method for class 'multigroup' constrain(x, par, k = 1, ...) <- value  constraints(object,data=model.frame(object),vcov=object$vcov,level=0.95,                         p=pars.default(object),k,idx,...)"},{"path":"/reference/constrain-set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add non-linear constraints to latent variable model — constrain<-","text":"x lvm-object ... Additional arguments passed low level functions value Real function taking args vector argument par Name new parameter. Alternatively formula lhs specifying new parameter rhs defining names parameters variable names defining new parameter (overruling args argument). args Vector variables names parameter names used defining par endogenous TRUE variable endogenous (sink node) k multigroup models argument specifies group add/extract constraint object lvm-object data Data-row possible non-linear constraints calculated vcov Variance matrix parameter estimates level Level confidence limits p Parameter vector idx Index indicating constraints extract","code":""},{"path":"/reference/constrain-set.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add non-linear constraints to latent variable model — constrain<-","text":"lvm object.","code":""},{"path":"/reference/constrain-set.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add non-linear constraints to latent variable model — constrain<-","text":"Add non-linear parameter constraints well non-linear associations covariates latent observed variables model (non-linear regression). example specify follow multiple regression model: $$E(Y|X_1,X_2) = \\alpha + \\beta_1 X_1 + \\beta_2 X_2$$ $$V(Y|X_1,X_2) = v$$ defined (appropiate parameter labels) m <- lvm(y ~ f(x,beta1) + f(x,beta2)) intercept(m) <- y ~ f(alpha) covariance(m) <- y ~ f(v) somewhat strained parameter constraint $$ v = \\frac{(beta1-beta2)^2}{alpha}$$ can specified constrain(m,v ~ beta1 + beta2 + alpha) <- function(x) (x[1]-x[2])^2/x[3] subset arguments args can covariates model, allowing specification non-linear regression models.  example non-linear regression model $$ E(Y\\mid X) = \\nu + \\Phi(\\alpha + \\beta X)$$ \\(\\Phi\\) denotes standard normal cumulative distribution function, can defined m <- lvm(y ~ f(x,0)) # linear effect x Next add three new parameters using parameter assigment function: parameter(m) <- ~nu+alpha+beta intercept \\(Y\\) defined mu intercept(m) <- y ~ f(mu) finally newly added intercept parameter mu defined appropiate non-linear function \\(\\alpha\\), \\(\\nu\\) \\(\\beta\\): constrain(m, mu ~ x + alpha + nu) <- function(x) pnorm(x[1]*x[2])+x[3] constraints function can used show estimated non-linear parameter constraints estimated model object (lvmfit multigroupfit). Calling constrain additional arguments beyound x return list functions parameter names defining non-linear restrictions. gradient function can optionally added attribute grad return value function defined value. case analytical derivatives calculated via chain rule evaluating corresponding score function log-likelihood. gradient attribute omitted chain rule applied numeric approximation gradient.","code":""},{"path":[]},{"path":"/reference/constrain-set.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add non-linear constraints to latent variable model — constrain<-","text":"Klaus K. Holst","code":""},{"path":"/reference/constrain-set.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add non-linear constraints to latent variable model — constrain<-","text":"","code":"############################## ### Non-linear parameter constraints 1 ############################## m <- lvm(y ~ f(x1,gamma)+f(x2,beta)) covariance(m) <- y ~ f(v) d <- sim(m,100) m1 <- m; constrain(m1,beta ~ v) <- function(x) x^2 ## Define slope of x2 to be the square of the residual variance of y ## Estimate both restricted and unrestricted model e <- estimate(m,d,control=list(method=\"NR\")) e1 <- estimate(m1,d) p1 <- coef(e1) p1 <- c(p1[1:2],p1[3]^2,p1[3]) ## Likelihood of unrestricted model evaluated in MLE of restricted model logLik(e,p1) #> 'log Lik.' -144.1895 (df=4) ## Likelihood of restricted model (MLE) logLik(e1) #> 'log Lik.' -144.1895 (df=3)  ############################## ### Non-linear regression ##############################  ## Simulate data m <- lvm(c(y1,y2)~f(x,0)+f(eta,1)) latent(m) <- ~eta covariance(m,~y1+y2) <- \"v\" intercept(m,~y1+y2) <- \"mu\" covariance(m,~eta) <- \"zeta\" intercept(m,~eta) <- 0 set.seed(1) d <- sim(m,100,p=c(v=0.01,zeta=0.01))[,manifest(m)] d <- transform(d,                y1=y1+2*pnorm(2*x),                y2=y2+2*pnorm(2*x))  ## Specify model and estimate parameters constrain(m, mu ~ x + alpha + nu + gamma) <- function(x) x[4]*pnorm(x[3]+x[1]*x[2])  ## Reduce Ex.Timings e <- estimate(m,d,control=list(trace=1,constrain=TRUE)) #>   0:     95.152055: -1.59936 -0.105361  0.00000  0.00000  0.00000 #>   1:     38.372166: -2.18276 0.313970  0.00000  0.00000 0.695563 #>   2:    -48.631404: -5.42107 -0.457717  1.00498 0.959271  2.42405 #>   3:    -105.61595: -4.91886 -0.355240  1.37309 0.129419  1.46668 #>   4:    -152.46012: -4.25655 -1.25021  1.67211 -0.125549  2.24731 #>   5:    -180.78964: -4.81503 -2.47787  1.62885 -0.253601  1.83976 #>   6:    -211.28333: -4.80871 -2.49722  1.70839 -0.00201508  2.15835 #>   7:    -221.43757: -4.99751 -2.78668  1.85800 -0.174274  2.15106 #>   8:    -234.66131: -4.89742 -3.07152  1.81950 0.0648691  2.00370 #>   9:    -235.81920: -4.84621 -3.39006  1.92584 -0.172015  2.00849 #>  10:    -243.54486: -4.84315 -3.41209  1.93840 -0.0450523  2.11931 #>  11:    -249.92689: -4.91487 -3.54656  1.94515 -0.0534678  2.04374 #>  12:    -255.87455: -4.87632 -3.87587  1.88862 -0.0315669  2.09477 #>  13:    -257.75884: -4.87429 -3.99772  1.89084 -0.0860001  2.04418 #>  14:    -260.62789: -4.95797 -4.02216  1.97158 -0.00861141  2.02769 #>  15:    -261.37051: -4.93303 -4.07134  1.96534 0.00793329  1.99764 #>  16:    -262.57297: -4.90750 -4.12620  1.96600 0.0130003  2.02147 #>  17:    -263.47641: -4.89102 -4.18624  1.97603 0.000429297  2.01046 #>  18:    -264.88048: -4.85966 -4.31148  1.98011 0.00245026  2.02872 #>  19:    -265.31709: -4.81141 -4.38806  1.88684 -0.00882753  2.02648 #>  20:    -266.24088: -4.85665 -4.48860  1.95610 -0.00918763  2.01806 #>  21:    -266.36993: -4.85543 -4.49025  1.95701 -0.00251444  2.02375 #>  22:    -266.42758: -4.85199 -4.49508  1.95778 0.000738714  2.01778 #>  23:    -266.52966: -4.83730 -4.50276  1.96383 0.00407116  2.02004 #>  24:    -266.85259: -4.78250 -4.55684  1.97997 0.00102846  2.01598 #>  25:    -267.11116: -4.79057 -4.63475  1.97192 0.00301228  2.01881 #>  26:    -267.25811: -4.76842 -4.70933  1.98152 0.00921799  2.01330 #>  27:    -267.27811: -4.74964 -4.75600  1.97691 0.00627923  2.01510 #>  28:    -267.27983: -4.74890 -4.75331  1.98105 0.00877742  2.01358 #>  29:    -267.28003: -4.75019 -4.75214  1.98027 0.00821320  2.01379 #>  30:    -267.28003: -4.75002 -4.75222  1.98016 0.00820184  2.01385 #>  31:    -267.28003: -4.75004 -4.75224  1.98020 0.00821068  2.01384 #>  32:    -267.28003: -4.75004 -4.75223  1.98020 0.00821063  2.01384 constraints(e,data=d) #>    Estimate Std. Error  Z value Pr(>|z|)     2.5%    97.5% #> mu 1.598142 0.02227334 71.75133        0 1.554487 1.641797 ## Plot model-fit plot(y1~x,d,pch=16); points(y2~x,d,pch=16,col=\"gray\") x0 <- seq(-4,4,length.out=100) lines(x0,coef(e)[\"nu\"] + coef(e)[\"gamma\"]*pnorm(coef(e)[\"alpha\"]*x0))    ############################## ### Multigroup model ############################## ### Define two models m1 <- lvm(y ~ f(x,beta)+f(z,beta2)) m2 <- lvm(y ~ f(x,psi) + z) ### And simulate data from them d1 <- sim(m1,500) d2 <- sim(m2,500) ### Add 'non'-linear parameter constraint constrain(m2,psi ~ beta2) <- function(x) x ## Add parameter beta2 to model 2, now beta2 exists in both models parameter(m2) <- ~ beta2 ee <- estimate(list(m1,m2),list(d1,d2),control=list(method=\"NR\")) summary(ee) #> ||score||^2= 2.641697e-17  #> Latent variables:  #> ____________________________________________________ #> Group 1 (n=500) #>                     Estimate Std. Error  Z value Pr(>|z|) #> Regressions:                                              #>    y~x               0.93621    0.04767 19.64130   <1e-12 #>    y~z               1.03489    0.03217 32.17115   <1e-12 #> Intercepts:                                               #>    y                -0.05578    0.04814 -1.15869   0.2466 #> Residual Variances:                                       #>    y                 1.15827    0.07326 15.81139          #> ____________________________________________________ #> Group 2 (n=500) #>                        Estimate Std. Error  Z value Pr(>|z|) #> Regressions:                                                 #>    y~z                  0.96338    0.04278 22.51997   <1e-12 #> Intercepts:                                                  #>    y                   -0.01359    0.04657 -0.29191   0.7704 #> Additional Parameters:                                       #>    beta2                1.03489    0.03217 32.17115   <1e-12 #> Residual Variances:                                          #>    y                    1.07306    0.06787 15.81139          #>  #> ──────────────────────────────────────────────────────────────────────────────── #> Non-linear constraints: #>     Estimate Std. Error  Z value      Pr(>|z|)      2.5%    97.5% #> psi 1.034886 0.03216812 32.17115 4.470275e-227 0.9718373 1.097934 #> ──────────────────────────────────────────────────────────────────────────────── #> Estimator: gaussian  #> ──────────────────────────────────────────────────────────────────────────────── #>  #>  Number of observations = 1000  #>  BIC = 2994.955  #>  AIC = 2960.6  #>  log-Likelihood of model = -1473.3  #>  #>  log-Likelihood of saturated model = -1473.128  #>  Chi-squared statistic: q = 0.3442204 , df = 1  #>   P(Q>q) = 0.5574032  #>  #>  RMSEA (90% CI): 0 (0;0.0698) #>   P(RMSEA<0.05)=0.85508 #>  #> rank(Information) = 7 (p=7) #> condition(Information) = 5.215445 #> mean(score^2) = 3.773853e-18  #> ────────────────────────────────────────────────────────────────────────────────  m3 <- lvm(y ~ f(x,beta)+f(z,beta2)) m4 <- lvm(y ~ f(x,beta2) + z) e2 <- estimate(list(m3,m4),list(d1,d2),control=list(method=\"NR\")) e2 #> ____________________________________________________ #> Group 1 (n=500) #>                     Estimate Std. Error  Z value Pr(>|z|) #> Regressions:                                              #>    y~x               0.93621    0.04767 19.64130   <1e-12 #>    y~z               1.03489    0.03217 32.17115   <1e-12 #> Intercepts:                                               #>    y                -0.05578    0.04814 -1.15869   0.2466 #> Residual Variances:                                       #>    y                 1.15827    0.07326 15.81139          #> ____________________________________________________ #> Group 2 (n=500) #>                     Estimate Std. Error  Z value Pr(>|z|) #> Regressions:                                              #>    y~x               1.03489    0.03217 32.17115   <1e-12 #>    y~z               0.96338    0.04278 22.51997   <1e-12 #> Intercepts:                                               #>    y                -0.01359    0.04657 -0.29191   0.7704 #> Residual Variances:                                       #>    y                 1.07306    0.06787 15.81139          #>"},{"path":"/reference/contr.html","id":null,"dir":"Reference","previous_headings":"","what":"Create contrast matrix — contr","title":"Create contrast matrix — contr","text":"Create contrast matrix typically use 'estimate' (Wald tests).","code":""},{"path":"/reference/contr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create contrast matrix — contr","text":"","code":"contr(p, n, diff = TRUE, ...)"},{"path":"/reference/contr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create contrast matrix — contr","text":"p index non-zero entries (see example) n Total number parameters (omitted max number p used) diff FALSE non-zero entries +1, otherwise second non-zero element row -1. ... Additional arguments lower level functions","code":""},{"path":"/reference/contr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create contrast matrix — contr","text":"","code":"contr(2,n=5) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0    1    0    0    0 contr(as.list(2:4),n=5) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0    1    0    0    0 #> [2,]    0    0    1    0    0 #> [3,]    0    0    0    1    0 contr(list(1,2,4),n=5) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    0    0    0    0 #> [2,]    0    1    0    0    0 #> [3,]    0    0    0    1    0 contr(c(2,3,4),n=5) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    0    1   -1    0    0 #> [2,]    0    1    0   -1    0 contr(list(c(1,3),c(2,4)),n=5) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    0   -1    0    0 #> [2,]    0    1    0   -1    0 contr(list(c(1,3),c(2,4),5)) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1    0   -1    0    0 #> [2,]    0    1    0   -1    0 #> [3,]    0    0    0    0    1  parsedesign(c(\"aa\",\"b\",\"c\"),\"?\",\"?\",diff=c(FALSE,TRUE)) #>      [,1] [,2] [,3] #> [1,]    0    1    0 #> [2,]    0    0    1 #> [3,]    0    1   -1  ## All pairs comparisons: pdiff <- function(n) lava::contr(lapply(seq(n-1), function(x) seq(x, n))) pdiff(4) #>      [,1] [,2] [,3] [,4] #> [1,]    1   -1    0    0 #> [2,]    1    0   -1    0 #> [3,]    1    0    0   -1 #> [4,]    0    1   -1    0 #> [5,]    0    1    0   -1 #> [6,]    0    0    1   -1"},{"path":"/reference/correlation.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic method for extracting correlation coefficients of model object — correlation","title":"Generic method for extracting correlation coefficients of model object — correlation","text":"Generic correlation method","code":""},{"path":"/reference/correlation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic method for extracting correlation coefficients of model object — correlation","text":"","code":"correlation(x, ...)"},{"path":"/reference/correlation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic method for extracting correlation coefficients of model object — correlation","text":"x Object ... Additional arguments","code":""},{"path":"/reference/correlation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generic method for extracting correlation coefficients of model object — correlation","text":"Klaus K. Holst","code":""},{"path":"/reference/covariance.html","id":null,"dir":"Reference","previous_headings":"","what":"Add covariance structure to Latent Variable Model — covariance","title":"Add covariance structure to Latent Variable Model — covariance","text":"Define covariances residual terms lvm-object.","code":""},{"path":"/reference/covariance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add covariance structure to Latent Variable Model — covariance","text":"","code":"# S3 method for class 'lvm' covariance(object, var1 = NULL, var2 = NULL, constrain = FALSE, pairwise = FALSE, ...) <- value"},{"path":"/reference/covariance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add covariance structure to Latent Variable Model — covariance","text":"object lvm-object ... Additional arguments passed low level functions var1 Vector variables names (formula) var2 Vector variables names (formula) defining pairwise covariance var1 var2) constrain Define non-linear parameter constraints ensure positive definite structure pairwise TRUE var2 omitted pairwise correlation added variables var1 value List parameter values (var1 unspecified)","code":""},{"path":"/reference/covariance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add covariance structure to Latent Variable Model — covariance","text":"lvm-object","code":""},{"path":"/reference/covariance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add covariance structure to Latent Variable Model — covariance","text":"covariance function used specify correlation structure residual terms latent variable model, using formula syntax. instance, multivariate model three response variables, $$Y_1 = \\mu_1 + \\epsilon_1$$ $$Y_2 = \\mu_2 + \\epsilon_2$$ $$Y_3 = \\mu_3 + \\epsilon_3$$ can specified m <- lvm(~y1+y2+y3) Pr. default two variables assumed independent. add covariance parameter \\(r = cov(\\epsilon_1,\\epsilon_2)\\), execute following code covariance(m) <- y1 ~ f(y2,r) special function f second argument omitted thus assigning unique parameter covariance y1 y2. Similarily marginal variance two response variables can fixed identical (\\(var(Y_i)=v\\)) via covariance(m) <- c(y1,y2,y3) ~ f(v) specify completely unstructured covariance structure, can call covariance(m) <- ~y1+y2+y3 parameter values linear constraints can given right handside expression assigment function covariance<- first (possibly second) argument defined well. E.g: covariance(m,y1~y1+y2) <- list(\"a1\",\"b1\") covariance(m,~y2+y3) <- list(\"a2\",2) Defines $$var(\\epsilon_1) = a1$$ $$var(\\epsilon_2) = a2$$ $$var(\\epsilon_3) = 2$$ $$cov(\\epsilon_1,\\epsilon_2) = b1$$ Parameter constraints can cleared fixing relevant parameters NA (see also regression method). function covariance (called without additional arguments) can used inspect covariance constraints lvm-object.","code":""},{"path":[]},{"path":"/reference/covariance.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add covariance structure to Latent Variable Model — covariance","text":"Klaus K. Holst","code":""},{"path":"/reference/covariance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add covariance structure to Latent Variable Model — covariance","text":"","code":"m <- lvm() ### Define covariance between residuals terms of y1 and y2 covariance(m) <- y1~y2 covariance(m) <- c(y1,y2)~f(v) ## Same marginal variance covariance(m) ## Examine covariance structure #> Covariance parameters: #>       y1 y2 #>    y1 v  *  #>    y2 *  v"},{"path":"/reference/csplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Split data into folds — csplit","title":"Split data into folds — csplit","text":"Split data folds","code":""},{"path":"/reference/csplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split data into folds — csplit","text":"","code":"csplit(x, p = NULL, replace = FALSE, return.index = FALSE, k = 2, ...)"},{"path":"/reference/csplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split data into folds — csplit","text":"x Data integer (size) p Number folds, number 0 1 given two folds size p (1-p) returned replace -replacement return.index TRUE index folds returned otherwise actual data splits returned (default) k (Optional, used p=NULL) number folds without shuffling ... additional arguments lower-level functions","code":""},{"path":"/reference/csplit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Split data into folds — csplit","text":"Klaus K. Holst","code":""},{"path":"/reference/csplit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split data into folds — csplit","text":"","code":"foldr(5,2,rep=2) #> [[1]] #> [[1]]$`1` #> [1] 1 5 3 #>  #> [[1]]$`2` #> [1] 2 4 #>  #>  #> [[2]] #> [[2]]$`1` #> [1] 2 1 5 #>  #> [[2]]$`2` #> [1] 3 4 #>  #>  csplit(10,3) #> $`1` #> [1]  7  8  5 10 #>  #> $`2` #> [1] 1 2 9 #>  #> $`3` #> [1] 3 6 4 #>  csplit(iris[1:10,]) ## Split in two sets 1:(n/2) and (n/2+1):n #> $`1` #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 1          5.1         3.5          1.4         0.2  setosa #> 2          4.9         3.0          1.4         0.2  setosa #> 3          4.7         3.2          1.3         0.2  setosa #> 4          4.6         3.1          1.5         0.2  setosa #> 5          5.0         3.6          1.4         0.2  setosa #>  #> $`2` #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 6           5.4         3.9          1.7         0.4  setosa #> 7           4.6         3.4          1.4         0.3  setosa #> 8           5.0         3.4          1.5         0.2  setosa #> 9           4.4         2.9          1.4         0.2  setosa #> 10          4.9         3.1          1.5         0.1  setosa #>  csplit(iris[1:10,],0.5) #> [[1]] #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 7           4.6         3.4          1.4         0.3  setosa #> 3           4.7         3.2          1.3         0.2  setosa #> 10          4.9         3.1          1.5         0.1  setosa #> 6           5.4         3.9          1.7         0.4  setosa #> 4           4.6         3.1          1.5         0.2  setosa #>  #> [[2]] #>   Sepal.Length Sepal.Width Petal.Length Petal.Width Species #> 5          5.0         3.6          1.4         0.2  setosa #> 2          4.9         3.0          1.4         0.2  setosa #> 1          5.1         3.5          1.4         0.2  setosa #> 8          5.0         3.4          1.5         0.2  setosa #> 9          4.4         2.9          1.4         0.2  setosa #>"},{"path":"/reference/curly.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds curly brackets to plot — curly","title":"Adds curly brackets to plot — curly","text":"Adds curly brackets plot","code":""},{"path":"/reference/curly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds curly brackets to plot — curly","text":"","code":"curly(   x,   y,   len = 1,   theta = 0,   wid,   shape = 1,   col = 1,   lwd = 1,   lty = 1,   grid = FALSE,   npoints = 50,   text = NULL,   offset = c(0.05, 0) )"},{"path":"/reference/curly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds curly brackets to plot — curly","text":"x center x axis curly brackets (start end coordinates (x1,x2)) y center y axis curly brackets (start end coordinates (y1,y2)) len Length curly brackets theta angle (radians) curly brackets orientation wid Width curly brackets shape shape (curvature) col color (passed lines/grid.lines) lwd line width (passed lines/grid.lines) lty line type (passed lines/grid.lines) grid TRUE use grid graphics (compatability ggplot2) npoints Number points used curves text Label offset Label offset (x,y)","code":""},{"path":"/reference/curly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adds curly brackets to plot — curly","text":"","code":"if (interactive()) { plot(0,0,type=\"n\",axes=FALSE,xlab=\"\",ylab=\"\") curly(x=c(1,0),y=c(0,1),lwd=2,text=\"a\") curly(x=c(1,0),y=c(0,1),lwd=2,text=\"b\",theta=pi) curly(x=-0.5,y=0,shape=1,theta=pi,text=\"c\") curly(x=0,y=0,shape=1,theta=0,text=\"d\") curly(x=0.5,y=0,len=0.2,theta=pi/2,col=\"blue\",lty=2) curly(x=0.5,y=-0.5,len=0.2,theta=-pi/2,col=\"red\",shape=1e3,text=\"e\") }"},{"path":"/reference/deprdiag.html","id":null,"dir":"Reference","previous_headings":"","what":"50 patients from Monash Medical Centre, Melbourne — deprdiag","title":"50 patients from Monash Medical Centre, Melbourne — deprdiag","text":"Diagnosis depression (DSM-III-R MDD, Dysthymia, Adjustment Disorder Depressed Mood, Depression NOS), Beck Depression Inventory (BDI) (Beck et al., 1961) General Health Questionnaire (GHQ) (Goldberg & Williams, 1988)","code":""},{"path":"/reference/deprdiag.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"50 patients from Monash Medical Centre, Melbourne — deprdiag","text":"data.frame","code":""},{"path":"/reference/deprdiag.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"50 patients from Monash Medical Centre, Melbourne — deprdiag","text":"Clarke, D. M., Smith, G. C., & Herrman, H. E. (1993). comparative   study screening instruments mental disorders general hospital   patients. International Journal Psychiatry Medicine, 23, pp. 323-337. McKenzie et al. (1996). Comparing correlated Kappas resampling: one level agreement significantly different another? J. Psychiat. Res. 30 (6), pp. 483-492.","code":""},{"path":"/reference/devcoords.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns device-coordinates and plot-region — devcoords","title":"Returns device-coordinates and plot-region — devcoords","text":"Returns device-coordinates plot-region","code":""},{"path":"/reference/devcoords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns device-coordinates and plot-region — devcoords","text":"","code":"devcoords()"},{"path":"/reference/devcoords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns device-coordinates and plot-region — devcoords","text":"list elements dev.x1 Device: Left x-coordinate dev.x2 Device: Right x-coordinate dev.y1 Device Bottom y-coordinate dev.y2 Device Top y-coordinate fig.x1 Plot: Left x-coordinate fig.x2 Plot: Right x-coordinate fig.y1 Plot: Bottom y-coordinate fig.y2 Plot: Top y-coordinate","code":""},{"path":"/reference/devcoords.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Returns device-coordinates and plot-region — devcoords","text":"Klaus K. Holst","code":""},{"path":"/reference/diagtest.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate diagnostic tests for 2x2 table — diagtest","title":"Calculate diagnostic tests for 2x2 table — diagtest","text":"Calculate prevalence, sensitivity, specificity, positive negative predictive values","code":""},{"path":"/reference/diagtest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate diagnostic tests for 2x2 table — diagtest","text":"","code":"diagtest(   table,   positive = 2,   exact = FALSE,   p0 = NA,   confint = c(\"logit\", \"arcsin\", \"pseudoscore\", \"exact\"),   ... )"},{"path":"/reference/diagtest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate diagnostic tests for 2x2 table — diagtest","text":"table Table (matrix/data.frame two columns) positive Switch reference exact TRUE exact binomial proportions CI/test used p0 Optional null hypothesis (test prevalenc, sensitivity, ...) confint Type confidence limits ... Additional arguments lower level functions","code":""},{"path":"/reference/diagtest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate diagnostic tests for 2x2 table — diagtest","text":"Table format outcome columns     test rows.  Data.frame test first     column outcome second column.","code":""},{"path":"/reference/diagtest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate diagnostic tests for 2x2 table — diagtest","text":"Klaus Holst","code":""},{"path":"/reference/diagtest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate diagnostic tests for 2x2 table — diagtest","text":"","code":"M <- as.table(matrix(c(42,12,                        35,28),ncol=2,byrow=TRUE,                      dimnames=list(rater=c(\"no\",\"yes\"),gold=c(\"no\",\"yes\")))) diagtest(M,exact=TRUE) #> Call: diagtest(table = M, exact = TRUE) #> Confidence limits: exact #> ──────────────────────────────────────────────────────────────────────────────── #>      gold #> rater no yes        no   yes #>   no  42  12     0.359 0.103 #>   yes 35  28     0.299 0.239 #>  #> Positive outcome: 'yes' #> ──────────────────────────────────────────────────────────────────────────────── #>                         Estimate    2.5%   97.5% P-value #> Prevalence               0.34188 0.25670 0.43528         #> Test                     0.53846 0.44389 0.63104         #> Sensitivity              0.70000 0.53468 0.83437         #> Specificity              0.54545 0.42790 0.65940         #> PositivePredictiveValue  0.44444 0.31917 0.57511         #> NegativePredictiveValue  0.77778 0.64400 0.87956         #> Accuracy                 0.59829 0.50363 0.68785         #> Homogeneity              0.74468 0.59650 0.86055  0.0011 #> ──────────────────────────────────────────────────────────────────────────────── #>  #> Prevalence:\t\t\t\tProb( outcome+ ) #> Test:\t\t\t\t\tProb( test+ ) #> Sensitivity (True positive rate):\tProb( test+ | outcome+ ) #> Specificity (True negative rate):\tProb( test- | outcome- ) #> Positive predictive value (Precision):\tProb( outcome+ | test+ ) #> Negative predictive value:\t\tProb( outcome- | test- ) #> Accuracy:\t\t\t\tProb( correct classification ) #> Homogeneity/Symmetry:\t\t\tProb( outcome+, test- | discordant ), H0: p=0.5  #>"},{"path":"/reference/dsep.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Check d-separation criterion — dsep.lvm","title":"Check d-separation criterion — dsep.lvm","text":"Check conditional independence (d-separation)","code":""},{"path":"/reference/dsep.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check d-separation criterion — dsep.lvm","text":"","code":"# S3 method for class 'lvm' dsep(object, x, cond = NULL, return.graph = FALSE, ...)"},{"path":"/reference/dsep.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check d-separation criterion — dsep.lvm","text":"object lvm object x Variables check conditional independence cond Conditioning set return.graph TRUE moralized ancestral graph conditioning set removed returned ... Additional arguments lower level functions","code":""},{"path":"/reference/dsep.lvm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check d-separation criterion — dsep.lvm","text":"argument 'x' can given formula, e.g.  x~y|z+v     ~x+y|z+v everything rhs bar defining     variables condition .","code":""},{"path":"/reference/dsep.lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check d-separation criterion — dsep.lvm","text":"","code":"m <- lvm(x5 ~ x4+x3, x4~x3+x1, x3~x2, x2~x1) if (interactive()) { plot(m,layoutType='neato') } dsep(m,x5~x1|x2+x4) #> [1] FALSE dsep(m,x5~x1|x3+x4) #> [1] TRUE dsep(m,~x1+x2+x3|x4) #> [1] FALSE"},{"path":"/reference/equivalence.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify candidates of equivalent models — equivalence","title":"Identify candidates of equivalent models — equivalence","text":"Identifies candidates equivalent models","code":""},{"path":"/reference/equivalence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify candidates of equivalent models — equivalence","text":"","code":"equivalence(x, rel, tol = 0.001, k = 1, omitrel = TRUE, ...)"},{"path":"/reference/equivalence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify candidates of equivalent models — equivalence","text":"x lvmfit-object rel Formula character-vector specifying two variables omit model subsequently search possible equivalent models tol Define two models empirical equivalent absolute difference score test less tol k Number parameters test simultaneously. equivalence number additional associations added instead rel. omitrel k greater 1, boolean defines wether omit candidates containing rel output ... Additional arguments passed lower-level functions","code":""},{"path":[]},{"path":"/reference/equivalence.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Identify candidates of equivalent models — equivalence","text":"Klaus K. Holst","code":""},{"path":"/reference/estimate.array.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate parameters and influence function. — estimate.array","title":"Estimate parameters and influence function. — estimate.array","text":"Estimate parameters sample mean, variance, quantiles","code":""},{"path":"/reference/estimate.array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate parameters and influence function. — estimate.array","text":"","code":"# S3 method for class 'array' estimate(x, type = \"mean\", probs = 0.5, ...)"},{"path":"/reference/estimate.array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate parameters and influence function. — estimate.array","text":"x numeric matrix type target parameter (\"mean\", \"variance\", \"quantile\") probs numeric vector probabilities (type=\"quantile\") ... Additional arguments lower level functions (.e., stats::density.default type=\"quantile\")","code":""},{"path":"/reference/estimate.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of functional of parameters — estimate.default","title":"Estimation of functional of parameters — estimate.default","text":"Estimation functional parameters. Wald tests, robust standard errors, cluster robust standard errors, LRT (f function)...","code":""},{"path":"/reference/estimate.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of functional of parameters — estimate.default","text":"","code":"# Default S3 method estimate(   x = NULL,   f = NULL,   ...,   data,   id,   iddata,   stack = TRUE,   average = FALSE,   subset,   score.deriv,   level = 0.95,   IC = robust,   type = c(\"robust\", \"df\", \"mbn\"),   keep,   use,   regex = FALSE,   ignore.case = FALSE,   contrast,   null,   vcov,   coef,   robust = TRUE,   df = NULL,   print = NULL,   labels,   label.width,   only.coef = FALSE,   back.transform = NULL,   folds = 0,   cluster,   R = 0,   null.sim )"},{"path":"/reference/estimate.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of functional of parameters — estimate.default","text":"x model object (glm, lvmfit, ...) f transformation model parameters (optionally) data, contrast matrix (vector) ... additional arguments lower level functions data data.frame id (optional) id-variable corresponding ic decomposition model parameters. iddata (optional) id-variable 'data' stack TRUE (default) ..d. decomposition automatically stacked according 'id' average TRUE averages calculated subset (optional) subset data.frame condition (logical expression variable name) score.deriv (optional) derivative mean score function level level confidence limits IC TRUE (default) influence function decompositions also returned (extract IC method) type type small-sample correction keep (optional) index parameters keep final result use (optional) index parameters use calculations regex TRUE use regular expression (perl compatible) keep, use arguments ignore.case Ignore case-sensitiveness regular expression contrast (optional) Contrast matrix final Wald test null (optional) null hypothesis test vcov (optional) covariance matrix parameter estimates (e.g. Wald-test) coef (optional) parameter coefficient robust TRUE robust standard errors calculated. FALSE p-values linear models calculated t-distribution df degrees freedom (default obtained 'df.residual') print (optional) print function labels (optional) names coefficients label.width (optional) max width labels .coef TRUE coefficient matrix return back.transform (optional) transform parameters confidence intervals folds (optional) aggregate influence functions (divide conquer) cluster (obsolete) alias 'id'. R Number simulations (simulated p-values) null.sim Mean null simulations","code":""},{"path":"/reference/estimate.default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of functional of parameters — estimate.default","text":"influence function decomposition estimator \\(\\widehat{\\theta}\\) based data \\(Z_1,\\ldots,Z_n\\): $$\\sqrt{n}(\\widehat{\\theta}-\\theta) = \\frac{1}{\\sqrt{n}}\\sum_{=1}^n IC(Z_i; P) + o_p(1)$$ can extracted IC method.","code":""},{"path":[]},{"path":"/reference/estimate.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of functional of parameters — estimate.default","text":"","code":"## Simulation from logistic regression model m <- lvm(y~x+z); distribution(m,y~x) <- binomial.lvm(\"logit\") d <- sim(m,1000) g <- glm(y~z+x,data=d,family=binomial()) g0 <- glm(y~1,data=d,family=binomial())  ## LRT estimate(g,g0) #>  #> \t- Likelihood ratio test - #>  #> data:   #> chisq = 214.1, df = 2, p-value < 2.2e-16 #> sample estimates: #> log likelihood (model 1) log likelihood (model 2)  #>                -570.8831                -677.9319  #>   ## Plain estimates (robust standard errors) estimate(g) #>             Estimate Std.Err    2.5%  97.5%   P-value #> (Intercept) -0.07117 0.09911 -0.2654 0.1231 4.727e-01 #> z            0.95923 0.08326  0.7960 1.1224 1.037e-30 #> x            1.01347 0.14415  0.7309 1.2960 2.055e-12  ## Testing contrasts estimate(g,null=0) #>               Estimate Std.Err    2.5%  97.5%   P-value #> [(Intercept)] -0.07117 0.09911 -0.2654 0.1231 4.727e-01 #> [z]            0.95923 0.08326  0.7960 1.1224 1.037e-30 #> [x]            1.01347 0.14415  0.7309 1.2960 2.055e-12 #>  #>  Null Hypothesis:  #>   [(Intercept)] = 0 #>   [z] = 0 #>   [x] = 0  #>   #> chisq = 191.8908, df = 3, p-value < 2.2e-16 estimate(g,rbind(c(1,1,0),c(1,0,2))) #>                      Estimate Std.Err   2.5% 97.5%   P-value #> [(Intercept)] + [z]    0.8881  0.1297 0.6339 1.142 7.471e-12 #> [(Intercept)] + 2[x]   1.9558  0.2318 1.5015 2.410 3.202e-17 #>  #>  Null Hypothesis:  #>   [(Intercept)] + [z] = 0 #>   [(Intercept)] + 2[x] = 0  #>   #> chisq = 158.1963, df = 2, p-value < 2.2e-16 estimate(g,rbind(c(1,1,0),c(1,0,2)),null=c(1,2)) #>                      Estimate Std.Err   2.5% 97.5% P-value #> [(Intercept)] + [z]    0.8881  0.1297 0.6339 1.142  0.3880 #> [(Intercept)] + 2[x]   1.9558  0.2318 1.5015 2.410  0.8486 #>  #>  Null Hypothesis:  #>   [(Intercept)] + [z] = 1 #>   [(Intercept)] + 2[x] = 2  #>   #> chisq = 0.9273, df = 2, p-value = 0.629 estimate(g,2:3) ## same as cbind(0,1,-1) #>           Estimate Std.Err    2.5%  97.5% P-value #> [z] - [x] -0.05424  0.1602 -0.3682 0.2597  0.7349 #>  #>  Null Hypothesis:  #>   [z] - [x] = 0  estimate(g,as.list(2:3)) ## same as rbind(c(0,1,0),c(0,0,1)) #>     Estimate Std.Err   2.5% 97.5%   P-value #> [z]   0.9592 0.08326 0.7960 1.122 1.037e-30 #> [x]   1.0135 0.14415 0.7309 1.296 2.055e-12 #>  #>  Null Hypothesis:  #>   [z] = 0 #>   [x] = 0  #>   #> chisq = 169.5678, df = 2, p-value < 2.2e-16 ## Alternative syntax estimate(g,\"z\",\"z\"-\"x\",2*\"z\"-3*\"x\") #>             Estimate Std.Err    2.5%   97.5%   P-value #> [z]          0.95923 0.08326  0.7960  1.1224 1.037e-30 #> [z] - [x]   -0.05424 0.16020 -0.3682  0.2597 7.349e-01 #> 2[z] - 3[x] -1.12195 0.44994 -2.0038 -0.2401 1.265e-02 #>  #>  Null Hypothesis:  #>   [z] = 0 #>   [z] - [x] = 0 #>   2[z] - 3[x] = 0  #>   #> chisq = 169.5678, df = 2, p-value < 2.2e-16 estimate(g,\"?\")  ## Wildcards #>           Estimate Std.Err    2.5%  97.5% P-value #> [z] - [x] -0.05424  0.1602 -0.3682 0.2597  0.7349 #>  #>  Null Hypothesis:  #>   [z] - [x] = 0  estimate(g,\"*Int*\",\"z\") #>               Estimate Std.Err    2.5%  97.5%   P-value #> [(Intercept)] -0.07117 0.09911 -0.2654 0.1231 4.727e-01 #> [z]            0.95923 0.08326  0.7960 1.1224 1.037e-30 #>  #>  Null Hypothesis:  #>   [(Intercept)] = 0 #>   [z] = 0  #>   #> chisq = 133.3069, df = 2, p-value < 2.2e-16 estimate(g,\"1\",\"2\"-\"3\",null=c(0,1)) #>               Estimate Std.Err    2.5%  97.5%   P-value #> [(Intercept)] -0.07117 0.09911 -0.2654 0.1231 4.727e-01 #> [z] - [x]     -0.05424 0.16020 -0.3682 0.2597 4.674e-11 #>  #>  Null Hypothesis:  #>   [(Intercept)] = 0 #>   [z] - [x] = 1  #>   #> chisq = 61.6299, df = 2, p-value = 4.142e-14 estimate(g,2,3) #>     Estimate Std.Err   2.5% 97.5%   P-value #> [z]   0.9592 0.08326 0.7960 1.122 1.037e-30 #> [x]   1.0135 0.14415 0.7309 1.296 2.055e-12 #>  #>  Null Hypothesis:  #>   [z] = 0 #>   [x] = 0  #>   #> chisq = 169.5678, df = 2, p-value < 2.2e-16  ## Usual (non-robust) confidence intervals estimate(g,robust=FALSE) #>             Estimate Std.Err    2.5%  97.5%   P-value #> (Intercept) -0.07117 0.09814 -0.2635 0.1212 4.683e-01 #> z            0.95923 0.08316  0.7962 1.1222 8.788e-31 #> x            1.01347 0.14564  0.7280 1.2989 3.432e-12  ## Transformations estimate(g,function(p) p[1]+p[2]) #>             Estimate Std.Err   2.5% 97.5%   P-value #> (Intercept)   0.8881  0.1297 0.6339 1.142 7.471e-12  ## Multiple parameters e <- estimate(g,function(p) c(p[1]+p[2], p[1]*p[2])) e #>               Estimate Std.Err    2.5%  97.5%   P-value #> (Intercept)    0.88806 0.12967  0.6339 1.1422 7.471e-12 #> (Intercept).1 -0.06827 0.09523 -0.2549 0.1184 4.734e-01 vcov(e) #>             (Intercept) (Intercept) #> (Intercept) 0.016815549 0.008955385 #> (Intercept) 0.008955385 0.009068500  ## Label new parameters estimate(g,function(p) list(\"a1\"=p[1]+p[2], \"b1\"=p[1]*p[2])) #>    Estimate Std.Err    2.5%  97.5%   P-value #> a1  0.88806 0.12967  0.6339 1.1422 7.471e-12 #> b1 -0.06827 0.09523 -0.2549 0.1184 4.734e-01 ##' ## Multiple group m <- lvm(y~x) m <- baptize(m) d2 <- d1 <- sim(m,50,seed=1) e <- estimate(list(m,m),list(d1,d2)) estimate(e) ## Wrong #>        Estimate Std.Err     2.5%  97.5%   P-value #> y@1      0.1044 0.08277 -0.05785 0.2666 2.073e-01 #> y~x@1    0.9665 0.08727  0.79541 1.1375 1.677e-28 #> y~~y@1   0.6764 0.10629  0.46803 0.8847 1.977e-10 ee <- estimate(e, id=rep(seq(nrow(d1)), 2)) ## Clustered ee #>        Estimate Std.Err    2.5%  97.5%   P-value #> y@1      0.1044  0.1171 -0.1250 0.3338 3.725e-01 #> y~x@1    0.9665  0.1234  0.7246 1.2084 4.859e-15 #> y~~y@1   0.6764  0.1503  0.3817 0.9710 6.814e-06 estimate(lm(y~x,d1)) #>             Estimate Std.Err    2.5%  97.5%   P-value #> (Intercept)   0.1044  0.1171 -0.1251 0.3338 3.726e-01 #> x             0.9665  0.1234  0.7246 1.2084 4.853e-15  ## Marginalize f <- function(p,data)   list(p0=lava:::expit(p[\"(Intercept)\"] + p[\"z\"]*data[,\"z\"]),        p1=lava:::expit(p[\"(Intercept)\"] + p[\"x\"] + p[\"z\"]*data[,\"z\"])) e <- estimate(g, f, average=TRUE) e #>    Estimate Std.Err   2.5%  97.5%    P-value #> p0   0.4860 0.02150 0.4438 0.5281 4.175e-113 #> p1   0.6884 0.01992 0.6494 0.7275 1.089e-261 estimate(e,diff) #>    Estimate Std.Err   2.5%  97.5%   P-value #> p1   0.2024 0.02802 0.1475 0.2573 5.069e-13 estimate(e,cbind(1,1)) #>             Estimate Std.Err  2.5% 97.5%    P-value #> [p0] + [p1]    1.174 0.03055 1.115 1.234 1.976e-323 #>  #>  Null Hypothesis:  #>   [p0] + [p1] = 0   ## Clusters and subset (conditional marginal effects) d$id <- rep(seq(nrow(d)/4),each=4) estimate(g,function(p,data)          list(p0=lava:::expit(p[1] + p[\"z\"]*data[,\"z\"])),          subset=d$z>0, id=d$id, average=TRUE) #>    Estimate Std.Err   2.5%  97.5%    P-value #> p0   0.6611 0.02218 0.6176 0.7046 3.296e-195  ## More examples with clusters: m <- lvm(c(y1,y2,y3)~u+x) d <- sim(m,10) l1 <- glm(y1~x,data=d) l2 <- glm(y2~x,data=d) l3 <- glm(y3~x,data=d)  ## Some random id-numbers id1 <- c(1,1,4,1,3,1,2,3,4,5) id2 <- c(1,2,3,4,5,6,7,8,1,1) id3 <- seq(10)  ## Un-stacked and stacked i.i.d. decomposition IC(estimate(l1,id=id1,stack=FALSE)) #>   (Intercept)          x #> 1   0.6443282 -1.5615821 #> 1   0.8292245 -0.3681720 #> 4   1.5725072 -0.7053035 #> 1  -1.5588173 -1.2129716 #> 3   1.5615501  2.9936336 #> 1  -1.0524707  7.9231560 #> 2   0.7800032 -2.7353224 #> 3  -4.2476305 -4.4726609 #> 4  -0.2651809 -0.4020531 #> 5   1.7364862  0.5412760 #> attr(,\"bread\") #>             (Intercept)         x #> (Intercept)    4.175654  2.360059 #> x              2.360059 12.463714 IC(estimate(l1,id=id1)) #>   (Intercept)          x #> 1  -0.5688677  2.3902152 #> 2   0.3900016 -1.3676612 #> 3  -1.3430402 -0.7395136 #> 4   0.6536632 -0.5536783 #> 5   0.8682431  0.2706380 #> attr(,\"bread\") #>             (Intercept)         x #> (Intercept)    4.175654  2.360059 #> x              2.360059 12.463714 #> attr(,\"N\") #> [1] 10  ## Combined i.i.d. decomposition e1 <- estimate(l1,id=id1) e2 <- estimate(l2,id=id2) e3 <- estimate(l3,id=id3) (a2 <- merge(e1,e2,e3)) #>               Estimate Std.Err     2.5%  97.5% P-value #> (Intercept)    -0.1858  0.3721 -0.91501 0.5434 0.61751 #> x               0.2707  0.5834 -0.87285 1.4142 0.64268 #> ─────────────                                          #> (Intercept).1   0.6284  0.3617 -0.08055 1.3373 0.08234 #> x.1             0.4415  0.7723 -1.07229 1.9552 0.56759 #> ─────────────                                          #> (Intercept).2   0.5316  0.3364 -0.12786 1.1910 0.11412 #> x.2             1.0678  0.5171  0.05420 2.0813 0.03894  ## If all models were estimated on the same data we could use the ## syntax: ## Reduce(merge,estimate(list(l1,l2,l3)))  ## Same: IC(a1 <- merge(l1,l2,l3,id=list(id1,id2,id3))) #>    (Intercept)         x (Intercept).1        x.1 (Intercept).2        x.2 #> 1   -1.1377353  4.780430    -0.0683124 -2.9519582   -0.87137910  2.1118587 #> 2    0.7800032 -2.735322     1.7168997  0.5351707   -0.43814610  0.1945349 #> 3   -2.6860804 -1.479027     0.4120817 -0.1829625    1.36962838 -0.6143080 #> 4    1.3073264 -1.107357     1.9069664 -0.8553157   -0.28910871 -0.2249658 #> 5    1.7364862  0.541276    -1.6893508 -1.3145444   -0.20205165 -0.3873514 #> 6    0.0000000  0.000000    -1.2666254 -2.4282362   -0.06001604  0.4518097 #> 7    0.0000000  0.000000    -0.9076952  6.8332644    0.87312198 -3.0618723 #> 8    0.0000000  0.000000    -0.1039640  0.3645818   -1.21352121 -1.2778110 #> 9    0.0000000  0.000000     0.0000000  0.0000000    2.11627845  3.2085890 #> 10   0.0000000  0.000000     0.0000000  0.0000000   -1.28480599 -0.4004838  IC(merge(l1,l2,l3,id=TRUE)) # one-to-one (same clusters) #>    (Intercept)          x (Intercept).1        x.1 (Intercept).2        x.2 #> 1    0.6443282 -1.5615821     0.7607628 -1.8437710   -0.87137910  2.1118587 #> 2    0.8292245 -0.3681720     1.7168997  0.5351707   -0.43814610  0.1945349 #> 3    1.5725072 -0.7053035     0.4120817 -0.1829625    1.36962838 -0.6143080 #> 4   -1.5588173 -1.2129716     1.9069664 -0.8553157   -0.28910871 -0.2249658 #> 5    1.5615501  2.9936336    -1.6893508 -1.3145444   -0.20205165 -0.3873514 #> 6   -1.0524707  7.9231560    -1.2666254 -2.4282362   -0.06001604  0.4518097 #> 7    0.7800032 -2.7353224    -0.9076952  6.8332644    0.87312198 -3.0618723 #> 8   -4.2476305 -4.4726609    -0.1039640  0.3645818   -1.21352121 -1.2778110 #> 9   -0.2651809 -0.4020531    -0.3212921 -0.3383135    2.11627845  3.2085890 #> 10   1.7364862  0.5412760    -0.5077830 -0.7698737   -1.28480599 -0.4004838 IC(merge(l1,l2,l3,id=FALSE)) # independence #>    (Intercept)          x (Intercept).1        x.1 (Intercept).2        x.2 #> 1    1.9329845  -4.684746     0.0000000  0.0000000     0.0000000  0.0000000 #> 2    2.4876735  -1.104516     0.0000000  0.0000000     0.0000000  0.0000000 #> 3    4.7175217  -2.115911     0.0000000  0.0000000     0.0000000  0.0000000 #> 4   -4.6764519  -3.638915     0.0000000  0.0000000     0.0000000  0.0000000 #> 5    4.6846502   8.980901     0.0000000  0.0000000     0.0000000  0.0000000 #> 6   -3.1574121  23.769468     0.0000000  0.0000000     0.0000000  0.0000000 #> 7    2.3400095  -8.205967     0.0000000  0.0000000     0.0000000  0.0000000 #> 8  -12.7428915 -13.417983     0.0000000  0.0000000     0.0000000  0.0000000 #> 9   -0.7955426  -1.206159     0.0000000  0.0000000     0.0000000  0.0000000 #> 10   5.2094586   1.623828     0.0000000  0.0000000     0.0000000  0.0000000 #> 11   0.0000000   0.000000     2.2822883 -5.5313129     0.0000000  0.0000000 #> 12   0.0000000   0.000000     5.1506990  1.6055121     0.0000000  0.0000000 #> 13   0.0000000   0.000000     1.2362452 -0.5488874     0.0000000  0.0000000 #> 14   0.0000000   0.000000     5.7208992 -2.5659471     0.0000000  0.0000000 #> 15   0.0000000   0.000000    -5.0680524 -3.9436331     0.0000000  0.0000000 #> 16   0.0000000   0.000000    -3.7998762 -7.2847086     0.0000000  0.0000000 #> 17   0.0000000   0.000000    -2.7230856 20.4997932     0.0000000  0.0000000 #> 18   0.0000000   0.000000    -0.3118919  1.0937453     0.0000000  0.0000000 #> 19   0.0000000   0.000000    -0.9638764 -1.0149405     0.0000000  0.0000000 #> 20   0.0000000   0.000000    -1.5233491 -2.3096211     0.0000000  0.0000000 #> 21   0.0000000   0.000000     0.0000000  0.0000000    -2.6141373  6.3355761 #> 22   0.0000000   0.000000     0.0000000  0.0000000    -1.3144383  0.5836048 #> 23   0.0000000   0.000000     0.0000000  0.0000000     4.1088851 -1.8429239 #> 24   0.0000000   0.000000     0.0000000  0.0000000    -0.8673261 -0.6748975 #> 25   0.0000000   0.000000     0.0000000  0.0000000    -0.6061550 -1.1620542 #> 26   0.0000000   0.000000     0.0000000  0.0000000    -0.1800481  1.3554291 #> 27   0.0000000   0.000000     0.0000000  0.0000000     2.6193659 -9.1856169 #> 28   0.0000000   0.000000     0.0000000  0.0000000    -3.6405636 -3.8334329 #> 29   0.0000000   0.000000     0.0000000  0.0000000     6.3488353  9.6257670 #> 30   0.0000000   0.000000     0.0000000  0.0000000    -3.8544180 -1.2014514   ## Monte Carlo approach, simple trend test example  m <- categorical(lvm(),~x,K=5) regression(m,additive=TRUE) <- y~x d <- simulate(m,100,seed=1,'y~x'=0.1) l <- lm(y~-1+factor(x),data=d)  f <- function(x) coef(lm(x~seq_along(x)))[2] null <- rep(mean(coef(l)),length(coef(l))) ##  just need to make sure we simulate under H0: slope=0 estimate(l,f,R=1e2,null.sim=null) #> 100 replications #>  #>          seq_along(x) #> Mean         0.014709 #> SD           0.065440 #>                       #> 2.5%        -0.097458 #> 97.5%        0.146613 #>                       #> Estimate     0.080949 #> P-value      0.180000 #>   estimate(l,f) #>              Estimate Std.Err     2.5%  97.5% P-value #> seq_along(x)  0.08095 0.06135 -0.03929 0.2012   0.187"},{"path":"/reference/estimate.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of parameters in a Latent Variable Model (lvm) — estimate.lvm","title":"Estimation of parameters in a Latent Variable Model (lvm) — estimate.lvm","text":"Estimate parameters. MLE, IV user-defined estimator.","code":""},{"path":"/reference/estimate.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of parameters in a Latent Variable Model (lvm) — estimate.lvm","text":"","code":"# S3 method for class 'lvm' estimate(   x,   data = parent.frame(),   estimator = NULL,   control = list(),   missing = FALSE,   weights,   weightsname,   data2,   id,   fix,   index = !quick,   graph = FALSE,   messages = lava.options()$messages,   quick = FALSE,   method,   param,   cluster,   p,   ... )"},{"path":"/reference/estimate.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of parameters in a Latent Variable Model (lvm) — estimate.lvm","text":"x lvm-object data data.frame estimator String defining estimator (see details ) control control/optimization parameters (see details ) missing Logical variable indiciating treat missing data. Setting FALSE leads complete case analysis. case likelihood based inference obtained integrating missing data assumption assumption data missing random (MAR). weights Optional weights used chosen estimator. weightsname Weights names (variable names model) case weights given vector column names data data2 Optional additional dataset used chosen estimator. id Vector (name column data) identifies correlated groups observations data leading variance estimates based sandwich estimator fix Logical variable indicating whether parameter restriction automatically imposed (e.g. intercepts latent variables set 0 least one regression parameter measurement model fixed ensure identifiability.) index internal use graph internal use messages Control much information printed estimation (0: none) quick TRUE parameter estimates calculated additional information standard errors skipped method Optimization method param set parametrization (see help(lava.options)) cluster Obsolete. Alias 'id'. p Evaluate model parameter 'p' (optimization) ... Additional arguments passed lower-level functions","code":""},{"path":"/reference/estimate.lvm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of parameters in a Latent Variable Model (lvm) — estimate.lvm","text":"lvmfit-object.","code":""},{"path":"/reference/estimate.lvm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of parameters in a Latent Variable Model (lvm) — estimate.lvm","text":"list parameters controlling estimation optimization procedures parsed via control argument. default Maximum Likelihood used assuming multivariate normal distributed measurement errors. list one following elements expected: start: Starting value. order parameters can shown calling coef (mean=TRUE) lvm-object plot(..., labels=TRUE). Note requires check actual model estimated, estimate might add additional restriction model, e.g. fix exo.fix arguments. lvm-object fitted model can extracted Model-function. starterfun: Starter-function syntax function(lvm, S, mu).  Three builtin functions available: startvalues, startvalues0, startvalues1, ... estimator: String defining estimator use (Defaults “gaussian”) meanstructure Logical variable indicating whether fit model meanstructure. method: String pointing alternative optimizer (e.g. optim use simulated annealing). control: Parameters passed optimizer (default stats::nlminb). tol: Tolerance optimization constraints lower limit variance parameters.","code":""},{"path":[]},{"path":"/reference/estimate.lvm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimation of parameters in a Latent Variable Model (lvm) — estimate.lvm","text":"Klaus K. Holst","code":""},{"path":"/reference/estimate.lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of parameters in a Latent Variable Model (lvm) — estimate.lvm","text":"","code":"dd <- read.table(header=TRUE, text=\"x1 x2 x3  0.0 -0.5 -2.5 -0.5 -2.0  0.0  1.0  1.5  1.0  0.0  0.5  0.0 -2.5 -1.5 -1.0\") e <- estimate(lvm(c(x1,x2,x3)~u),dd)  ## Simulation example m <- lvm(list(y~v1+v2+v3+v4,c(v1,v2,v3,v4)~x)) covariance(m) <- v1~v2+v3+v4 dd <- sim(m,10000) ## Simulate 10000 observations from model e <- estimate(m, dd) ## Estimate parameters e #>                      Estimate Std. Error   Z-value  P-value #> Regressions:                                                #>    y~v1               1.00149    0.01785  56.11702   <1e-12 #>    y~v2               0.99393    0.01085  91.60386   <1e-12 #>    y~v3               1.00639    0.01103  91.22640   <1e-12 #>    y~v4               0.99367    0.01099  90.42082   <1e-12 #>     v1~x              0.99195    0.01008  98.39443   <1e-12 #>    v2~x               1.00054    0.01011  98.96869   <1e-12 #>     v3~x              0.98866    0.01020  96.95567   <1e-12 #>    v4~x               1.00539    0.00986 101.96561   <1e-12 #> Intercepts:                                                 #>    y                  0.00585    0.01001   0.58393   0.5593 #>    v1                -0.00897    0.01001  -0.89547   0.3705 #>    v2                 0.00585    0.01004   0.58266   0.5601 #>    v3                -0.01329    0.01013  -1.31181   0.1896 #>    v4                -0.01010    0.00979  -1.03097   0.3026 #> Residual Variances:                                         #>    y                  1.00198    0.01417  70.71068          #>    v1                 1.00276    0.01121  89.48353          #>    v1~~v2             0.49738    0.00864  57.55835   <1e-12 #>    v1~~v3             0.52060    0.00894  58.26409   <1e-12 #>    v1~~v4             0.48319    0.00841  57.48108   <1e-12 #>    v2                 1.00840    0.01426  70.71068          #>    v3                 1.02590    0.01451  70.71068          #>    v4                 0.95924    0.01357  70.71068           ## Using just sufficient statistics n <- nrow(dd) e0 <- estimate(m,data=list(S=cov(dd)*(n-1)/n,mu=colMeans(dd),n=n)) rm(dd)  ## Multiple group analysis m <- lvm() regression(m) <- c(y1,y2,y3)~u regression(m) <- u~x d1 <- sim(m,100,p=c(\"u,u\"=1,\"u~x\"=1)) d2 <- sim(m,100,p=c(\"u,u\"=2,\"u~x\"=-1))  mm <- baptize(m) regression(mm,u~x) <- NA covariance(mm,~u) <- NA intercept(mm,~u) <- NA ee <- estimate(list(mm,mm),list(d1,d2))  ## Missing data d0 <- makemissing(d1,cols=1:2) e0 <- estimate(m,d0,missing=TRUE) e0 #>                     Estimate Std. Error  Z value Pr(>|z|) #> Regressions:                                              #>    y1~u              1.11173    0.07587 14.65369   <1e-12 #>     y2~u             1.00679    0.07355 13.68871   <1e-12 #>    y3~u              1.03929    0.06293 16.51400   <1e-12 #>     u~x              1.14033    0.12487  9.13202   <1e-12 #> Intercepts:                                               #>    y1                0.00405    0.10782  0.03752   0.9701 #>    y2                0.10148    0.10931  0.92832   0.3532 #>    y3                0.07911    0.09085  0.87082   0.3839 #>    u                -0.03681    0.10653 -0.34549   0.7297 #> Residual Variances:                                       #>    y1                0.97632    0.15066  6.48007          #>    y2                0.96712    0.15198  6.36330          #>    y3                0.82342    0.11646  7.07021          #>    u                 1.13361    0.16033  7.07044"},{"path":"/reference/eventTime.html","id":null,"dir":"Reference","previous_headings":"","what":"Add an observed event time outcome to a latent variable model. — eventTime","title":"Add an observed event time outcome to a latent variable model. — eventTime","text":"example, model 'm' includes latent event time variables called 'T1' 'T2' 'C' end follow-(right censored), one can specify","code":""},{"path":"/reference/eventTime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add an observed event time outcome to a latent variable model. — eventTime","text":"","code":"eventTime(object, formula, eventName = \"status\", ...)"},{"path":"/reference/eventTime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add an observed event time outcome to a latent variable model. — eventTime","text":"object Model object formula Formula (see details) eventName Event names ... Additional arguments lower levels functions","code":""},{"path":"/reference/eventTime.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add an observed event time outcome to a latent variable model. — eventTime","text":"eventTime(object=m,formula=ObsTime~min(T1=,T2=b,C=0,\"ObsEvent\")) data simulated model one gets 2 new columns: - \"ObsTime\": smallest T1, T2 C - \"ObsEvent\": '' T1 smallest, 'b' T2 smallest '0' C smallest Note \"ObsEvent\" \"ObsTime\" names specified user.","code":""},{"path":"/reference/eventTime.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add an observed event time outcome to a latent variable model. — eventTime","text":"Thomas . Gerds, Klaus K. Holst","code":""},{"path":"/reference/eventTime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add an observed event time outcome to a latent variable model. — eventTime","text":"","code":"# Right censored survival data without covariates m0 <- lvm() distribution(m0,\"eventtime\") <- coxWeibull.lvm(scale=1/100,shape=2) distribution(m0,\"censtime\") <- coxExponential.lvm(rate=1/10) m0 <- eventTime(m0,time~min(eventtime=1,censtime=0),\"status\") sim(m0,10) #>    eventtime    censtime        time status #> 1   8.846923 18.79067364  8.84692274      1 #> 2  14.009893  3.39319492  3.39319492      0 #> 3  14.029624  4.81329027  4.81329027      0 #> 4  17.929567 22.09611099 17.92956695      1 #> 5  10.537679 16.55291245 10.53767868      1 #> 6   8.534200  0.06189218  0.06189218      0 #> 7   8.161939 11.85611149  8.16193939      1 #> 8   7.802480  0.31966069  0.31966069      0 #> 9  13.206909  6.78797323  6.78797323      0 #> 10 14.468739  2.16618630  2.16618630      0  # Alternative specification of the right censored survival outcome ## eventTime(m,\"Status\") <- ~min(eventtime=1,censtime=0)  # Cox regression: # lava implements two different parametrizations of the same # Weibull regression model. The first specifies # the effects of covariates as proportional hazard ratios # and works as follows: m <- lvm() distribution(m,\"eventtime\") <- coxWeibull.lvm(scale=1/100,shape=2) distribution(m,\"censtime\") <- coxWeibull.lvm(scale=1/100,shape=2) m <- eventTime(m,time~min(eventtime=1,censtime=0),\"status\") distribution(m,\"sex\") <- binomial.lvm(p=0.4) distribution(m,\"sbp\") <- normal.lvm(mean=120,sd=20) regression(m,from=\"sex\",to=\"eventtime\") <- 0.4 regression(m,from=\"sbp\",to=\"eventtime\") <- -0.01 sim(m,6) #>   eventtime   censtime       time status sex      sbp #> 1  4.503515 10.3321280  4.5035153      1   0 106.6415 #> 2  7.788162  8.9109949  7.7881625      1   0 103.8519 #> 3  9.875467  2.0632497  2.0632497      0   1 134.3462 #> 4 12.386353 12.8740043 12.3863532      1   1 107.2798 #> 5 16.413136  0.4363755  0.4363755      0   1 113.6455 #> 6 18.454376 13.7010274 13.7010274      0   0 122.3273 # The parameters can be recovered using a Cox regression # routine or a Weibull regression model. E.g., if (FALSE) { # \\dontrun{     set.seed(18)     d <- sim(m,1000)     library(survival)     coxph(Surv(time,status)~sex+sbp,data=d)      sr <- survreg(Surv(time,status)~sex+sbp,data=d)     library(SurvRegCensCov)     ConvertWeibull(sr)  } # }  # The second parametrization is an accelerated failure time # regression model and uses the function weibull.lvm instead # of coxWeibull.lvm to specify the event time distributions. # Here is an example:  ma <- lvm() distribution(ma,\"eventtime\") <- weibull.lvm(scale=3,shape=1/0.7) distribution(ma,\"censtime\") <- weibull.lvm(scale=2,shape=1/0.7) ma <- eventTime(ma,time~min(eventtime=1,censtime=0),\"status\") distribution(ma,\"sex\") <- binomial.lvm(p=0.4) distribution(ma,\"sbp\") <- normal.lvm(mean=120,sd=20) regression(ma,from=\"sex\",to=\"eventtime\") <- 0.7 regression(ma,from=\"sbp\",to=\"eventtime\") <- -0.008 set.seed(17) sim(ma,6) #>   eventtime  censtime      time status sex       sbp #> 1 0.5531481 1.1285503 0.5531481      1   1  99.69983 #> 2 4.2973225 1.4665922 1.4665922      0   1 118.40727 #> 3 1.5884110 0.4704796 0.4704796      0   1 115.34026 #> 4 1.7404946 1.2284359 1.2284359      0   1 103.65464 #> 5 0.2765550 0.8633771 0.2765550      1   1 135.44182 #> 6 1.5803203 0.6912997 0.6912997      0   0 116.68776 # The regression coefficients of the AFT model # can be tranformed into log(hazard ratios): #  coef.coxWeibull = - coef.weibull / shape.weibull if (FALSE) { # \\dontrun{     set.seed(17)     da <- sim(ma,1000)     library(survival)     fa <- coxph(Surv(time,status)~sex+sbp,data=da)     coef(fa)     c(0.7,-0.008)/0.7 } # }   # The following are equivalent parametrizations # which produce exactly the same random numbers:  model.aft <- lvm() distribution(model.aft,\"eventtime\") <- weibull.lvm(intercept=-log(1/100)/2,sigma=1/2) distribution(model.aft,\"censtime\") <- weibull.lvm(intercept=-log(1/100)/2,sigma=1/2) sim(model.aft,6,seed=17) #>   eventtime  censtime #> 1 12.552208 13.652847 #> 2 12.946401  1.792538 #> 3  4.984980  8.710482 #> 4 12.806975  5.025406 #> 5  9.133336  9.469785 #> 6 24.669793  7.863944  model.aft <- lvm() distribution(model.aft,\"eventtime\") <- weibull.lvm(scale=100^(1/2), shape=2) distribution(model.aft,\"censtime\") <- weibull.lvm(scale=100^(1/2), shape=2) sim(model.aft,6,seed=17) #>   eventtime  censtime #> 1 12.552208 13.652847 #> 2 12.946401  1.792538 #> 3  4.984980  8.710482 #> 4 12.806975  5.025406 #> 5  9.133336  9.469785 #> 6 24.669793  7.863944  model.cox <- lvm() distribution(model.cox,\"eventtime\") <- coxWeibull.lvm(scale=1/100,shape=2) distribution(model.cox,\"censtime\") <- coxWeibull.lvm(scale=1/100,shape=2) sim(model.cox,6,seed=17) #>   eventtime  censtime #> 1 12.552208 13.652847 #> 2 12.946401  1.792538 #> 3  4.984980  8.710482 #> 4 12.806975  5.025406 #> 5  9.133336  9.469785 #> 6 24.669793  7.863944  # The minimum of multiple latent times one of them still # being a censoring time, yield # right censored competing risks data  mc <- lvm() distribution(mc,~X2) <- binomial.lvm() regression(mc) <- T1~f(X1,-.5)+f(X2,0.3) regression(mc) <- T2~f(X2,0.6) distribution(mc,~T1) <- coxWeibull.lvm(scale=1/100) distribution(mc,~T2) <- coxWeibull.lvm(scale=1/100) distribution(mc,~C) <- coxWeibull.lvm(scale=1/100) mc <- eventTime(mc,time~min(T1=1,T2=2,C=0),\"event\") sim(mc,6) #>   X2        T1          X1        T2         C      time event #> 1  0  7.023211 -0.05517906 14.575911 11.814841  7.023211     1 #> 2  1  6.179319  0.83847112  5.138275  7.716248  5.138275     2 #> 3  1  5.890305  0.15937013  9.886258 12.038218  5.890305     1 #> 4  0 15.128422  0.62595440 13.871923 11.629342 11.629342     0 #> 5  1 12.075247  0.63358473  9.551212  2.196766  2.196766     0 #> 6  0 19.313957  0.68102765  7.433206  3.930187  3.930187     0"},{"path":"/reference/fplot.html","id":null,"dir":"Reference","previous_headings":"","what":"fplot — fplot","title":"fplot — fplot","text":"Faster plot via RGL","code":""},{"path":"/reference/fplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fplot — fplot","text":"","code":"fplot(   x,   y,   z = NULL,   xlab,   ylab,   ...,   z.col = topo.colors(64),   data = parent.frame(),   add = FALSE,   aspect = c(1, 1),   zoom = 0.8 )"},{"path":"/reference/fplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fplot — fplot","text":"x X variable y Y variable z Z variable (optional) xlab x-axis label ylab y-axis label ... additional arggument lower-level plot functions z.col color (use argument alpha set transparency) data data.frame add TRUE use current active device aspect aspect ratio zoom zoom level","code":""},{"path":"/reference/fplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"fplot — fplot","text":"","code":"if (interactive()) { data(iris) fplot(Sepal.Length ~ Petal.Length+Species, data=iris, size=2, type=\"s\") }"},{"path":"/reference/getMplus.html","id":null,"dir":"Reference","previous_headings":"","what":"Read Mplus output — getMplus","title":"Read Mplus output — getMplus","text":"Read Mplus output files","code":""},{"path":"/reference/getMplus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read Mplus output — getMplus","text":"","code":"getMplus(infile = \"template.out\", coef = TRUE, ...)"},{"path":"/reference/getMplus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read Mplus output — getMplus","text":"infile Mplus output file coef Coefficients ... additional arguments lower level functions","code":""},{"path":[]},{"path":"/reference/getMplus.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Read Mplus output — getMplus","text":"Klaus K. Holst","code":""},{"path":"/reference/getSAS.html","id":null,"dir":"Reference","previous_headings":"","what":"Read SAS output — getSAS","title":"Read SAS output — getSAS","text":"Run SAS code like following:","code":""},{"path":"/reference/getSAS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read SAS output — getSAS","text":"","code":"getSAS(infile, entry = \"Parameter Estimates\", ...)"},{"path":"/reference/getSAS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read SAS output — getSAS","text":"infile file (csv file generated ODS) entry Name entry capture ... additional arguments lower level functions","code":""},{"path":"/reference/getSAS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read SAS output — getSAS","text":"ODS CSVALL BODY=\"myest.csv\"; proc nlmixed data=aj qpoints=2 dampstep=0.5; ... run; ODS CSVALL Close; read results R : getsas(\"myest.csv\",\"Parameter Estimates\")","code":""},{"path":[]},{"path":"/reference/getSAS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Read SAS output — getSAS","text":"Klaus K. Holst","code":""},{"path":"/reference/gof.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract model summaries and GOF statistics for model object — gof","title":"Extract model summaries and GOF statistics for model object — gof","text":"Calculates various GOF statistics model object including global chi-squared test statistic AIC. Extract model-specific mean variance structure, residuals various predicitions.","code":""},{"path":"/reference/gof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract model summaries and GOF statistics for model object — gof","text":"","code":"gof(object, ...)  # S3 method for class 'lvmfit' gof(object, chisq=FALSE, level=0.90, rmsea.threshold=0.05,all=FALSE,...)  moments(x,...)  # S3 method for class 'lvm' moments(x, p, debug=FALSE, conditional=FALSE, data=NULL, latent=FALSE, ...)  # S3 method for class 'lvmfit' logLik(object, p=coef(object),                       data=model.frame(object),                       model=object$estimator,                       weights=Weights(object),                       data2=object$data$data2,                           ...)  # S3 method for class 'lvmfit' score(x, data=model.frame(x), p=pars(x), model=x$estimator,                    weights=Weights(x), data2=x$data$data2, ...)  # S3 method for class 'lvmfit' information(x,p=pars(x),n=x$data$n,data=model.frame(x),                    model=x$estimator,weights=Weights(x), data2=x$data$data2, ...)"},{"path":"/reference/gof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract model summaries and GOF statistics for model object — gof","text":"object Model object ... Additional arguments passed low level functions x Model object p Parameter vector used calculate statistics data Data.frame use latent TRUE predictions latent variables included output data2 Optional second data.frame (censored observations) weights Optional weight matrix n Number observations conditional TRUE conditional moments given covariates calculated. Otherwise joint moments calculated model String defining estimator, e.g. \"gaussian\" (see estimate) debug Debugging chisq Boolean indicating whether calculate chi-squared goodness--fit (always TRUE estimator='gaussian') level Level confidence limits RMSEA rmsea.threshold probability calculate, Pr(RMSEA<rmsea.treshold) Calculate (ad hoc) FIT indices: TLI, CFI, NFI, SRMR, ...","code":""},{"path":"/reference/gof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract model summaries and GOF statistics for model object — gof","text":"htest-object.","code":""},{"path":"/reference/gof.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract model summaries and GOF statistics for model object — gof","text":"Klaus K. Holst","code":""},{"path":"/reference/gof.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract model summaries and GOF statistics for model object — gof","text":"","code":"m <- lvm(list(y~v1+v2+v3+v4,c(v1,v2,v3,v4)~x)) set.seed(1) dd <- sim(m,1000) e <- estimate(m, dd) gof(e,all=TRUE,rmsea.threshold=0.05,level=0.9) #>  #>  Number of observations = 1000  #>  BIC = 14585.57  #>  AIC = 14468.26  #>  log-Likelihood of model = -7216.128  #>  #>  log-Likelihood of saturated model = -7212.5  #>  Chi-squared statistic: q = 7.254653 , df = 7  #>   P(Q>q) = 0.4028559  #>  #>  RMSEA (90% CI): 0.006 (0;0.0397) #>   P(RMSEA<0.05)=0.9916145 #>  TLI = 0.9998998  #>  CFI = 0.9999532  #>  NFI = 0.9986715  #>  SRMR = 0.008682085  #>  #> rank(Information) = 18 (p=18) #> condition(Information) = 10.37525 #> mean(score^2) = 4.216767e-09    set.seed(1) m <- lvm(list(c(y1,y2,y3)~u,y1~x)); latent(m) <- ~u regression(m,c(y2,y3)~u) <- \"b\" d <- sim(m,1000) e <- estimate(m,d) rsq(e) #> $`R-squared` #>           y1           y2           y3            u  #> 6.714238e-01 5.109812e-01 5.276472e-01 1.221245e-15  #>  #> $`Variance explained by 'u'` #>        y1        y2        y3  #> 0.3697894 0.5109812 0.5276472  #>  ##' rr <- rsq(e,TRUE) rr #>  #> R-squared: #>  #>     Estimate    Std.Err      2.5%     97.5%       P-value #> y1 0.6666507 0.02449714 0.6186372 0.7146642 4.506818e-163 #> y2 0.5062724 0.02751655 0.4523409 0.5602038  1.342309e-75 #> y3 0.5319590 0.02627482 0.4804613 0.5834567  3.855758e-91 estimate(rr,contrast=rbind(c(1,-1,0),c(1,0,-1),c(0,1,-1))) #>             Estimate Std.Err     2.5%   97.5%   P-value #> [y1] - [y2]  0.16038 0.04040  0.08119 0.23956 7.197e-05 #> [y1] - [y3]  0.13469 0.03884  0.05857 0.21081 5.244e-04 #> [y2] - [y3] -0.02569 0.02786 -0.08029 0.02891 3.565e-01 #>  #>  Null Hypothesis:  #>   [y1] - [y2] = 0 #>   [y1] - [y3] = 0 #>   [y2] - [y3] = 0  #>   #> chisq = 16.2844, df = 2, p-value = 0.000291"},{"path":"/reference/hubble.html","id":null,"dir":"Reference","previous_headings":"","what":"Hubble data — hubble","title":"Hubble data — hubble","text":"Velocity (v) distance (D) measures 36 Type Ia super-novae Hubble Space Telescope","code":""},{"path":"/reference/hubble.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Hubble data — hubble","text":"data.frame","code":""},{"path":"/reference/hubble.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Hubble data — hubble","text":"Freedman, W. L., et al. 2001, AstroPhysicalJournal, 553, 47.","code":""},{"path":"/reference/hubble2.html","id":null,"dir":"Reference","previous_headings":"","what":"Hubble data — hubble2","title":"Hubble data — hubble2","text":"Hubble data","code":""},{"path":"/reference/hubble2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Hubble data — hubble2","text":"data.frame","code":""},{"path":[]},{"path":"/reference/iid.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract i.i.d. decomposition from model object — iid","title":"Extract i.i.d. decomposition from model object — iid","text":"function extracts","code":""},{"path":"/reference/iid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract i.i.d. decomposition from model object — iid","text":"","code":"iid(x, ...)"},{"path":"/reference/iid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract i.i.d. decomposition from model object — iid","text":"x Model object ... Additional arguments (see man-page IC method)","code":""},{"path":"/reference/images.html","id":null,"dir":"Reference","previous_headings":"","what":"Organize several image calls (for visualizing categorical data) — images","title":"Organize several image calls (for visualizing categorical data) — images","text":"Visualize categorical group variable","code":""},{"path":"/reference/images.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Organize several image calls (for visualizing categorical data) — images","text":"","code":"images(   x,   group,   ncol = 2,   byrow = TRUE,   colorbar = 1,   colorbar.space = 0.1,   label.offset = 0.02,   order = TRUE,   colorbar.border = 0,   main,   rowcol = FALSE,   plotfun = NULL,   axis1,   axis2,   mar,   col = list(c(\"#EFF3FF\", \"#BDD7E7\", \"#6BAED6\", \"#2171B5\"), c(\"#FEE5D9\", \"#FCAE91\",     \"#FB6A4A\", \"#CB181D\"), c(\"#EDF8E9\", \"#BAE4B3\", \"#74C476\", \"#238B45\"), c(\"#FEEDDE\",     \"#FDBE85\", \"#FD8D3C\", \"#D94701\")),   ... )"},{"path":"/reference/images.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Organize several image calls (for visualizing categorical data) — images","text":"x data.frame matrix group group variable ncol number columns layout byrow organize row TRUE colorbar Add color bar colorbar.space Space around color bar label.offset label offset order order colorbar.border Add border around color bar main Main title rowcol switch rows columns plotfun Alternative plot function (instead 'image') axis1 Axis 1 axis2 Axis 2 mar Margins col Colours ... Additional arguments lower level graphics functions","code":""},{"path":"/reference/images.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Organize several image calls (for visualizing categorical data) — images","text":"Klaus Holst","code":""},{"path":"/reference/images.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Organize several image calls (for visualizing categorical data) — images","text":"","code":"X <- matrix(rbinom(400,3,0.5),20) group <- rep(1:4,each=5) images(X,colorbar=0,zlim=c(0,3))  images(X,group=group,zlim=c(0,3))  if (FALSE) { # \\dontrun{ images(X,group=group,col=list(RColorBrewer::brewer.pal(4,\"Purples\"),                                RColorBrewer::brewer.pal(4,\"Greys\"),                                RColorBrewer::brewer.pal(4,\"YlGn\"),                                RColorBrewer::brewer.pal(4,\"PuBuGn\")),colorbar=2,zlim=c(0,3)) } # } images(list(X,X,X,X),group=group,zlim=c(0,3))  images(list(X,X,X,X),ncol=1,group=group,zlim=c(0,3)) images(list(X,X),group,axis2=c(FALSE,FALSE),axis1=c(FALSE,FALSE),       mar=list(c(0,0,0,0),c(0,0,0,0)),yaxs=\"i\",xaxs=\"i\",zlim=c(0,3))"},{"path":"/reference/indoorenv.html","id":null,"dir":"Reference","previous_headings":"","what":"Data — indoorenv","title":"Data — indoorenv","text":"Description","code":""},{"path":"/reference/indoorenv.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data — indoorenv","text":"data.frame","code":""},{"path":"/reference/indoorenv.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data — indoorenv","text":"Simulated","code":""},{"path":"/reference/intercept.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix mean parameters in 'lvm'-object — intercept","title":"Fix mean parameters in 'lvm'-object — intercept","text":"Define linear constraints intercept parameters lvm-object.","code":""},{"path":"/reference/intercept.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix mean parameters in 'lvm'-object — intercept","text":"","code":"# S3 method for class 'lvm' intercept(object, vars, ...) <- value"},{"path":"/reference/intercept.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix mean parameters in 'lvm'-object — intercept","text":"object lvm-object ... Additional arguments vars character vector variable names value Vector (list) parameter values labels (numeric character) formula defining linear constraints (see also regression covariance methods).","code":""},{"path":"/reference/intercept.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fix mean parameters in 'lvm'-object — intercept","text":"lvm-object","code":""},{"path":"/reference/intercept.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fix mean parameters in 'lvm'-object — intercept","text":"intercept function used specify linear constraints intercept parameters latent variable model. example look multivariate regression model $$ E(Y_1|X) = \\alpha_1 + \\beta_1 X$$ $$ E(Y_2|X) = \\alpha_2 + \\beta_2 X$$ defined call m <- lvm(c(y1,y2) ~ x) fix \\(\\alpha_1=\\alpha_2\\) call intercept(m) <- c(y1,y2) ~ f(mu) Fixed parameters can reset fixing NA.  instance free parameter restriction \\(Y_1\\) time fixing \\(\\alpha_2=2\\), call intercept(m, ~y1+y2) <- list(NA,2) Calling intercept additional arguments return current intercept restrictions lvm-object.","code":""},{"path":"/reference/intercept.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fix mean parameters in 'lvm'-object — intercept","text":"Variables added model already present.","code":""},{"path":[]},{"path":"/reference/intercept.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fix mean parameters in 'lvm'-object — intercept","text":"Klaus K. Holst","code":""},{"path":"/reference/intercept.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fix mean parameters in 'lvm'-object — intercept","text":"","code":"## A multivariate model m <- lvm(c(y1,y2) ~ f(x1,beta)+x2) regression(m) <- y3 ~ f(x1,beta) intercept(m) <- y1 ~ f(mu) intercept(m, ~y2+y3) <- list(2,\"mu\") intercept(m) ## Examine intercepts of model (NA translates to free/unique paramete##r) #> Intercept parameters: #>     y1 y2 y3 #>     *  2  mu"},{"path":"/reference/internal.html","id":null,"dir":"Reference","previous_headings":"","what":"For internal use — startvalues","title":"For internal use — startvalues","text":"internal use","code":""},{"path":"/reference/internal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"For internal use — startvalues","text":"Klaus K. Holst","code":""},{"path":"/reference/intervention.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Define intervention — intervention.lvm","title":"Define intervention — intervention.lvm","text":"Define intervention `lvm` object","code":""},{"path":"/reference/intervention.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define intervention — intervention.lvm","text":"","code":"# S3 method for class 'lvm' intervention(object, to, value, dist = none.lvm(), ...)"},{"path":"/reference/intervention.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define intervention — intervention.lvm","text":"object lvm object String defining variable formula value function defining intervention dist Distribution ... Additional arguments lower level functions","code":""},{"path":[]},{"path":"/reference/intervention.lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define intervention — intervention.lvm","text":"","code":"m <- lvm(y ~ a + x, a ~ x) distribution(m, ~a+y) <- binomial.lvm() mm <- intervention(m, \"a\", value=3) sim(mm, 10) #>    y a          x #> 1  1 3  0.1758473 #> 2  1 3 -0.7003017 #> 3  1 3  0.8740681 #> 4  1 3 -0.7909800 #> 5  1 3  0.5525168 #> 6  0 3  0.3305292 #> 7  1 3 -0.8173789 #> 8  1 3 -1.0896205 #> 9  1 3 -0.4401358 #> 10 1 3 -0.1832252 mm <- intervention(m, a~x, function(x) (x>0)*1) sim(mm, 10) #>    y a           x #> 1  1 1  0.18123140 #> 2  0 0 -0.64806949 #> 3  1 1  0.30274123 #> 4  1 0 -0.92839816 #> 5  1 0 -0.44087137 #> 6  0 0 -0.37248179 #> 7  0 0 -0.81769810 #> 8  1 0 -0.57704241 #> 9  1 1  1.01409187 #> 10 1 1  0.06610547"},{"path":"/reference/ksmooth2.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot/estimate surface — ksmooth2","title":"Plot/estimate surface — ksmooth2","text":"Plot/estimate surface","code":""},{"path":"/reference/ksmooth2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot/estimate surface — ksmooth2","text":"","code":"ksmooth2(   x,   data,   h = NULL,   xlab = NULL,   ylab = NULL,   zlab = \"\",   gridsize = rep(51L, 2),   ... )"},{"path":"/reference/ksmooth2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot/estimate surface — ksmooth2","text":"x formula data data data.frame h bandwidth xlab X label ylab Y label zlab Z label gridsize grid size kernel smoother ... Additional arguments graphics routine (persp3d persp)","code":""},{"path":"/reference/ksmooth2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot/estimate surface — ksmooth2","text":"","code":"if (requireNamespace(\"KernSmooth\")) {##' ksmooth2(rmvn0(1e4,sigma=diag(2)*.5+.5),c(-3.5,3.5),h=1,         rgl=FALSE,theta=30) ##' if (interactive()) {     ksmooth2(rmvn0(1e4,sigma=diag(2)*.5+.5),c(-3.5,3.5),h=1)     ksmooth2(function(x,y) x^2+y^2, c(-20,20))     ksmooth2(function(x,y) x^2+y^2, xlim=c(-5,5), ylim=c(0,10))      f <- function(x,y) 1-sqrt(x^2+y^2)     surface(f,xlim=c(-1,1),alpha=0.9,aspect=c(1,1,0.75))     surface(f,xlim=c(-1,1),clut=heat.colors(128))     ##play3d(spin3d(axis=c(0,0,1), rpm=8), duration=5) }  if (interactive()) {     surface(function(x) dmvn0(x,sigma=diag(2)),c(-3,3),lit=FALSE,smooth=FALSE,box=FALSE,alpha=0.8)     surface(function(x) dmvn0(x,sigma=diag(2)),c(-3,3),box=FALSE,specular=\"black\")##' }  if (!inherits(try(find.package(\"fields\"),silent=TRUE),\"try-error\")) {     f <- function(x,y) 1-sqrt(x^2+y^2)     ksmooth2(f,c(-1,1),rgl=FALSE,image=fields::image.plot) }  } #> Loading required namespace: KernSmooth"},{"path":"/reference/labels-set.html","id":null,"dir":"Reference","previous_headings":"","what":"Define labels of graph — labels<-","title":"Define labels of graph — labels<-","text":"Alters labels nodes edges graph latent variable model","code":""},{"path":"/reference/labels-set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define labels of graph — labels<-","text":"","code":"# Default S3 method labels(object, ...) <- value # S3 method for class 'lvm' edgelabels(object, to, ...) <- value # Default S3 method nodecolor(object, var=vars(object), border, labcol, shape, lwd, ...) <- value"},{"path":"/reference/labels-set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define labels of graph — labels<-","text":"object lvm-object. ... Additional arguments (lwd, cex, col, labcol), border. value node label/edge label/color Formula specifying outcomes predictors defining relevant edges. var Formula character vector specifying nodes/variables alter. border Colors borders labcol Text label colors shape Shape node lwd Line width border","code":""},{"path":"/reference/labels-set.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Define labels of graph — labels<-","text":"Klaus K. Holst","code":""},{"path":"/reference/labels-set.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define labels of graph — labels<-","text":"","code":"m <- lvm(c(y,v)~x+z) regression(m) <- c(v,x)~z labels(m) <- c(y=expression(psi), z=expression(zeta)) nodecolor(m,~y+z+x,border=c(\"white\",\"white\",\"black\"),           labcol=\"white\", lwd=c(1,1,5),           lty=c(1,2)) <-  c(\"orange\",\"indianred\",\"lightgreen\") edgelabels(m,y~z+x, cex=c(2,1.5), col=c(\"orange\",\"black\"),labcol=\"darkblue\",            arrowhead=c(\"tee\",\"dot\"),            lwd=c(3,1)) <- expression(phi,rho) edgelabels(m,c(v,x)~z, labcol=\"red\", cex=0.8,arrowhead=\"none\") <- 2 if (interactive()) {     plot(m,addstyle=FALSE) }  m <- lvm(y~x) labels(m) <- list(x=\"multiple\\nlines\") if (interactive()) { op <- par(mfrow=c(1,2)) plot(m,plain=TRUE) plot(m) par(op)  d <- sim(m,100) e <- estimate(m,d) plot(e,type=\"sd\") }"},{"path":"/reference/lava-package.html","id":null,"dir":"Reference","previous_headings":"","what":"lava: Latent Variable Models — lava-package","title":"lava: Latent Variable Models — lava-package","text":"general implementation Structural Equation Models latent variables (MLE, 2SLS, composite likelihood estimators) continuous, censored, ordinal outcomes (Holst Budtz-Joergensen (2013) doi:10.1007/s00180-012-0344-y ). Mixture latent variable models non-linear latent variable models (Holst Budtz-Joergensen (2020) doi:10.1093/biostatistics/kxy082 ). package also provides methods graph exploration (d-separation, back-door criterion), simulation general non-linear latent variable models, estimation influence functions broad range statistical models. general implementation Structural Equation Models wth latent variables (MLE, 2SLS, composite likelihood estimators) continuous, censored, ordinal outcomes (Holst Budtz-Joergensen (2013) <doi:10.1007/s00180-012-0344-y>). Mixture latent variable models non-linear latent variable models (Holst Budtz-Joergensen (2020) <doi:10.1093/biostatistics/kxy082>). package also provides methods graph exploration (d-separation, back-door criterion), simulation general non-linear latent variable models, estimation influence functions broad range statistical models.","code":""},{"path":[]},{"path":"/reference/lava-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"lava: Latent Variable Models — lava-package","text":"Maintainer: Klaus K. Holst klaus@holst.contributors: Brice Ozenne [contributor] Thomas Gerds [contributor] Klaus K. Holst Maintainer: <klaus@holst.>","code":""},{"path":"/reference/lava-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"lava: Latent Variable Models — lava-package","text":"","code":"lava()"},{"path":"/reference/lava.options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set global options for lava — lava.options","title":"Set global options for lava — lava.options","text":"Extract set global parameters lava. particular optimization parameters estimate function.","code":""},{"path":"/reference/lava.options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set global options for lava — lava.options","text":"","code":"lava.options(...)"},{"path":"/reference/lava.options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set global options for lava — lava.options","text":"... Arguments","code":""},{"path":"/reference/lava.options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set global options for lava — lava.options","text":"list parameters","code":""},{"path":"/reference/lava.options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set global options for lava — lava.options","text":"param: 'relative' (factor loading variance one endogenous variables measurement model fixed one), 'absolute' (mean variance latent variables set 0 1, respectively), 'hybrid' (intercept latent variables fixed 0, factor loading least one endogenous variable measurement model fixed 1), 'none' (constraints added) layout: One 'dot','fdp','circo','twopi','neato','osage' messages: Set 0 disable various output messages ... see control parameter estimate function.","code":""},{"path":"/reference/lava.options.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set global options for lava — lava.options","text":"Klaus K. Holst","code":""},{"path":"/reference/lava.options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set global options for lava — lava.options","text":"","code":"if (FALSE) { # \\dontrun{ lava.options(iter.max=100,messages=0) } # }"},{"path":"/reference/lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize new latent variable model — lvm","title":"Initialize new latent variable model — lvm","text":"Function constructs new latent variable model object","code":""},{"path":"/reference/lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize new latent variable model — lvm","text":"","code":"lvm(x = NULL, ..., latent = NULL, messages = lava.options()$messages)"},{"path":"/reference/lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize new latent variable model — lvm","text":"x Vector variable names. Optional gives control sequence appearance variables. argument can given character vector formula, e.g. ~y1+y2 equivalent c(\"y1\",\"y2\"). Alternatively argument can formula specifying linear model. ... Additional arguments passed low level functions latent (optional) Latent variables messages Controls messages printed (0: none)","code":""},{"path":"/reference/lvm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize new latent variable model — lvm","text":"Returns object class lvm.","code":""},{"path":[]},{"path":"/reference/lvm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Initialize new latent variable model — lvm","text":"Klaus K. Holst","code":""},{"path":"/reference/lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize new latent variable model — lvm","text":"","code":"m <- lvm() # Empty model m1 <- lvm(y~x) # Simple linear regression m2 <- lvm(~y1+y2) # Model with two independent variables (argument) m3 <- lvm(list(c(y1,y2,y3)~u,u~x+z)) # SEM with three items"},{"path":"/reference/makemissing.html","id":null,"dir":"Reference","previous_headings":"","what":"Create random missing data — makemissing","title":"Create random missing data — makemissing","text":"Generates missing entries data.frame/matrix","code":""},{"path":"/reference/makemissing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create random missing data — makemissing","text":"","code":"makemissing(   data,   p = 0.2,   cols = seq_len(ncol(data)),   rowwise = FALSE,   nafun = function(x) x,   seed = NULL )"},{"path":"/reference/makemissing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create random missing data — makemissing","text":"data data.frame p Fraction missing data column cols columns (name index) alter rowwise missing occur row-wise (either none selected columns missing) nafun (Optional) function applied data.frame return (e.g. na.omit return complete-cases ) seed Random seed","code":""},{"path":"/reference/makemissing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create random missing data — makemissing","text":"data.frame","code":""},{"path":"/reference/makemissing.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create random missing data — makemissing","text":"Klaus K. Holst","code":""},{"path":"/reference/measurement.error.html","id":null,"dir":"Reference","previous_headings":"","what":"Two-stage (non-linear) measurement error — measurement.error","title":"Two-stage (non-linear) measurement error — measurement.error","text":"Two-stage measurement error","code":""},{"path":"/reference/measurement.error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two-stage (non-linear) measurement error — measurement.error","text":"","code":"measurement.error(   model1,   formula,   data = parent.frame(),   predictfun = function(mu, var, data, ...) mu[, 1]^2 + var[1],   id1,   id2,   ... )"},{"path":"/reference/measurement.error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two-stage (non-linear) measurement error — measurement.error","text":"model1 Stage 1 model formula Formula specifying observed covariates stage 2 model data data.frame predictfun Predictions used stage 2 id1 Optional id-vector stage 1 id2 Optional id-vector stage 2 ... Additional arguments lower level functions","code":""},{"path":[]},{"path":"/reference/measurement.error.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two-stage (non-linear) measurement error — measurement.error","text":"","code":"m <- lvm(c(y1,y2,y3)~u,c(y3,y4,y5)~v,u~~v,c(u,v)~x) transform(m,u2~u) <- function(x) x^2 transform(m,uv~u+v) <- prod regression(m) <- z~u2+u+v+uv+x set.seed(1) d <- sim(m,1000,p=c(\"u,u\"=1))  ## Stage 1 m1 <- lvm(c(y1[0:s],y2[0:s],y3[0:s])~1*u,c(y3[0:s],y4[0:s],y5[0:s])~1*v,u~b*x,u~~v) latent(m1) <- ~u+v e1 <- estimate(m1,d)  pp <- function(mu,var,data,...) {     cbind(u=mu[,\"u\"],u2=mu[,\"u\"]^2+var[\"u\",\"u\"],v=mu[,\"v\"],uv=mu[,\"u\"]*mu[,\"v\"]+var[\"u\",\"v\"]) } (e <- measurement.error(e1, z~1+x, data=d, predictfun=pp)) #>             Estimate Std.Err   2.5% 97.5% P-value #> (Intercept)   0.1358   27.63 -54.03 54.30  0.9961 #> x             1.1287   10.29 -19.04 21.30  0.9127 #> u             0.9437   17.91 -34.15 36.04  0.9580 #> u2            0.9374   31.05 -59.92 61.79  0.9759 #> v             1.1385   15.48 -29.21 31.48  0.9414 #> uv            1.0375   29.79 -57.34 59.42  0.9722  ## uu <- seq(-1,1,length.out=100) ## pp <- estimate(e,function(p,...) p[\"(Intercept)\"]+p[\"u\"]*uu+p[\"u2\"]*uu^2)$coefmat if (interactive()) {     plot(e,intercept=TRUE,line=0)      f <- function(p) p[1]+p[\"u\"]*u+p[\"u2\"]*u^2     u <- seq(-1,1,length.out=100)     plot(e, f, data=data.frame(u), ylim=c(-.5,2.5)) }"},{"path":"/reference/missingdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Missing data example — missingdata","title":"Missing data example — missingdata","text":"Simulated data generated model $$E(Y_i\\mid X) = X, \\quad cov(Y_1,Y_2\\mid X)=0.5$$","code":""},{"path":"/reference/missingdata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Missing data example — missingdata","text":"list data.frames","code":""},{"path":"/reference/missingdata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Missing data example — missingdata","text":"Simulated","code":""},{"path":"/reference/missingdata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Missing data example — missingdata","text":"list contains four data sets 1) Complete data 2) MCAR 3) MAR 4) MNAR (missing mechanism depends variable V correlated Y1,Y2)","code":""},{"path":"/reference/missingdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Missing data example — missingdata","text":"","code":"data(missingdata) e0 <- estimate(lvm(c(y1,y2)~b*x,y1~~y2),missingdata[[1]]) ## No missing e1 <- estimate(lvm(c(y1,y2)~b*x,y1~~y2),missingdata[[2]]) ## CC (MCAR) e2 <- estimate(lvm(c(y1,y2)~b*x,y1~~y2),missingdata[[2]],missing=TRUE) ## MCAR e3 <- estimate(lvm(c(y1,y2)~b*x,y1~~y2),missingdata[[3]]) ## CC (MAR) e4 <- estimate(lvm(c(y1,y2)~b*x,y1~~y2),missingdata[[3]],missing=TRUE) ## MAR"},{"path":"/reference/mixture.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate mixture latent variable model. — mixture","title":"Estimate mixture latent variable model. — mixture","text":"Estimate mixture latent variable model","code":""},{"path":"/reference/mixture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate mixture latent variable model. — mixture","text":"","code":"mixture(   x,   data,   k = length(x),   control = list(),   vcov = \"observed\",   names = FALSE,   ... )"},{"path":"/reference/mixture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate mixture latent variable model. — mixture","text":"x List lvm objects. single lvm object given, k-mixture model fitted (free parameters varying mixture components). data data.frame k Number mixture components control Optimization parameters (see details) #type Type EM algorithm (standard, classification, stochastic) vcov asymptotic covariance matrix (NULL omit) names TRUE returns names parameters (defining starting values) ... Additional arguments parsed lower-level functions","code":""},{"path":"/reference/mixture.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate mixture latent variable model. — mixture","text":"Estimate parameters mixture latent variable models via EM algorithm. performance EM algorithm can tuned via control argument, list subset following members can altered: start Optional starting values nstart Evaluate nstart different starting values run EM-algorithm parameters largest likelihood tol Convergence tolerance EM-algorithm.  algorithm stopped absolute change likelihood parameter (2-norm) successive iterations less tol iter.max Maximum number iterations EM-algorithm gamma Scale-(.e. number 0 1) step-size Newton-Raphson algorithm M-step trace Trace information EM-algorithm printed every traceth iteration Note algorithm can aborted time (C-c) still saved (via .exit call).","code":""},{"path":[]},{"path":"/reference/mixture.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate mixture latent variable model. — mixture","text":"Klaus K. Holst","code":""},{"path":"/reference/mixture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate mixture latent variable model. — mixture","text":"","code":"# \\donttest{ m0 <- lvm(list(y~x+z,x~z)) distribution(m0,~z) <- binomial.lvm() d <- sim(m0,2000,p=c(\"y~z\"=2,\"y~x\"=1),seed=1)  ## unmeasured confounder example m <- baptize(lvm(y~x, x~1)); intercept(m,~x+y) <- NA  if (requireNamespace('mets', quietly=TRUE)) {   set.seed(42)   M <- mixture(m,k=2,data=d,control=list(trace=1,tol=1e-6))   summary(M)   lm(y~x,d)   estimate(M,\"y~x\")   ## True slope := 1 } #> Squarem-2  #> Residual:  0.02701133   Extrapolation:  TRUE   Steplength:  1  #> Residual:  0.03759283   Extrapolation:  TRUE   Steplength:  4  #> Residual:  0.6706137   Extrapolation:  TRUE   Steplength:  16  #> Residual:  0.0202431   Extrapolation:  TRUE   Steplength:  2.070702  #> Residual:  0.001280273   Extrapolation:  TRUE   Steplength:  3.588918  #> Residual:  0.0003418473   Extrapolation:  TRUE   Steplength:  6.548224  #> Residual:  0.0001613898   Extrapolation:  TRUE   Steplength:  4.502928  #> Residual:  0.0001075834   Extrapolation:  TRUE   Steplength:  5.972323  #> Residual:  2.075601e-05   Extrapolation:  TRUE   Steplength:  3.792669  #> Residual:  2.528599e-06   Extrapolation:  TRUE   Steplength:  4.761634  #>       Estimate Std.Err   2.5% 97.5%    P-value #> [y~x]    1.048 0.03811 0.9737 1.123 1.263e-166 #>  #>  Null Hypothesis:  #>   [y~x] = 0  # }"},{"path":"/reference/modelsearch.html","id":null,"dir":"Reference","previous_headings":"","what":"Model searching — modelsearch","title":"Model searching — modelsearch","text":"Performs Wald score tests","code":""},{"path":"/reference/modelsearch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model searching — modelsearch","text":"","code":"modelsearch(x, k = 1, dir = \"forward\", type = \"all\", ...)"},{"path":"/reference/modelsearch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model searching — modelsearch","text":"x lvmfit-object k Number parameters test simultaneously. equivalence number additional associations added instead rel. dir Direction model search. \"forward\" := add associations/arrows model/graph (score tests), \"backward\" := remove associations/arrows model/graph (wald test) type equal 'correlation' consider score tests covariance parameters. equal 'regression' go direct effects  (default '' ) ... Additional arguments passed low level functions","code":""},{"path":"/reference/modelsearch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model searching — modelsearch","text":"Matrix test-statistics p-values","code":""},{"path":[]},{"path":"/reference/modelsearch.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model searching — modelsearch","text":"Klaus K. Holst","code":""},{"path":"/reference/modelsearch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model searching — modelsearch","text":"","code":"m <- lvm(); regression(m) <- c(y1,y2,y3) ~ eta; latent(m) <- ~eta regression(m) <- eta ~ x m0 <- m; regression(m0) <- y2 ~ x dd <- sim(m0,100)[,manifest(m0)] e <- estimate(m,dd); modelsearch(e,messages=0) #>  Score: S P(S>s) Index  holm BH     #>  0.04342  0.8349 y3~~x  1    0.8349 #>  0.04342  0.8349 y3~x   1    0.8349 #>  0.04342  0.8349 x~y3   1    0.8349 #>  0.04342  0.8349 y1~~y2 1    0.8349 #>  0.04342  0.8349 y1~y2  1    0.8349 #>  0.04342  0.8349 y2~y1  1    0.8349 #>  0.2946   0.5873 y1~~x  1    0.8349 #>  0.2946   0.5873 y1~x   1    0.8349 #>  0.2946   0.5873 x~y1   1    0.8349 #>  0.2946   0.5873 y2~~y3 1    0.8349 #>  0.2946   0.5873 y2~y3  1    0.8349 #>  0.2946   0.5873 y3~y2  1    0.8349 #>  0.7496   0.3866 y2~~x  1    0.8349 #>  0.7496   0.3866 y2~x   1    0.8349 #>  0.7496   0.3866 x~y2   1    0.8349 #>  0.7496   0.3866 y1~~y3 1    0.8349 #>  0.7496   0.3866 y1~y3  1    0.8349 #>  0.7496   0.3866 y3~y1  1    0.8349 modelsearch(e,messages=0,type=\"cor\") #>  Score: S P(S>s) Index  holm BH     #>  0.04342  0.8349 y3~~x  1    0.8349 #>  0.04342  0.8349 y1~~y2 1    0.8349 #>  0.2946   0.5873 y1~~x  1    0.8349 #>  0.2946   0.5873 y2~~y3 1    0.8349 #>  0.7496   0.3866 y2~~x  1    0.8349 #>  0.7496   0.3866 y1~~y3 1    0.8349"},{"path":"/reference/multinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate probabilities in contingency table — multinomial","title":"Estimate probabilities in contingency table — multinomial","text":"Estimate probabilities contingency table","code":""},{"path":"/reference/multinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate probabilities in contingency table — multinomial","text":"","code":"multinomial(   x,   data = parent.frame(),   marginal = FALSE,   transform,   vcov = TRUE,   IC = TRUE,   ... )"},{"path":"/reference/multinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate probabilities in contingency table — multinomial","text":"x Formula (matrix data.frame observations, 1 2 columns) data Optional data.frame marginal TRUE marginals estimated transform Optional transformation parameters (e.g., logit) vcov Calculate asymptotic variance (default TRUE) IC Return ic decomposition (default TRUE) ... Additional arguments lower-level functions","code":""},{"path":"/reference/multinomial.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate probabilities in contingency table — multinomial","text":"Klaus K. Holst","code":""},{"path":"/reference/multinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate probabilities in contingency table — multinomial","text":"","code":"set.seed(1) breaks <- c(-Inf,-1,0,Inf) m <- lvm(); covariance(m,pairwise=TRUE) <- ~y1+y2+y3+y4 d <- transform(sim(m,5e2),               z1=cut(y1,breaks=breaks),               z2=cut(y2,breaks=breaks),               z3=cut(y3,breaks=breaks),               z4=cut(y4,breaks=breaks))  multinomial(d[,5]) #> Call: multinomial(x = d[, 5]) #>  #> Joint probabilities: #> x #> (-Inf,-1]    (-1,0]  (0, Inf]  #>     0.154     0.350     0.496  #>  #>    Estimate Std.Err   2.5%  97.5%    P-value #> p1    0.154 0.01614 0.1224 0.1856  1.425e-21 #> p2    0.350 0.02133 0.3082 0.3918  1.669e-60 #> p3    0.496 0.02236 0.4522 0.5398 5.068e-109 (a1 <- multinomial(d[,5:6])) #> Call: multinomial(x = d[, 5:6]) #>  #> Joint probabilities: #>            z2 #> z1          (-Inf,-1] (-1,0] (0, Inf] #>   (-Inf,-1]     0.064  0.062    0.028 #>   (-1,0]        0.066  0.146    0.138 #>   (0, Inf]      0.040  0.154    0.302 #>  #> Conditional probabilities: #>            z2 #> z1           (-Inf,-1]     (-1,0]   (0, Inf] #>   (-Inf,-1] 0.41558442 0.40259740 0.18181818 #>   (-1,0]    0.18857143 0.41714286 0.39428571 #>   (0, Inf]  0.08064516 0.31048387 0.60887097 #>  #>     Estimate  Std.Err    2.5%   97.5%   P-value #> p11    0.064 0.010946 0.04255 0.08545 5.004e-09 #> p21    0.066 0.011104 0.04424 0.08776 2.780e-09 #> p31    0.040 0.008764 0.02282 0.05718 5.010e-06 #> p12    0.062 0.010785 0.04086 0.08314 8.986e-09 #> p22    0.146 0.015791 0.11505 0.17695 2.340e-20 #> p32    0.154 0.016142 0.12236 0.18564 1.425e-21 #> p13    0.028 0.007378 0.01354 0.04246 1.475e-04 #> p23    0.138 0.015424 0.10777 0.16823 3.657e-19 #> p33    0.302 0.020533 0.26176 0.34224 5.707e-49 (K1 <- kappa(a1)) ## Cohen's kappa #>       Estimate Std.Err  2.5% 97.5%   P-value #> kappa   0.2065 0.03547 0.137 0.276 5.805e-09  K2 <- kappa(d[,7:8]) ## Testing difference K1-K2: estimate(merge(K1,K2,id=TRUE),diff) #>         Estimate Std.Err     2.5%  97.5% P-value #> kappa.1  0.05756 0.04779 -0.03611 0.1512  0.2284  estimate(merge(K1,K2,id=FALSE),diff) ## Wrong std.err ignoring dependence #>         Estimate Std.Err     2.5%  97.5% P-value #> kappa.1  0.05756 0.04997 -0.04037 0.1555  0.2493 sqrt(vcov(K1)+vcov(K2)) #>            kappa #> kappa 0.04996804  ## Average of the two kappas: estimate(merge(K1,K2,id=TRUE),function(x) mean(x)) #>    Estimate Std.Err   2.5%  97.5%  P-value #> p1   0.2353 0.02603 0.1843 0.2863 1.57e-19 estimate(merge(K1,K2,id=FALSE),function(x) mean(x)) ## Independence #>    Estimate Std.Err   2.5%  97.5%  P-value #> p1   0.2353 0.02498 0.1863 0.2842 4.64e-21 ##' ## Goodman-Kruskal's gamma m2 <- lvm(); covariance(m2) <- y1~y2 breaks1 <- c(-Inf,-1,0,Inf) breaks2 <- c(-Inf,0,Inf) d2 <- transform(sim(m2,5e2),               z1=cut(y1,breaks=breaks1),               z2=cut(y2,breaks=breaks2))  (g1 <- gkgamma(d2[,3:4])) #> Call: gkgamma(x = d2[, 3:4]) #> ──────────────────────────────────────────────────────────────────────────────── #> n = 500 #>  #>       Estimate  Std.Err    2.5%   97.5%   P-value #> C      0.26654 0.013898 0.23931 0.29378 5.522e-82 #> D      0.06619 0.007974 0.05056 0.08182 1.033e-16 #> gamma  0.60214 0.053796 0.49670 0.70757 4.411e-29 ## same as if (FALSE) { # \\dontrun{ gkgamma(table(d2[,3:4])) gkgamma(multinomial(d2[,3:4])) } # }  ##partial gamma d2$x <- rbinom(nrow(d2),2,0.5) gkgamma(z1~z2|x,data=d2) #> Call: gkgamma(x = z1 ~ z2 | x, data = d2) #> ──────────────────────────────────────────────────────────────────────────────── #> Strata: #>  #> 0 (n=112): #>   Estimate Std.Err    2.5%   97.5%   P-value #> C  0.29464 0.02999 0.23587 0.35342 8.758e-23 #> D  0.04624 0.01379 0.01921 0.07326 7.981e-04 #>  #> 1 (n=248): #>   Estimate Std.Err    2.5%  97.5%   P-value #> C  0.24340 0.01958 0.20502 0.2818 1.797e-35 #> D  0.08126 0.01256 0.05665 0.1059 9.786e-11 #>  #> 2 (n=140): #>   Estimate Std.Err    2.5%  97.5%   P-value #> C  0.28520 0.02604 0.23417 0.3362 6.415e-28 #> D  0.05806 0.01436 0.02992 0.0862 5.261e-05 #>  #> ──────────────────────────────────────────────────────────────────────────────── #>  #> n = 500 #>  #> Gamma coefficient: #>  #>        Estimate Std.Err   2.5%  97.5%   P-value #> γ:0      0.7287 0.09062 0.5511 0.9063 8.894e-16 #> γ:1      0.4994 0.08649 0.3299 0.6689 7.744e-09 #> γ:2      0.6617 0.09293 0.4796 0.8439 1.076e-12 #> pgamma   0.5663 0.06074 0.4473 0.6854 1.126e-20"},{"path":"/reference/mvnmix.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate mixture latent variable model — mvnmix","title":"Estimate mixture latent variable model — mvnmix","text":"Estimate mixture latent variable model","code":""},{"path":"/reference/mvnmix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate mixture latent variable model — mvnmix","text":"","code":"mvnmix(   data,   k = 2,   theta,   steps = 500,   tol = 1e-16,   lambda = 0,   mu = NULL,   silent = TRUE,   extra = FALSE,   n.start = 1,   init = \"kmpp\",   ... )"},{"path":"/reference/mvnmix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate mixture latent variable model — mvnmix","text":"data data.frame k Number mixture components theta Optional starting values steps Maximum number iterations tol Convergence tolerance EM algorithm lambda Regularisation parameter. Added diagonal covariance matrix (avoid singularities) mu Initial centres (unspecified random centres chosen) silent Turn /output messages extra Extra debug information n.start Number restarts init Function choose initial centres ... Additional arguments parsed lower-level functions","code":""},{"path":"/reference/mvnmix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate mixture latent variable model — mvnmix","text":"mixture object","code":""},{"path":"/reference/mvnmix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate mixture latent variable model — mvnmix","text":"Estimate parameters mixture latent variable models via EM algorithm.","code":""},{"path":[]},{"path":"/reference/mvnmix.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate mixture latent variable model — mvnmix","text":"Klaus K. Holst","code":""},{"path":"/reference/mvnmix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate mixture latent variable model — mvnmix","text":"","code":"data(faithful) set.seed(1) M1 <- mvnmix(faithful[,\"waiting\",drop=FALSE],k=2) M2 <- mvnmix(faithful,k=2) if (interactive()) {     par(mfrow=c(2,1))     plot(M1,col=c(\"orange\",\"blue\"),ylim=c(0,0.05))     plot(M2,col=c(\"orange\",\"blue\")) }"},{"path":"/reference/nldata.html","id":null,"dir":"Reference","previous_headings":"","what":"Example data (nonlinear model) — nldata","title":"Example data (nonlinear model) — nldata","text":"Example data (nonlinear model)","code":""},{"path":"/reference/nldata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example data (nonlinear model) — nldata","text":"data.frame","code":""},{"path":"/reference/nldata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example data (nonlinear model) — nldata","text":"Simulated","code":""},{"path":"/reference/nsem.html","id":null,"dir":"Reference","previous_headings":"","what":"Example SEM data (nonlinear) — nsem","title":"Example SEM data (nonlinear) — nsem","text":"Simulated data","code":""},{"path":"/reference/nsem.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example SEM data (nonlinear) — nsem","text":"data.frame","code":""},{"path":"/reference/nsem.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example SEM data (nonlinear) — nsem","text":"Simulated","code":""},{"path":"/reference/op_concat.html","id":null,"dir":"Reference","previous_headings":"","what":"Concatenation operator — %++%","title":"Concatenation operator — %++%","text":"matrices block-diagonal matrix created. data types operator wrapper paste.","code":""},{"path":"/reference/op_concat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Concatenation operator — %++%","text":"","code":"x %++% y"},{"path":"/reference/op_concat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Concatenation operator — %++%","text":"x First object y Second object class","code":""},{"path":"/reference/op_concat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Concatenation operator — %++%","text":"Concatenation operator","code":""},{"path":[]},{"path":"/reference/op_concat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Concatenation operator — %++%","text":"Klaus K. Holst","code":""},{"path":"/reference/op_concat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Concatenation operator — %++%","text":"","code":"## Block diagonal matrix(rnorm(25),5)%++%matrix(rnorm(25),5) #>             [,1]       [,2]       [,3]       [,4]        [,5]         [,6] #>  [1,] -0.5428883  0.9921604  0.5607461 -1.5637821 -0.37670272  0.000000000 #>  [2,] -0.4333103 -0.4295131 -0.4527840  1.1565370  2.44136463  0.000000000 #>  [3,] -0.6494716  1.2383041 -0.8320433  0.8320471 -0.79533912  0.000000000 #>  [4,]  0.7267507 -0.2793463 -1.1665705 -0.2273287 -0.05487747  0.000000000 #>  [5,]  1.1519118  1.7579031 -1.0655906  0.2661374  0.25014132  0.000000000 #>  [6,]  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 -0.928567035 #>  [7,]  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 -0.294720447 #>  [8,]  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000 -0.005767173 #>  [9,]  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000  2.404653389 #> [10,]  0.0000000  0.0000000  0.0000000  0.0000000  0.00000000  0.763593461 #>             [,7]       [,8]        [,9]       [,10] #>  [1,]  0.0000000  0.0000000  0.00000000  0.00000000 #>  [2,]  0.0000000  0.0000000  0.00000000  0.00000000 #>  [3,]  0.0000000  0.0000000  0.00000000  0.00000000 #>  [4,]  0.0000000  0.0000000  0.00000000  0.00000000 #>  [5,]  0.0000000  0.0000000  0.00000000  0.00000000 #>  [6,] -0.7990092  0.2522234  0.37739565  1.08576936 #>  [7,] -1.1476570 -0.8919211  0.13333636 -0.69095384 #>  [8,] -0.2894616  0.4356833  0.80418951 -1.28459935 #>  [9,] -0.2992151 -1.2375384 -0.05710677  0.04672617 #> [10,] -0.4115108 -0.2242679  0.50360797 -0.23570656 ## String concatenation \"Hello \"%++%\" World\" #> [1] \"Hello  World\" ## Function composition f <- log %++% exp f(2) #> [1] 2"},{"path":"/reference/op_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Matching operator (x not in y) oposed to the %in%-operator (x in y) — %ni%","title":"Matching operator (x not in y) oposed to the %in%-operator (x in y) — %ni%","text":"Matching operator","code":""},{"path":"/reference/op_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matching operator (x not in y) oposed to the %in%-operator (x in y) — %ni%","text":"","code":"x %ni% y"},{"path":"/reference/op_match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matching operator (x not in y) oposed to the %in%-operator (x in y) — %ni%","text":"x vector y vector type x","code":""},{"path":"/reference/op_match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matching operator (x not in y) oposed to the %in%-operator (x in y) — %ni%","text":"logical vector.","code":""},{"path":[]},{"path":"/reference/op_match.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Matching operator (x not in y) oposed to the %in%-operator (x in y) — %ni%","text":"Klaus K. Holst","code":""},{"path":"/reference/op_match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matching operator (x not in y) oposed to the %in%-operator (x in y) — %ni%","text":"","code":"1:10 %ni% c(1,5,10) #>  [1] FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE"},{"path":"/reference/ordinal-set.html","id":null,"dir":"Reference","previous_headings":"","what":"Define variables as ordinal — ordinal<-","title":"Define variables as ordinal — ordinal<-","text":"Define variables ordinal latent variable model object","code":""},{"path":"/reference/ordinal-set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define variables as ordinal — ordinal<-","text":"","code":"ordinal(x, ...) <- value"},{"path":"/reference/ordinal-set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define variables as ordinal — ordinal<-","text":"x Object ... additional arguments lower level functions value variable (formula character vector)","code":""},{"path":"/reference/ordinal-set.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define variables as ordinal — ordinal<-","text":"","code":"if (requireNamespace(\"mets\")) { m <- lvm(y + z ~ x + 1*u[0], latent=~u) ordinal(m, K=3) <- ~y+z d <- sim(m, 100, seed=1) e <- estimate(m, d) }"},{"path":"/reference/ordreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Univariate cumulative link regression models — ordreg","title":"Univariate cumulative link regression models — ordreg","text":"Ordinal regression models","code":""},{"path":"/reference/ordreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Univariate cumulative link regression models — ordreg","text":"","code":"ordreg(   formula,   data = parent.frame(),   offset,   family = stats::binomial(\"probit\"),   start,   fast = FALSE,   ... )"},{"path":"/reference/ordreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Univariate cumulative link regression models — ordreg","text":"formula formula data data.frame offset offset family family (default proportional odds) start optional starting values fast TRUE standard errors etc. calculated ... Additional arguments lower level functions","code":""},{"path":"/reference/ordreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Univariate cumulative link regression models — ordreg","text":"Klaus K. Holst","code":""},{"path":"/reference/ordreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Univariate cumulative link regression models — ordreg","text":"","code":"m <- lvm(y~x) ordinal(m,K=3) <- ~y d <- sim(m,100) e <- ordreg(y~x,d)"},{"path":"/reference/parpos.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic method for finding indeces of model parameters — parpos","title":"Generic method for finding indeces of model parameters — parpos","text":"Generic method finding indeces model parameters","code":""},{"path":"/reference/parpos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic method for finding indeces of model parameters — parpos","text":"","code":"parpos(x, ...)"},{"path":"/reference/parpos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic method for finding indeces of model parameters — parpos","text":"x Model object ... Additional arguments","code":""},{"path":"/reference/parpos.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generic method for finding indeces of model parameters — parpos","text":"Klaus K. Holst","code":""},{"path":"/reference/partialcor.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate partial correlations — partialcor","title":"Calculate partial correlations — partialcor","text":"Calculate partial correlation coefficients confidence limits via Fishers z-transform","code":""},{"path":"/reference/partialcor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate partial correlations — partialcor","text":"","code":"partialcor(formula, data, level = 0.95, ...)"},{"path":"/reference/partialcor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate partial correlations — partialcor","text":"formula formula speciying covariates optionally outcomes calculate partial correlation data data.frame level Level confidence limits ... Additional arguments lower level functions","code":""},{"path":"/reference/partialcor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate partial correlations — partialcor","text":"coefficient matrix","code":""},{"path":"/reference/partialcor.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate partial correlations — partialcor","text":"Klaus K. Holst","code":""},{"path":"/reference/partialcor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate partial correlations — partialcor","text":"","code":"m <- lvm(c(y1,y2,y3)~x1+x2) covariance(m) <- c(y1,y2,y3)~y1+y2+y3 d <- sim(m,500) partialcor(~x1+x2,d) #>             cor        z         pval   lowerCI   upperCI #> y1~y2 0.5359140 13.30023 2.307666e-40 0.4701186 0.5957859 #> y1~y3 0.5145458 12.64428 1.203234e-36 0.4468121 0.5764142 #> y2~y3 0.5320687 13.18067 1.133819e-39 0.4659177 0.5923050"},{"path":"/reference/path.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract pathways in model graph — path","title":"Extract pathways in model graph — path","text":"Extract possible paths one variable another connected component latent variable model. estimated model effect size decomposed direct, indirect total effects including approximate standard errors.","code":""},{"path":"/reference/path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract pathways in model graph — path","text":"","code":"# S3 method for class 'lvm' path (object, to = NULL, from, all=FALSE, ...) # S3 method for class 'lvmfit' effects (object, to, from, ...)"},{"path":"/reference/path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract pathways in model graph — path","text":"object Model object (lvm) ... Additional arguments passed low level functions Outcome variable (string). Alternatively formula specifying response predictor case argument ignored. Response variable (string), necessarily directly affected . TRUE simple paths (undirected graph) returned /.","code":""},{"path":"/reference/path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract pathways in model graph — path","text":"object class lvmfit list following elements returned idx list element defines possible pathway via integer vector indicating index visited nodes. V List covariance matrices path. coef list parameters estimates path path list element defines possible pathway via character vector naming visited nodes order. edges Description 'comp2' object class lvm path element returned. effects method returns object class effects.","code":""},{"path":"/reference/path.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract pathways in model graph — path","text":"lvmfit-object parameters estimates corresponding covariance matrix also returned.  effects-function additionally calculates total indirect effects approximate standard errors","code":""},{"path":[]},{"path":"/reference/path.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract pathways in model graph — path","text":"Klaus K. Holst","code":""},{"path":"/reference/path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract pathways in model graph — path","text":"","code":"m <- lvm(c(y1,y2,y3)~eta) regression(m) <- y2~x1 latent(m) <- ~eta regression(m) <- eta~x1+x2 d <- sim(m,500) e <- estimate(m,d)  path(Model(e),y2~x1) #> [[1]] #> [1] \"x1\" \"y2\" #>  #> [[2]] #> [1] \"x1\"  \"eta\" \"y2\"  #>  parents(Model(e), ~y2) #> [1] \"eta\" \"x1\"  children(Model(e), ~x2) #> [1] \"eta\" children(Model(e), ~x2+eta) #> [1] \"eta\" \"y1\"  \"y2\"  \"y3\"  effects(e,y2~x1) #>           Estimate Std.Err z value   Pr(>|z|) #> Total       1.9889 0.06350   31.32 2.310e-215 #> Direct      0.9381 0.07042   13.32  1.759e-40 #> Indirect    1.0508 0.07242   14.51  1.066e-47 #> y2~eta~x1   1.0508 0.07242   14.51  1.066e-47 #>  #>                      Estimate   2.5%  97.5% #> Mediation proportion   0.5283 0.4653 0.5913 ## All simple paths (undirected) path(m,y1~x1,all=TRUE) #> [[1]] #> [1] \"x1\"  \"y2\"  \"eta\" \"y1\"  #>  #> [[2]] #> [1] \"x1\"  \"eta\" \"y1\"  #>"},{"path":"/reference/pcor.html","id":null,"dir":"Reference","previous_headings":"","what":"Polychoric correlation — pcor","title":"Polychoric correlation — pcor","text":"Maximum likelhood estimates polychoric correlations","code":""},{"path":"/reference/pcor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polychoric correlation — pcor","text":"","code":"pcor(x, y, X, start, ...)"},{"path":"/reference/pcor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polychoric correlation — pcor","text":"x Variable 1 y Variable 2 X Optional covariates start Optional starting values ... Additional arguments lower level functions","code":""},{"path":"/reference/pdfconvert.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert pdf to raster format — pdfconvert","title":"Convert pdf to raster format — pdfconvert","text":"Convert PDF file print quality png (default 300 dpi)","code":""},{"path":"/reference/pdfconvert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert pdf to raster format — pdfconvert","text":"","code":"pdfconvert(   files,   dpi = 300,   resolution = 1024,   gs,   gsopt,   resize,   format = \"png\",   ... )"},{"path":"/reference/pdfconvert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert pdf to raster format — pdfconvert","text":"files Vector (pdf-)filenames process dpi DPI resolution Resolution raster image file gs Optional ghostscript command gsopt Optional ghostscript arguments resize Optional resize arguments (mogrify) format Raster format (e.g. png, jpg, tif, ...) ... Additional arguments","code":""},{"path":"/reference/pdfconvert.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert pdf to raster format — pdfconvert","text":"Access ghostscript program 'gs' needed","code":""},{"path":[]},{"path":"/reference/pdfconvert.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert pdf to raster format — pdfconvert","text":"Klaus K. Holst","code":""},{"path":"/reference/plot.estimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for 'estimate' objects — plot.estimate","title":"Plot method for 'estimate' objects — plot.estimate","text":"Plot method 'estimate' objects","code":""},{"path":"/reference/plot.estimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for 'estimate' objects — plot.estimate","text":"","code":"# S3 method for class 'estimate' plot(   x,   f,   idx,   intercept = FALSE,   data,   confint = TRUE,   type = \"l\",   xlab = \"x\",   ylab = \"f(x)\",   col = 1,   add = FALSE,   ... )"},{"path":"/reference/plot.estimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for 'estimate' objects — plot.estimate","text":"x estimate object f function parameter coefficients data parsed 'estimate'. omitted forest-plot produced. idx Index parameters (default ) intercept include intercept forest-plot data data.frame confint Add confidence limits type plot type ('l') xlab x-axis label ylab y-axis label col color add add plot current device ... additional arguments lower-level functions","code":""},{"path":"/reference/plot.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot path diagram — plot.lvm","title":"Plot path diagram — plot.lvm","text":"Plot path diagram SEM","code":""},{"path":"/reference/plot.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot path diagram — plot.lvm","text":"","code":"# S3 method for class 'lvm' plot(   x,   diag = FALSE,   cor = TRUE,   labels = FALSE,   intercept = FALSE,   addcolor = TRUE,   plain = FALSE,   cex,   fontsize1 = 10,   noplot = FALSE,   graph = list(rankdir = \"BT\"),   attrs = list(graph = graph),   unexpr = FALSE,   addstyle = TRUE,   plot.engine = lava.options()$plot.engine,   init = TRUE,   layout = lava.options()$layout,   edgecolor = lava.options()$edgecolor,   graph.proc = lava.options()$graph.proc,   ... )"},{"path":"/reference/plot.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot path diagram — plot.lvm","text":"x Model object diag Logical argument indicating whether visualize variance parameters (.e. diagonal variance matrix) cor Logical argument indicating whether visualize correlation parameters labels Logical argument indiciating whether add labels plot (Unnamed parameters labeled p1,p2,...) intercept Logical argument indiciating whether add intercept labels addcolor Logical argument indiciating whether add colors plot (overrides nodecolor calls) plain TRUE strip plot colors boxes cex Fontsize node labels fontsize1 Fontsize edge labels noplot TRUE return graphNEL object graph Graph attributes (Rgraphviz) attrs Attributes (Rgraphviz) unexpr TRUE remove expressions labels addstyle Logical argument indicating whether additional style automatically added plot (e.g. dashed lines double-headed arrows) plot.engine default 'Rgraphviz' available, otherwise visNetwork,igraph init Reinitialize graph (internal use) layout Graph layout (see Rgraphviz igraph manual) edgecolor TRUE plot style colored edges graph.proc Function post-process graph object (default: subscripts automatically added labels nodes) ... Additional arguments passed low level functions","code":""},{"path":"/reference/plot.lvm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot path diagram — plot.lvm","text":"Klaus K. Holst","code":""},{"path":"/reference/plot.lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot path diagram — plot.lvm","text":"","code":"if (interactive()) { m <- lvm(c(y1,y2) ~ eta) regression(m) <- eta ~ z+x2 regression(m) <- c(eta,z) ~ x1 latent(m) <- ~eta labels(m) <- c(y1=expression(y[scriptscriptstyle(1)]), y2=expression(y[scriptscriptstyle(2)]), x1=expression(x[scriptscriptstyle(1)]), x2=expression(x[scriptscriptstyle(2)]), eta=expression(eta)) edgelabels(m, eta ~ z+x1+x2, cex=2, lwd=3,            col=c(\"orange\",\"lightblue\",\"lightblue\")) <- expression(rho,phi,psi) nodecolor(m, vars(m), border=\"white\", labcol=\"darkblue\") <- NA nodecolor(m, ~y1+y2+z, labcol=c(\"white\",\"white\",\"black\")) <- NA plot(m,cex=1.5)  d <- sim(m,100) e <- estimate(m,d) plot(e)  m <- lvm(c(y1,y2) ~ eta) regression(m) <- eta ~ z+x2 regression(m) <- c(eta,z) ~ x1 latent(m) <- ~eta plot(lava:::beautify(m,edgecol=FALSE)) }"},{"path":"/reference/plot.sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for simulation 'sim' objects — plot.sim","title":"Plot method for simulation 'sim' objects — plot.sim","text":"Density scatter plots","code":""},{"path":"/reference/plot.sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for simulation 'sim' objects — plot.sim","text":"","code":"# S3 method for class 'sim' plot(   x,   estimate,   se = NULL,   true = NULL,   names = NULL,   auto.layout = TRUE,   byrow = FALSE,   type = \"p\",   ask = grDevices::dev.interactive(),   col = c(\"gray60\", \"orange\", \"darkblue\", \"seagreen\", \"darkred\"),   pch = 16,   cex = 0.5,   lty = 1,   lwd = 0.3,   legend,   legendpos = \"topleft\",   cex.legend = 0.8,   plot.type = c(\"multiple\", \"single\"),   polygon = TRUE,   density = 0,   angle = -45,   cex.axis = 0.8,   alpha = 0.2,   main,   cex.main = 1,   equal = FALSE,   delta = 1.15,   ylim = NULL,   xlim = NULL,   ylab = \"\",   xlab = \"\",   rug = FALSE,   rug.alpha = 0.5,   line.col = scatter.col,   line.lwd = 1,   line.lty = 1,   line.alpha = 1,   scatter.ylab = \"Estimate\",   scatter.ylim = NULL,   scatter.xlim = NULL,   scatter.alpha = 0.5,   scatter.col = col,   border = col,   true.lty = 2,   true.col = \"gray70\",   true.lwd = 1.2,   density.plot = TRUE,   scatter.plot = FALSE,   running.mean = scatter.plot,   ... )"},{"path":"/reference/plot.sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for simulation 'sim' objects — plot.sim","text":"x sim object estimate columns estimates se columns standard error estimates true (optional) vector true parameter values names (optional) names estimates auto.layout Auto layout (default TRUE) byrow Add new plots layout row type plot type ask TRUE user asked input, new figure drawn col colour (estimate) pch plot symbol cex point size lty line type lwd line width legend legend legendpos legend position cex.legend size legend text plot.type 'single' 'multiple' (default) polygon TRUE fill density estimates colour density non-zero add shading lines polygon angle shading lines angle polygon cex.axis Font size axis alpha Semi-transparent level (1: non-transparent, 0: full) main Main title cex.main Size title font equal x-axis y-axis plots delta Controls amount space around axis limits ylim y-axis limits xlim x-axis limits ylab y axis label xlab x axis label rug TRUE add rug representation data x-axis rug.alpha rug semi-transparency level line.col line colour (running mean, scatter plots) line.lwd line width (running mean, scatter plots) line.lty line type (running mean, scatter plots) line.alpha line transparency scatter.ylab y label density plots scatter.ylim y-axis limits density plots scatter.xlim x-axis limits density plots scatter.alpha semi-transparency scatter plot scatter.col scatter plot colour border border colour density estimates true.lty true parameter estimate line type true.col true parameter colour true.lwd true parameter line width density.plot TRUE add density plot scatter.plot TRUE add scatter plot running.mean TRUE add running average estimate scatter plot ... additional arguments lower level functions","code":""},{"path":"/reference/plot.sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for simulation 'sim' objects — plot.sim","text":"","code":"n <- 1000 val <- cbind(est1=rnorm(n,sd=1),est2=rnorm(n,sd=0.2),est3=rnorm(n,1,sd=0.5),              sd1=runif(n,0.8,1.2),sd2=runif(n,0.1,0.3),sd3=runif(n,0.25,0.75))  plot.sim(val,estimate=c(1,2),true=c(0,0),se=c(4,5),equal=TRUE,scatter.plot=TRUE)  plot.sim(val,estimate=c(1,3),true=c(0,1),se=c(4,6),xlim=c(-3,3),   scatter.ylim=c(-3,3),scatter.plot=TRUE)  plot.sim(val,estimate=c(1,2),true=c(0,0),se=c(4,5),equal=TRUE,   plot.type=\"single\",scatter.plot=TRUE)  plot.sim(val,estimate=c(1),se=c(4,5,6),plot.type=\"single\",scatter.plot=TRUE)  plot.sim(val,estimate=c(1,2,3),equal=TRUE,scatter.plot=TRUE)  plot.sim(val,estimate=c(1,2,3),equal=TRUE,byrow=TRUE,scatter.plot=TRUE)  plot.sim(val,estimate=c(1,2,3),plot.type=\"single\",scatter.plot=TRUE)  plot.sim(val,estimate=1,se=c(3,4,5),plot.type=\"single\",scatter.plot=TRUE)   density.sim(val,estimate=c(1,2,3),density=c(0,10,10), lwd=2, angle=c(0,45,-45),cex.legend=1.3)"},{"path":"/reference/plotConf.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot regression lines — plotConf","title":"Plot regression lines — plotConf","text":"Plot regression line (interactions) partial residuals.","code":""},{"path":"/reference/plotConf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot regression lines — plotConf","text":"","code":"plotConf(   model,   var1 = NULL,   var2 = NULL,   data = NULL,   ci.lty = 0,   ci = TRUE,   level = 0.95,   pch = 16,   lty = 1,   lwd = 2,   npoints = 100,   xlim,   col = NULL,   colpt,   alpha = 0.5,   cex = 1,   delta = 0.07,   centermark = 0.03,   jitter = 0.2,   cidiff = FALSE,   mean = TRUE,   legend = ifelse(is.null(var1), FALSE, \"topright\"),   trans = function(x) {      x  },   partres = inherits(model, \"lm\"),   partse = FALSE,   labels,   vcov,   predictfun,   plot = TRUE,   new = TRUE,   ... )"},{"path":"/reference/plotConf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot regression lines — plotConf","text":"model Model object (e.g. lm) var1 predictor (Continuous factor) var2 Factor interacts var1 data data.frame use prediction (model.frame used default) ci.lty Line type confidence limits ci Boolean indicating wether draw pointwise 95% confidence limits level Level confidence limits (default 95%) pch Point type partial residuals lty Line type estimated regression lines lwd Line width regression lines npoints Number points used plot curves xlim Range x axis col Color (level var2) colpt Color partial residual points alpha Alpha level cex Point size delta categorical var1 centermark categorical var1 jitter categorical var1 cidiff categorical var1 mean categorical var1 legend Boolean (add legend) trans Transform estimates (e.g. exponential) partres Boolean indicating whether plot partial residuals partse . labels Optional labels var2 vcov Optional variance estimates predictfun Optional predict-function used calculate confidence limits predictions plot FALSE return predictions confidence bands new FALSE add current plot ... additional arguments lower level functions","code":""},{"path":"/reference/plotConf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot regression lines — plotConf","text":"list following members: x Variable x-axis (var1) y Variable y-axis (partial residuals) predict Matrix confidence limits predicted values","code":""},{"path":[]},{"path":"/reference/plotConf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot regression lines — plotConf","text":"Klaus K. Holst","code":""},{"path":"/reference/plotConf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot regression lines — plotConf","text":"","code":"n <- 100 x0 <- rnorm(n) x1 <- seq(-3,3, length.out=n) x2 <- factor(rep(c(1,2),each=n/2), labels=c(\"A\",\"B\")) y <- 5 + 2*x0 + 0.5*x1 + -1*(x2==\"B\")*x1 + 0.5*(x2==\"B\") + rnorm(n, sd=0.25) dd <- data.frame(y=y, x1=x1, x2=x2) lm0 <- lm(y ~ x0 + x1*x2, dd) plotConf(lm0, var1=\"x1\", var2=\"x2\") abline(a=5,b=0.5,col=\"red\") abline(a=5.5,b=-0.5,col=\"red\")  ### points(5+0.5*x1 -1*(x2==\"B\")*x1 + 0.5*(x2==\"B\") ~ x1, cex=2)  data(iris) l <- lm(Sepal.Length ~ Sepal.Width*Species,iris) plotConf(l,var2=\"Species\")  plotConf(l,var1=\"Sepal.Width\",var2=\"Species\")   if (FALSE) { # \\dontrun{ ## lme4 model dd$Id <- rbinom(n, size = 3, prob = 0.3) lmer0 <- lme4::lmer(y ~ x0 + x1*x2 + (1|Id), dd) plotConf(lmer0, var1=\"x1\", var2=\"x2\") } # }"},{"path":"/reference/predict.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction in structural equation models — predict.lvm","title":"Prediction in structural equation models — predict.lvm","text":"Prediction structural equation models","code":""},{"path":"/reference/predict.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction in structural equation models — predict.lvm","text":"","code":"# S3 method for class 'lvm' predict(   object,   x = NULL,   y = NULL,   residual = FALSE,   p,   data,   path = FALSE,   quick = is.null(x) & !(residual | path),   ... )"},{"path":"/reference/predict.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction in structural equation models — predict.lvm","text":"object Model object x optional list (endogenous) variables condition y optional subset variables predict residual true residuals predicted p Parameter vector data Data use prediction path Path prediction quick TRUE conditional mean variance given covariates returned (calculations skipped) ... Additional arguments lower level function","code":""},{"path":[]},{"path":"/reference/predict.lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction in structural equation models — predict.lvm","text":"","code":"m <- lvm(list(c(y1,y2,y3)~u,u~x)); latent(m) <- ~u d <- sim(m,100) e <- estimate(m,d)  ## Conditional mean (and variance as attribute) given covariates r <- predict(e) ## Best linear unbiased predictor (BLUP) r <- predict(e,vars(e)) ##  Conditional mean of y3 giving covariates and y1,y2 r <- predict(e,y3~y1+y2) ##  Conditional mean  gives covariates and y1 r <- predict(e,~y1) ##  Predicted residuals (conditional on all observed variables) r <- predict(e,vars(e),residual=TRUE)"},{"path":"/reference/predictlvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict function for latent variable models — predictlvm","title":"Predict function for latent variable models — predictlvm","text":"Predictions conditinoal mean variance calculation jacobian respect parameter vector.","code":""},{"path":"/reference/predictlvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict function for latent variable models — predictlvm","text":"","code":"predictlvm(object, formula, p = coef(object), data = model.frame(object), ...)"},{"path":"/reference/predictlvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict function for latent variable models — predictlvm","text":"object Model object formula Formula specifying variables predict condition p Parameter vector data Data.frame ... Additional arguments lower level functions","code":""},{"path":[]},{"path":"/reference/predictlvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict function for latent variable models — predictlvm","text":"","code":"m <- lvm(c(x1,x2,x3)~u1,u1~z,          c(y1,y2,y3)~u2,u2~u1+z) latent(m) <- ~u1+u2 d <- simulate(m,10,\"u2,u2\"=2,\"u1,u1\"=0.5,seed=123) e <- estimate(m,d)  ## Conditional mean given covariates predictlvm(e,c(x1,x2)~1)$mean #>                x1           x2 #>  [1,] -0.17634038  0.001097242 #>  [2,]  0.22409175  0.370702775 #>  [3,] -0.64578819 -0.432210919 #>  [4,]  2.17930239  2.175394823 #>  [5,]  1.38879089  1.445739518 #>  [6,] -0.52874258 -0.324175875 #>  [7,]  0.06371187  0.222669470 #>  [8,]  0.01125438  0.174250335 #>  [9,]  1.03672161  1.120773697 #> [10,]  0.32654483  0.465268679 ## Conditional variance of u1,y1 given x1,x2 predictlvm(e,c(u1,y1)~x1+x2)$var #>            u1         y1 #> u1 0.17501758 0.09920436 #> y1 0.09920436 0.89761525"},{"path":"/reference/rbind.Surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Appending Surv objects — rbind.Surv","title":"Appending Surv objects — rbind.Surv","text":"rbind method Surv objects","code":""},{"path":"/reference/rbind.Surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Appending Surv objects — rbind.Surv","text":"","code":"# S3 method for class 'Surv' rbind(...)"},{"path":"/reference/rbind.Surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Appending Surv objects — rbind.Surv","text":"... Surv objects","code":""},{"path":"/reference/rbind.Surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Appending Surv objects — rbind.Surv","text":"Surv object","code":""},{"path":"/reference/rbind.Surv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Appending Surv objects — rbind.Surv","text":"Klaus K. Holst","code":""},{"path":"/reference/rbind.Surv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Appending Surv objects — rbind.Surv","text":"","code":"y <- yl <- yr <- rnorm(10) yl[1:5] <- NA; yr[6:10] <- NA S1 <- survival::Surv(yl,yr,type=\"interval2\") S2 <- survival::Surv(y,y>0,type=\"right\") S3 <- survival::Surv(y,y<0,type=\"left\")  rbind(S1,S1) #>  [1]  1.13176967- -1.30350912- -0.65058095- -0.98595731-  1.66846313- #>  [6]  0.08767241+  0.82288646+  0.71012082+  0.51054011+ -0.72494378+ #> [11]  1.13176967- -1.30350912- -0.65058095- -0.98595731-  1.66846313- #> [16]  0.08767241+  0.82288646+  0.71012082+  0.51054011+ -0.72494378+ rbind(S2,S2) #>  [1]  1.13176967  -1.30350912+ -0.65058095+ -0.98595731+  1.66846313  #>  [6]  0.08767241   0.82288646   0.71012082   0.51054011  -0.72494378+ #> [11]  1.13176967  -1.30350912+ -0.65058095+ -0.98595731+  1.66846313  #> [16]  0.08767241   0.82288646   0.71012082   0.51054011  -0.72494378+ rbind(S3,S3) #>  [1]  1.13176967- -1.30350912  -0.65058095  -0.98595731   1.66846313- #>  [6]  0.08767241-  0.82288646-  0.71012082-  0.51054011- -0.72494378  #> [11]  1.13176967- -1.30350912  -0.65058095  -0.98595731   1.66846313- #> [16]  0.08767241-  0.82288646-  0.71012082-  0.51054011- -0.72494378"},{"path":"/reference/regression-set.html","id":null,"dir":"Reference","previous_headings":"","what":"Add regression association to latent variable model — regression<-","title":"Add regression association to latent variable model — regression<-","text":"Define regression association variables lvm-object define linear constraints model equations.","code":""},{"path":"/reference/regression-set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add regression association to latent variable model — regression<-","text":"","code":"# S3 method for class 'lvm' regression(object = lvm(), to, from, fn = NA, messages = lava.options()$messages, additive=TRUE, y, x, value, ...) # S3 method for class 'lvm' regression(object, to = NULL, quick = FALSE, ...) <- value"},{"path":"/reference/regression-set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add regression association to latent variable model — regression<-","text":"object lvm-object. ... Additional arguments passed low level functions value formula specifying linear constraints =NULL list parameter values. Character vector outcome(s) formula object. Character vector predictor(s). fn Real function defining functional form predictors (simulation ). messages Controls messages turned /(0: ) additive FALSE predictor categorical non-additive effect assumed y Alias '' x Alias '' quick Faster implementation without parameter constraints","code":""},{"path":"/reference/regression-set.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add regression association to latent variable model — regression<-","text":"lvm-object","code":""},{"path":"/reference/regression-set.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add regression association to latent variable model — regression<-","text":"regression function used specify linear associations variables latent variable model, offers formula syntax resembling model specification e.g. lm. instance, add following linear regression model, lvm-object, m: $$ E(Y|X_1,X_2) = \\beta_1 X_1 + \\beta_2 X_2$$ can write regression(m) <- y ~ x1 + x2 Multivariate models can specified successive calls regression, multivariate formulas also supported, e.g. regression(m) <- c(y1,y2) ~ x1 + x2 defines $$ E(Y_i|X_1,X_2) = \\beta_{1i} X_1 + \\beta_{2i} X_2 $$ special function, f, can used model specification specify linear constraints. E.g. fix \\(\\beta_1=\\beta_2\\) , write regression(m) <- y ~ f(x1,beta) + f(x2,beta) second argument f can also number (e.g. defining offset) set NA order clear previously defined linear constraints. Alternatively, straight forward notation can used: regression(m) <- y ~ beta*x1 + beta*x2 parameter values linear constraints can given right handside expression assigment function regression<- (regfix<-) first (possibly second) argument defined well. E.g: regression(m,y1~x1+x2) <- list(\"a1\",\"b1\") defines \\(E(Y_1|X_1,X_2) = a1 X_1 + b1 X_2\\). rhs argument can mixture character numeric values (NA's remove constraints). function regression (called without additional arguments) can used inspect linear constraints lvm-object.","code":""},{"path":"/reference/regression-set.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Add regression association to latent variable model — regression<-","text":"Variables added model already present.","code":""},{"path":[]},{"path":"/reference/regression-set.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add regression association to latent variable model — regression<-","text":"Klaus K. Holst","code":""},{"path":"/reference/regression-set.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add regression association to latent variable model — regression<-","text":"","code":"m <- lvm() ## Initialize empty lvm-object ### E(y1|z,v) = beta1*z + beta2*v regression(m) <- y1 ~ z + v ### E(y2|x,z,v) = beta*x + beta*z + 2*v + beta3*u regression(m) <- y2 ~ f(x,beta) + f(z,beta)  + f(v,2) + u ### Clear restriction on association between y and ### fix slope coefficient of u to beta regression(m, y2 ~ v+u) <- list(NA,\"beta\")  regression(m) ## Examine current linear parameter constraints #> Regression parameters: #>       y1 z    v y2 x    u    #>    y1    *    *              #>    y2    beta *    beta beta  ## ## A multivariate model, E(yi|x1,x2) = beta[1i]*x1 + beta[2i]*x2: m2 <- lvm(c(y1,y2) ~ x1+x2)"},{"path":"/reference/revdiag.html","id":null,"dir":"Reference","previous_headings":"","what":"Create/extract 'reverse'-diagonal matrix or off-diagonal elements — revdiag","title":"Create/extract 'reverse'-diagonal matrix or off-diagonal elements — revdiag","text":"Create/extract 'reverse'-diagonal matrix -diagonal elements","code":""},{"path":"/reference/revdiag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create/extract 'reverse'-diagonal matrix or off-diagonal elements — revdiag","text":"","code":"revdiag(x,...) offdiag(x,type=0,...)  revdiag(x, ...) <- value offdiag(x, type = 0, ...) <- value"},{"path":"/reference/revdiag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create/extract 'reverse'-diagonal matrix or off-diagonal elements — revdiag","text":"x vector ... additional arguments lower level functions value assignment function values put diagonal type 0: upper lower triangular, 1: upper triangular, 2: lower triangular, 3: upper triangular + diagonal, 4: lower triangular + diagonal","code":""},{"path":"/reference/revdiag.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create/extract 'reverse'-diagonal matrix or off-diagonal elements — revdiag","text":"Klaus K. Holst","code":""},{"path":"/reference/rmvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove variables from (model) object. — rmvar","title":"Remove variables from (model) object. — rmvar","text":"Generic method removing elements object","code":""},{"path":"/reference/rmvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove variables from (model) object. — rmvar","text":"","code":"rmvar(x, ...) <- value"},{"path":"/reference/rmvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove variables from (model) object. — rmvar","text":"x Model object ... additional arguments lower level functions value Vector variables formula specifying nodes remove","code":""},{"path":[]},{"path":"/reference/rmvar.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remove variables from (model) object. — rmvar","text":"Klaus K. Holst","code":""},{"path":"/reference/rmvar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove variables from (model) object. — rmvar","text":"","code":"m <- lvm() addvar(m) <- ~y1+y2+x covariance(m) <- y1~y2 regression(m) <- c(y1,y2) ~ x ### Cancel the covariance between the residuals of y1 and y2 cancel(m) <- y1~y2 ### Remove y2 from the model rmvar(m) <- ~y2"},{"path":"/reference/rotate2.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs a rotation in the plane — rotate2","title":"Performs a rotation in the plane — rotate2","text":"Performs rotation plane","code":""},{"path":"/reference/rotate2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs a rotation in the plane — rotate2","text":"","code":"rotate2(x, theta = pi)"},{"path":"/reference/rotate2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs a rotation in the plane — rotate2","text":"x Matrix rotated (2 times n) theta Rotation radians","code":""},{"path":"/reference/rotate2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs a rotation in the plane — rotate2","text":"Returns matrix dimension x","code":""},{"path":"/reference/rotate2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Performs a rotation in the plane — rotate2","text":"Klaus K. Holst","code":""},{"path":"/reference/rotate2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs a rotation in the plane — rotate2","text":"","code":"rotate2(cbind(c(1,2),c(2,1))) #>      [,1] [,2] #> [1,]   -1   -2 #> [2,]   -2   -1"},{"path":"/reference/scheffe.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate simultaneous confidence limits by Scheffe's method — scheffe","title":"Calculate simultaneous confidence limits by Scheffe's method — scheffe","text":"Function compute Scheffe corrected confidence interval regression line","code":""},{"path":"/reference/scheffe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate simultaneous confidence limits by Scheffe's method — scheffe","text":"","code":"scheffe(model, newdata = model.frame(model), level = 0.95)"},{"path":"/reference/scheffe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate simultaneous confidence limits by Scheffe's method — scheffe","text":"model Linear model newdata new data frame level confidence level (0.95)","code":""},{"path":"/reference/scheffe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate simultaneous confidence limits by Scheffe's method — scheffe","text":"","code":"x <- rnorm(100) d <- data.frame(y=rnorm(length(x),x),x=x) l <- lm(y~x,d) plot(y~x,d) abline(l) d0 <- data.frame(x=seq(-5,5,length.out=100)) d1 <- cbind(d0,predict(l,newdata=d0,interval=\"confidence\")) d2 <- cbind(d0,scheffe(l,d0)) lines(lwr~x,d1,lty=2,col=\"red\") lines(upr~x,d1,lty=2,col=\"red\") lines(lwr~x,d2,lty=2,col=\"blue\") lines(upr~x,d2,lty=2,col=\"blue\")"},{"path":"/reference/semdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Example SEM data — semdata","title":"Example SEM data — semdata","text":"Simulated data","code":""},{"path":"/reference/semdata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example SEM data — semdata","text":"data.frame","code":""},{"path":"/reference/semdata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example SEM data — semdata","text":"Simulated","code":""},{"path":"/reference/serotonin.html","id":null,"dir":"Reference","previous_headings":"","what":"Serotonin data — serotonin","title":"Serotonin data — serotonin","text":"simulated data mimics PET imaging study 5-HT2A receptor serotonin transporter (SERT) binding potential quantified 8 different regions. 5-HT2A cortical regions considered high-binding regions measurements.  measurements can regarded proxy measures extra-cellular levels serotonin brain","code":""},{"path":"/reference/serotonin.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Serotonin data — serotonin","text":"data.frame","code":""},{"path":"/reference/serotonin.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Serotonin data — serotonin","text":"Simulated","code":""},{"path":"/reference/sim.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo simulation — sim.default","title":"Monte Carlo simulation — sim.default","text":"Applies function repeatedly specified number replications list/data.frame plot summary methods summarizing Monte Carlo experiment. Can parallelized via future package (use future::plan function).","code":""},{"path":"/reference/sim.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo simulation — sim.default","text":"","code":"# Default S3 method sim(   x = NULL,   R = 100,   f = NULL,   colnames = NULL,   seed = NULL,   args = list(),   iter = FALSE,   mc.cores,   progressr.message = NULL,   ... )"},{"path":"/reference/sim.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo simulation — sim.default","text":"x function 'sim' object R Number replications data.frame parameters f Optional function (.e., x matrix) colnames Optional column names seed (optional) Seed (needed cl=TRUE) args (optional) list named arguments passed (mc)mapply iter TRUE iteration number passed first argument (mc)mapply mc.cores Optional number cores. use parallel::mcmapply instead future progressr.message Optional message progressr progress-bar ... Additional arguments future.apply::future_mapply","code":""},{"path":"/reference/sim.default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Monte Carlo simulation — sim.default","text":"parallelize calculation use future::plan function (e.g.,   future::plan(multisession()) distribute calculations R   replications available cores). output controlled via   progressr package (e.g., progressr::handlers(global=TRUE) enable   progress information).","code":""},{"path":[]},{"path":"/reference/sim.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monte Carlo simulation — sim.default","text":"","code":"m <- lvm(y~x+e) distribution(m,~y) <- 0 distribution(m,~x) <- uniform.lvm(a=-1.1,b=1.1) transform(m,e~x) <- function(x) (1*x^4)*rnorm(length(x),sd=1)  onerun <- function(iter=NULL,...,n=2e3,b0=1,idx=2) {     d <- sim(m,n,p=c(\"y~x\"=b0))     l <- lm(y~x,d)     res <- c(coef(summary(l))[idx,1:2],              confint(l)[idx,],              estimate(l,only.coef=TRUE)[idx,2:4])     names(res) <- c(\"Estimate\",\"Model.se\",\"Model.lo\",\"Model.hi\",                     \"Sandwich.se\",\"Sandwich.lo\",\"Sandwich.hi\")     res } val <- sim(onerun,R=10,b0=1) val #>    Estimate Model.se Model.lo Model.hi Sandwich.se Sandwich.lo Sandwich.hi #> 1  0.981936 0.010066 0.962195 1.001677 0.014230    0.954045    1.009827    #> 2  0.985010 0.018630 0.948473 1.021546 0.026497    0.933076    1.036943    #> 3  0.993945 0.006745 0.980717 1.007173 0.009338    0.975642    1.012248    #> 4  0.987181 0.009413 0.968721 1.005640 0.013156    0.961396    1.012966    #> 5  0.990049 0.006639 0.977028 1.003069 0.009411    0.971603    1.008495    #> 6  0.980337 0.019269 0.942548 1.018127 0.027398    0.926638    1.034036    #> 7  0.997944 0.001032 0.995920 0.999968 0.001460    0.995082    1.000806    #> 8  1.000065 0.001981 0.996179 1.003951 0.002797    0.994583    1.005546    #> 9  1.006180 0.006264 0.993894 1.018465 0.008815    0.988903    1.023456    #> 10 1.002229 0.006264 0.989943 1.014514 0.008572    0.985427    1.019030    #>  #>       Estimate  Model.se Model.lo  Model.hi Sandwich.se Sandwich.lo Sandwich.hi #> Mean 0.9924875 0.0086305 0.975562 1.0094131   0.0121675    0.968640    1.016335 #> SD   0.0089484 0.0061147 0.019608 0.0079547   0.0087226    0.024533    0.011951  val <- sim(val,R=40,b0=1) ## append results summary(val,estimate=c(1,1),confint=c(3,4,6,7),true=c(1,1)) #> 50 replications\t\t\t\t\tTime: 0.974s #>  #>            Estimate Estimate.1 #> Mean      0.9961265  0.9961265 #> SD        0.0138953  0.0138953 #> Coverage  0.8200000  0.9800000 #>                                #> Min       0.9673948  0.9673948 #> 2.5%      0.9722390  0.9722390 #> 50%       0.9976991  0.9976991 #> 97.5%     1.0298590  1.0298590 #> Max       1.0402295  1.0402295 #>                                #> Missing   0.0000000  0.0000000 #>                                #> True      1.0000000  1.0000000 #> Bias     -0.0038735 -0.0038735 #> RMSE      0.0144251  0.0144251 #>   summary(val,estimate=c(1,1),se=c(2,5),names=c(\"Model\",\"Sandwich\")) #> 50 replications\t\t\t\t\tTime: 0.974s #>  #>             Model Sandwich #> Mean    0.9961265 0.996127 #> SD      0.0138953 0.013895 #> SE      0.0091896 0.012960 #> SE/SD   0.6613435 0.932713 #>                            #> Min     0.9673948 0.967395 #> 2.5%    0.9722390 0.972239 #> 50%     0.9976991 0.997699 #> 97.5%   1.0298590 1.029859 #> Max     1.0402295 1.040229 #>                            #> Missing 0.0000000 0.000000 #>  summary(val,estimate=c(1,1),se=c(2,5),true=c(1,1),         names=c(\"Model\",\"Sandwich\"),confint=TRUE) #> 50 replications\t\t\t\t\tTime: 0.974s #>  #>               Model   Sandwich #> Mean      0.9961265  0.9961265 #> SD        0.0138953  0.0138953 #> SE        0.0091896  0.0129603 #> SE/SD     0.6613435  0.9327125 #> Coverage  0.8200000  0.9800000 #>                                #> Min       0.9673948  0.9673948 #> 2.5%      0.9722390  0.9722390 #> 50%       0.9976991  0.9976991 #> 97.5%     1.0298590  1.0298590 #> Max       1.0402295  1.0402295 #>                                #> Missing   0.0000000  0.0000000 #>                                #> True      1.0000000  1.0000000 #> Bias     -0.0038735 -0.0038735 #> RMSE      0.0144251  0.0144251 #>   if (interactive()) {     plot(val,estimate=1,c(2,5),true=1,          names=c(\"Model\",\"Sandwich\"),polygon=FALSE)     plot(val,estimate=c(1,1),se=c(2,5),main=NULL,          true=c(1,1),names=c(\"Model\",\"Sandwich\"),          line.lwd=1,col=c(\"gray20\",\"gray60\"),          rug=FALSE)     plot(val,estimate=c(1,1),se=c(2,5),true=c(1,1),          names=c(\"Model\",\"Sandwich\")) }  f <- function(a=1, b=1) {   rep(a*b, 5) } R <- Expand(a=1:3, b=1:3) sim(f, R) #>   [,1] [,2] [,3] [,4] [,5] #> 1 1    1    1    1    1    #> 2 2    2    2    2    2    #> 3 3    3    3    3    3    #> 4 2    2    2    2    2    #> 5 4    4    4    4    4    #> 6 6    6    6    6    6    #> 7 3    3    3    3    3    #> 8 6    6    6    6    6    #> 9 9    9    9    9    9    #>  #>        [,1]   [,2]   [,3]   [,4]   [,5] #> Mean 4.0000 4.0000 4.0000 4.0000 4.0000 #> SD   2.5495 2.5495 2.5495 2.5495 2.5495 sim(function(a,b) f(a,b), 3, args=c(a=5,b=5)) #>   [,1] [,2] [,3] [,4] [,5] #> 1 25   25   25   25   25   #> 2 25   25   25   25   25   #> 3 25   25   25   25   25   #>  #>      [,1] [,2] [,3] [,4] [,5] #> Mean   25   25   25   25   25 #> SD      0    0    0    0    0 sim(function(iter=1,a=5,b=5) iter*f(a,b), iter=TRUE, R=5) #>   [,1] [,2] [,3] [,4] [,5] #> 1  25   25   25   25   25  #> 2  50   50   50   50   50  #> 3  75   75   75   75   75  #> 4 100  100  100  100  100  #> 5 125  125  125  125  125  #>  #>        [,1]   [,2]   [,3]   [,4]   [,5] #> Mean 75.000 75.000 75.000 75.000 75.000 #> SD   39.528 39.528 39.528 39.528 39.528"},{"path":"/reference/sim.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate model — sim.lvm","title":"Simulate model — sim.lvm","text":"Simulate data general SEM model including non-linear effects general link distribution variables.","code":""},{"path":"/reference/sim.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate model — sim.lvm","text":"","code":"# S3 method for class 'lvm' sim(x, n = NULL, p = NULL, normal = FALSE, cond = FALSE, sigma = 1, rho = 0.5, X = NULL, unlink=FALSE, latent=TRUE, use.labels = TRUE, seed=NULL, ...)"},{"path":"/reference/sim.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate model — sim.lvm","text":"x Model object n Number simulated values/individuals p Parameter value (optional) normal Logical indicating whether simulate data multivariate normal distribution conditional exogenous variables hence ignoring functional/distribution definition cond internal use sigma Default residual variance (1) rho Default covariance parameter (0.5) X Optional matrix fixed values variables (manipulation) unlink Return Inverse link transformed data latent Include latent variables (default TRUE) use.labels convert categorical variables factors applying transformation seed Random seed ... Additional arguments passed low level functions","code":""},{"path":"/reference/sim.lvm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate model — sim.lvm","text":"Klaus K. Holst","code":""},{"path":"/reference/sim.lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate model — sim.lvm","text":"","code":"################################################## ## Logistic regression ################################################## m <- lvm(y~x+z) regression(m) <- x~z distribution(m,~y+z) <- binomial.lvm(\"logit\") d <- sim(m,1e3) head(d) #>   y          x z #> 1 1 -0.3890521 0 #> 2 1  1.5760916 1 #> 3 1  1.5709196 1 #> 4 1  1.4971902 1 #> 5 1  1.3515534 1 #> 6 1  0.6453046 0  e <- estimate(m,d,estimator=\"glm\") e #>              Estimate Std. Error  Z-value   P-value #> Regressions:                                        #>    y~x        1.06972    0.09349 11.44259    <1e-12 #>    y~z        1.01578    0.16776  6.05499 1.404e-09 #>     x~z       0.96477    0.06532 14.77041    <1e-12 #> Intercepts:                                         #>    y         -0.13044    0.10078 -1.29431    0.1956 #>    x          0.02210    0.04701  0.47012    0.6383 #> Dispersion:                                         #>    x          1.06874                               ## Simulate a few observation from estimated model sim(e,n=5) #>   y         x z #> 1 1 0.7578086 1 #> 2 0 0.6592641 1 #> 3 1 1.2263657 1 #> 4 1 0.2300801 0 #> 5 1 0.9931559 1  ################################################## ## Poisson ################################################## distribution(m,~y) <- poisson.lvm() d <- sim(m,1e4,p=c(y=-1,\"y~x\"=2,z=1)) head(d) #>    y           x z #> 1 14  1.01864520 1 #> 2  1  0.09862234 0 #> 3  0 -0.28820655 0 #> 4 19  1.53349369 1 #> 5  0  0.46584650 0 #> 6  6  1.12191083 1 estimate(m,d,estimator=\"glm\") #>                Estimate Std. Error    Z-value  P-value #> Regressions:                                           #>    y~x          1.99880    0.00192 1042.74787   <1e-12 #>    y~z          0.98743    0.01116   88.49805   <1e-12 #>     x~z         0.99262    0.02273   43.66784   <1e-12 #> Intercepts:                                            #>    y           -0.98504    0.01167  -84.44281   <1e-12 #>    x            0.00358    0.01950    0.18345   0.8544 #> Dispersion:                                            #>    x            1.00426                                mean(d$z); lava:::expit(1) #> [1] 0.7251 #> [1] 0.7310586  summary(lm(y~x,sim(lvm(y[1:2]~4*x),1e3))) #>  #> Call: #> lm(formula = y ~ x, data = sim(lvm(y[1:2] ~ 4 * x), 1000)) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -4.2216 -1.0570  0.0261  0.9492  4.5983  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  0.99738    0.04548   21.93   <2e-16 *** #> x            3.99724    0.04426   90.31   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 1.438 on 998 degrees of freedom #> Multiple R-squared:  0.891,\tAdjusted R-squared:  0.8909  #> F-statistic:  8156 on 1 and 998 DF,  p-value: < 2.2e-16 #>   ################################################## ### Gamma distribution ################################################## m <- lvm(y~x) distribution(m,~y+x) <- list(Gamma.lvm(shape=2),binomial.lvm()) intercept(m,~y) <- 0.5 d <- sim(m,1e4) summary(g <- glm(y~x,family=Gamma(),data=d)) #>  #> Call: #> glm(formula = y ~ x, family = Gamma(), data = d) #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) 0.505874   0.005102   99.15   <2e-16 *** #> x           1.008180   0.016302   61.84   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> (Dispersion parameter for Gamma family taken to be 0.5156528) #>  #>     Null deviance: 8397.4  on 9999  degrees of freedom #> Residual deviance: 5546.3  on 9998  degrees of freedom #> AIC: 20678 #>  #> Number of Fisher Scoring iterations: 6 #>  if (FALSE) MASS::gamma.shape(g) # \\dontrun{}  args(lava::Gamma.lvm) #> function (link = \"inverse\", shape, rate, unit = FALSE, var = FALSE,  #>     log = FALSE, ...)  #> NULL distribution(m,~y) <- Gamma.lvm(shape=2,log=TRUE) sim(m,10,p=c(y=0.5))[,\"y\"] #>  [1] -1.14993675  0.06110529 -0.78986992  1.68142084  0.13917097 -0.35847861 #>  [7]  0.73652104 -1.62401234 -0.39977265 -1.16007252  ################################################## ### Beta ################################################## m <- lvm() distribution(m,~y) <- beta.lvm(alpha=2,beta=1) var(sim(m,100,\"y,y\"=2)) #>         y #> y 1.14993 distribution(m,~y) <- beta.lvm(alpha=2,beta=1,scale=FALSE) var(sim(m,100)) #>           y #> y 0.0521512  ################################################## ### Transform ################################################## m <- lvm() transform(m,xz~x+z) <- function(x) x[1]*(x[2]>0) regression(m) <- y~x+z+xz d <- sim(m,1e3) summary(lm(y~x+z + x*I(z>0),d)) #>  #> Call: #> lm(formula = y ~ x + z + x * I(z > 0), data = d) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -3.1528 -0.6738 -0.0486  0.7210  3.6658  #>  #> Coefficients: #>                 Estimate Std. Error t value Pr(>|t|)     #> (Intercept)     0.021540   0.061655   0.349    0.727     #> x               0.987755   0.047652  20.728   <2e-16 *** #> z               1.016270   0.054549  18.630   <2e-16 *** #> I(z > 0)TRUE   -0.005932   0.106185  -0.056    0.955     #> x:I(z > 0)TRUE  1.009156   0.065653  15.371   <2e-16 *** #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> Residual standard error: 1.018 on 995 degrees of freedom #> Multiple R-squared:  0.7704,\tAdjusted R-squared:  0.7694  #> F-statistic: 834.5 on 4 and 995 DF,  p-value: < 2.2e-16 #>   ################################################## ### Non-random variables ################################################## m <- lvm() distribution(m,~x+z+v+w) <- list(Sequence.lvm(0,5),## Seq. 0 to 5 by 1/n                                Binary.lvm(),       ## Vector of ones                                Binary.lvm(0.5),    ##  0.5n 0, 0.5n 1                                Binary.lvm(interval=list(c(0.3,0.5),c(0.8,1)))) sim(m,10) #>            x z v w #> 1  0.0000000 1 0 0 #> 2  0.5555556 1 0 0 #> 3  1.1111111 1 0 1 #> 4  1.6666667 1 0 1 #> 5  2.2222222 1 0 1 #> 6  2.7777778 1 1 0 #> 7  3.3333333 1 1 0 #> 8  3.8888889 1 1 1 #> 9  4.4444444 1 1 1 #> 10 5.0000000 1 1 1  ################################################## ### Cox model ### piecewise constant hazard ################################################ m <- lvm(t~x) rates <- c(1,0.5); cuts <- c(0,5) ## Constant rate: 1 in [0,5), 0.5 in [5,Inf) distribution(m,~t) <- coxExponential.lvm(rate=rates,timecut=cuts)  if (FALSE) { # \\dontrun{     d <- sim(m,2e4,p=c(\"t~x\"=0.1)); d$status <- TRUE     plot(timereg::aalen(survival::Surv(t,status)~x,data=d,                         resample.iid=0,robust=0),spec=1)     L <- approxfun(c(cuts,max(d$t)),f=1,                    cumsum(c(0,rates*diff(c(cuts,max(d$t))))),                    method=\"linear\")     curve(L,0,100,add=TRUE,col=\"blue\") } # }  ################################################## ### Cox model ### piecewise constant hazard, gamma frailty ################################################## m <- lvm(y~x+z) rates <- c(0.3,0.5); cuts <- c(0,5) distribution(m,~y+z) <- list(coxExponential.lvm(rate=rates,timecut=cuts),                              loggamma.lvm(rate=1,shape=1)) if (FALSE) { # \\dontrun{     d <- sim(m,2e4,p=c(\"y~x\"=0,\"y~z\"=0)); d$status <- TRUE     plot(timereg::aalen(survival::Surv(y,status)~x,data=d,                         resample.iid=0,robust=0),spec=1)     L <- approxfun(c(cuts,max(d$y)),f=1,                    cumsum(c(0,rates*diff(c(cuts,max(d$y))))),                    method=\"linear\")     curve(L,0,100,add=TRUE,col=\"blue\") } # } ## Equivalent via transform (here with Aalens additive hazard model) m <- lvm(y~x) distribution(m,~y) <- aalenExponential.lvm(rate=rates,timecut=cuts) distribution(m,~z) <- Gamma.lvm(rate=1,shape=1) transform(m,t~y+z) <- prod sim(m,10) #>              y          x            z             t #> 1  -7.52089416 -0.3975626 0.0521017141 -3.918515e-01 #> 2   2.20571704  0.3470455 0.5086850008  1.122015e+00 #> 3  -4.36804686 -0.3792286 0.5905137765 -2.579392e+00 #> 4  -0.07640396 -1.5337391 0.2058743050 -1.572961e-02 #> 5  21.43594787 -0.2640809 0.0099792760  2.139152e-01 #> 6   4.25372148  0.1839688 0.4443781625  1.890261e+00 #> 7  -0.09900900 -1.4246557 0.0006665787 -6.599729e-05 #> 8  -1.15906345 -1.0335661 0.8045995309 -9.325819e-01 #> 9   6.72402679 -0.2305547 0.6546673730  4.402001e+00 #> 10  5.53307450 -0.1962768 0.2215395973  1.225795e+00 ## Shared frailty m <- lvm(c(t1,t2)~x+z) rates <- c(1,0.5); cuts <- c(0,5) distribution(m,~y) <- aalenExponential.lvm(rate=rates,timecut=cuts) distribution(m,~z) <- loggamma.lvm(rate=1,shape=1) if (FALSE) { # \\dontrun{ mets::fast.reshape(sim(m,100),varying=\"t\") } # }  ################################################## ### General multivariate distributions ################################################## if (FALSE) { # \\dontrun{ m <- lvm() distribution(m,~y1+y2,oratio=4) <- VGAM::rbiplackcop ksmooth2(sim(m,1e4),rgl=FALSE,theta=-20,phi=25)  m <- lvm() distribution(m,~z1+z2,\"or1\") <- VGAM::rbiplackcop distribution(m,~y1+y2,\"or2\") <- VGAM::rbiplackcop sim(m,10,p=c(or1=0.1,or2=4)) } # }  m <- lvm() distribution(m,~y1+y2+y3,TRUE) <- function(n,...) rmvn0(n,sigma=diag(3)+1) var(sim(m,100)) #>          y1        y2        y3 #> y1 2.546658 1.2446886 1.1131815 #> y2 1.244689 2.1601392 0.8173183 #> y3 1.113182 0.8173183 1.8257718  ## Syntax also useful for univariate generators, e.g. m <- lvm(y~x+z) distribution(m,~y,TRUE) <- function(n) rnorm(n,mean=1000) sim(m,5) #>           y          x           z #> 1 1000.5214  0.2177780  1.93296840 #> 2  999.1417 -0.4748423  0.10528753 #> 3  999.1108 -2.2866782 -0.09999915 #> 4  998.8764 -0.7593130 -0.13847376 #> 5 1001.0689 -0.3586061  0.24695597 distribution(m,~y,\"m1\",0) <- rnorm sim(m,5) #>            y          x          z #> 1 -0.5899834  0.5347800 -2.3598938 #> 2 -0.4243369 -0.9962041 -0.5107305 #> 3  3.5456795  1.7645527  1.5297775 #> 4 -1.4880155 -0.7726338 -0.1372156 #> 5 -0.2474045  0.3482477 -0.1443716 sim(m,5,p=c(m1=100)) #>           y            x          z #> 1 102.25740  0.129915309  2.7875521 #> 2 101.53418  1.820998862 -0.3153138 #> 3  98.71054 -0.007577379 -0.2353492 #> 4  99.17310 -0.901698372 -0.4610830 #> 5 103.29305  0.072049531  1.9003038  ################################################## ### Regression design in other parameters ################################################## ## Variance heterogeneity m <- lvm(y~x) distribution(m,~y) <- function(n,mean,x) rnorm(n,mean,exp(x)^.5) if (interactive()) plot(y~x,sim(m,1e3)) ## Alternaively, calculate the standard error directly addvar(m) <- ~sd ## If 'sd' should be part of the resulting data.frame constrain(m,sd~x) <- function(x) exp(x)^.5 distribution(m,~y) <- function(n,mean,sd) rnorm(n,mean,sd) if (interactive()) plot(y~x,sim(m,1e3))  ## Regression on variance parameter m <- lvm() regression(m) <- y~x regression(m) <- v~x ##distribution(m,~v) <- 0 # No stochastic term ## Alternative: ## regression(m) <- v[NA:0]~x distribution(m,~y) <- function(n,mean,v) rnorm(n,mean,exp(v)^.5) if (interactive()) plot(y~x,sim(m,1e3))  ## Regression on shape parameter in Weibull model m <- lvm() regression(m) <- y ~ z+v regression(m) <- s ~ exp(0.6*x-0.5*z) distribution(m,~x+z) <- binomial.lvm() distribution(m,~cens) <- coxWeibull.lvm(scale=1) distribution(m,~y) <- coxWeibull.lvm(scale=0.1,shape=~s) eventTime(m) <- time ~ min(y=1,cens=0)  if (interactive()) {     d <- sim(m,1e3)     require(survival)     (cc <- coxph(Surv(time,status)~v+strata(x,z),data=d))     plot(survfit(cc) ,col=1:4,mark.time=FALSE) }  ################################################## ### Categorical predictor ################################################## m <- lvm() ## categorical(m,K=3) <- \"v\" categorical(m,labels=c(\"A\",\"B\",\"C\")) <- \"v\"  regression(m,additive=FALSE) <- y~v if (FALSE) { # \\dontrun{ plot(y~v,sim(m,1000,p=c(\"y~v:2\"=3))) } # }  m <- lvm() categorical(m,labels=c(\"A\",\"B\",\"C\"),p=c(0.5,0.3)) <- \"v\" regression(m,additive=FALSE,beta=c(0,2,-1)) <- y~v ## equivalent to: ## regression(m,y~v,additive=FALSE) <- c(0,2,-1) regression(m,additive=FALSE,beta=c(0,4,-1)) <- z~v table(sim(m,1e4)$v) #>  #>    A    B    C  #> 5004 3018 1978  glm(y~v, data=sim(m,1e4)) #>  #> Call:  glm(formula = y ~ v, data = sim(m, 10000)) #>  #> Coefficients: #> (Intercept)           vB           vC   #>     0.02492      1.99774     -1.00229   #>  #> Degrees of Freedom: 9999 Total (i.e. Null);  9997 Residual #> Null Deviance:\t    22580  #> Residual Deviance: 9997 \tAIC: 28380 glm(y~v, data=sim(m,1e4,p=c(\"y~v:1\"=3))) #>  #> Call:  glm(formula = y ~ v, data = sim(m, 10000, p = c(`y~v:1` = 3))) #>  #> Coefficients: #> (Intercept)           vB           vC   #>    0.003437     2.987178    -1.009686   #>  #> Degrees of Freedom: 9999 Total (i.e. Null);  9997 Residual #> Null Deviance:\t    34490  #> Residual Deviance: 10330 \tAIC: 28710  transform(m,v2~v) <- function(x) x=='A' sim(m,10) #>    v          y          z    v2 #> 1  B  2.2298156  4.1679282 FALSE #> 2  B  0.6586923  3.7329303 FALSE #> 3  B  2.6336803  2.2362200 FALSE #> 4  C -1.2815957 -3.2806097 FALSE #> 5  B  1.7904833  1.7922099 FALSE #> 6  A  1.5817981 -2.4106877  TRUE #> 7  A  0.9435654  0.8197093  TRUE #> 8  A  0.5989207  0.9182792  TRUE #> 9  C -0.5337450  0.2826166 FALSE #> 10 A  0.7108434 -1.3749699  TRUE  ################################################## ### Pre-calculate object ################################################## m <- lvm(y~x) m2 <- sim(m,'y~x'=2) sim(m,10,'y~x'=2) #>             y          x #> 1  -2.9969686 -0.5822500 #> 2   2.0932122  0.4675629 #> 3   2.4677225  1.1228049 #> 4   1.3229557  1.3806512 #> 5   3.1524416  1.9010546 #> 6  -0.6734257 -0.6149359 #> 7   0.4034541 -0.4402311 #> 8   0.5278260 -0.2312745 #> 9   1.3184855  0.7196587 #> 10 -0.6764807 -0.2205306 sim(m2,10) ## Faster #>             y          x #> 1   0.2093413 -0.1414400 #> 2   1.7423583  0.9679083 #> 3   2.3735490  0.8827087 #> 4  -2.9847372 -1.3114255 #> 5   0.8275647 -0.2983199 #> 6  -3.4592201 -1.8890341 #> 7   2.4341144  0.9988011 #> 8  -1.1049947 -0.4407522 #> 9  -0.4269766 -0.1266534 #> 10 -1.4520110 -0.6076527"},{"path":"/reference/spaghetti.html","id":null,"dir":"Reference","previous_headings":"","what":"Spaghetti plot — spaghetti","title":"Spaghetti plot — spaghetti","text":"Spaghetti plot longitudinal data","code":""},{"path":"/reference/spaghetti.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spaghetti plot — spaghetti","text":"","code":"spaghetti(   formula,   data = NULL,   id = \"id\",   group = NULL,   type = \"o\",   lty = 1,   pch = NA,   col = 1:10,   alpha = 0.3,   lwd = 1,   level = 0.95,   trend.formula = formula,   tau = NULL,   trend.lty = 1,   trend.join = TRUE,   trend.delta = 0.2,   trend = !is.null(tau),   trend.col = col,   trend.alpha = 0.2,   trend.lwd = 3,   trend.jitter = 0,   legend = NULL,   by = NULL,   xlab = \"Time\",   ylab = \"\",   add = FALSE,   ... )"},{"path":"/reference/spaghetti.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spaghetti plot — spaghetti","text":"formula Formula (response ~ time) data data.frame id Id variable group group variable type Type (line 'l', stair 's', ...) lty Line type pch Colour col Colour alpha transparency (0-1) lwd Line width level Confidence level trend.formula Formula trendline tau Quantile estimate (trend) trend.lty Trend line type trend.join Trend polygon trend.delta Length limit bars trend Add trend line trend.col Colour trend line trend.alpha Transparency trend.lwd Trend line width trend.jitter Jitter amount legend Legend make separate plot level '' (formula, name column, vector) xlab Label X-axis ylab Label Y-axis add Add existing device ... Additional arguments lower level arguments","code":""},{"path":"/reference/spaghetti.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Spaghetti plot — spaghetti","text":"Klaus K. Holst","code":""},{"path":"/reference/spaghetti.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spaghetti plot — spaghetti","text":"","code":"if (interactive() & requireNamespace(\"mets\")) { K <- 5 y <- \"y\"%++%seq(K) m <- lvm() regression(m,y=y,x=~u) <- 1 regression(m,y=y,x=~s) <- seq(K)-1 regression(m,y=y,x=~x) <- \"b\" N <- 50 d <- sim(m,N); d$z <- rbinom(N,1,0.5) dd <- mets::fast.reshape(d); dd$num <- dd$num+3 spaghetti(y~num,dd,id=\"id\",lty=1,col=Col(1,.4),           trend.formula=~factor(num),trend=TRUE,trend.col=\"darkblue\") dd$num <- dd$num+rnorm(nrow(dd),sd=0.5) ## Unbalance spaghetti(y~num,dd,id=\"id\",lty=1,col=Col(1,.4),           trend=TRUE,trend.col=\"darkblue\") spaghetti(y~num,dd,id=\"id\",lty=1,col=Col(1,.4),            trend.formula=~num+I(num^2),trend=TRUE,trend.col=\"darkblue\") }"},{"path":"/reference/stack.estimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack estimating equations — stack.estimate","title":"Stack estimating equations — stack.estimate","text":"Stack estimating equations (two-stage estimator)","code":""},{"path":"/reference/stack.estimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack estimating equations — stack.estimate","text":"","code":"# S3 method for class 'estimate' stack(   x,   model2,   D1u,   inv.D2u,   propensity,   dpropensity,   U,   keep1 = FALSE,   propensity.arg,   estimate.arg,   na.action = na.pass,   ... )"},{"path":"/reference/stack.estimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack estimating equations — stack.estimate","text":"x Model 1 model2 Model 2 D1u Derivative score model 2 w.r.t. parameter vector model 1 inv.D2u Inverse deri propensity propensity score (vector function) dpropensity derivative propensity score wrt parameters model 1 U Optional score function (model 2) function parameters keep1 FALSE parameters model 2 returned propensity.arg Arguments propensity function estimate.arg Arguments 'estimate' na.action Method dealing missing data propensity score ... Additional arguments lower level functions","code":""},{"path":"/reference/stack.estimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stack estimating equations — stack.estimate","text":"","code":"m <- lvm(z0~x) Missing(m, z ~ z0) <- r~x distribution(m,~x) <- binomial.lvm() p <- c(r=-1,'r~x'=0.5,'z0~x'=2) beta <- p[3]/2 d <- sim(m,500,p=p,seed=1) m1 <- estimate(r~x,data=d,family=binomial) d$w <- d$r/predict(m1,type=\"response\") m2 <- estimate(z~1, weights=w, data=d) (e <- stack(m1,m2,propensity=TRUE)) #>             Estimate Std.Err   2.5% 97.5%   P-value #> (Intercept)   0.9076 0.08836 0.7344 1.081 9.454e-25"},{"path":"/reference/subset.lvm.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract subset of latent variable model — subset.lvm","title":"Extract subset of latent variable model — subset.lvm","text":"Extract measurement models user-specified subset model","code":""},{"path":"/reference/subset.lvm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract subset of latent variable model — subset.lvm","text":"","code":"# S3 method for class 'lvm' subset(x, vars, ...)"},{"path":"/reference/subset.lvm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract subset of latent variable model — subset.lvm","text":"x lvm-object. vars Character vector formula specifying variables include subset. ... Additional arguments passed low level functions","code":""},{"path":"/reference/subset.lvm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract subset of latent variable model — subset.lvm","text":"lvm-object.","code":""},{"path":"/reference/subset.lvm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract subset of latent variable model — subset.lvm","text":"Klaus K. Holst","code":""},{"path":"/reference/subset.lvm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract subset of latent variable model — subset.lvm","text":"","code":"m <- lvm(c(y1,y2)~x1+x2) subset(m,~y1+x1) #> Latent Variable Model #>                      #>   y1 ~ x1   gaussian #>  #> Exogenous variables:                     #>   x1        gaussian #>"},{"path":"/reference/summary.sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for 'sim' objects — summary.sim","title":"Summary method for 'sim' objects — summary.sim","text":"Summary method 'sim' objects","code":""},{"path":"/reference/summary.sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for 'sim' objects — summary.sim","text":"","code":"# S3 method for class 'sim' summary(   object,   estimate = NULL,   se = NULL,   confint = !is.null(se) && !is.null(true),   true = NULL,   fun,   names = NULL,   unique.names = TRUE,   minimal = FALSE,   level = 0.95,   quantiles = c(0, 0.025, 0.5, 0.975, 1),   ... )"},{"path":"/reference/summary.sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for 'sim' objects — summary.sim","text":"object sim object estimate (optional) columns estimates se (optional) columns standard error estimates confint (optional) list pairs columns confidence limits true (optional) vector true parameter values fun (optional) summary function names (optional) names estimates unique.names TRUE, unique.names applied column names minimal TRUE, minimal summary returned level confidence level (0.95) quantiles quantiles (0,0.025,0.5,0.975,1) ... additional levels lower-level functions","code":""},{"path":"/reference/timedep.html","id":null,"dir":"Reference","previous_headings":"","what":"Time-dependent parameters — timedep","title":"Time-dependent parameters — timedep","text":"Add time-varying covariate effects model","code":""},{"path":"/reference/timedep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Time-dependent parameters — timedep","text":"","code":"timedep(object, formula, rate, timecut, type = \"coxExponential.lvm\", ...)"},{"path":"/reference/timedep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Time-dependent parameters — timedep","text":"object Model formula Formula rhs specifying time-varying covariates rate Optional rate parameters. given vector parameter interpreted raw (baseline-)rates within time interval defined timecut.  given matrix parameters interpreted log-rates (log-rate-ratios time-varying covariates defined formula). timecut Time intervals type Type model (default piecewise constant intensity) ... Additional arguments lower level functions","code":""},{"path":"/reference/timedep.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Time-dependent parameters — timedep","text":"Klaus K. Holst","code":""},{"path":"/reference/timedep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Time-dependent parameters — timedep","text":"","code":"## Piecewise constant hazard m <- lvm(y~1) m <- timedep(m,y~1,timecut=c(0,5),rate=c(0.5,0.3))  if (FALSE) { # \\dontrun{ d <- sim(m,1e4); d$status <- TRUE dd <- mets::lifetable(Surv(y,status)~1,data=d,breaks=c(0,5,10)); exp(coef(glm(events ~ offset(log(atrisk)) + -1 + interval, dd, family=poisson))) } # }   ## Piecewise constant hazard and time-varying effect of z1 m <- lvm(y~1) distribution(m,~z1) <- Binary.lvm(0.5) R <- log(cbind(c(0.2,0.7,0.9),c(0.5,0.3,0.3))) m <- timedep(m,y~z1,timecut=c(0,3,5),rate=R)  if (FALSE) { # \\dontrun{ d <- sim(m,1e4); d$status <- TRUE dd <- mets::lifetable(Surv(y,status)~z1,data=d,breaks=c(0,3,5,Inf)); exp(coef(glm(events ~ offset(log(atrisk)) + -1 + interval+z1:interval, dd, family=poisson))) } # }    ## Explicit simulation of time-varying effects m <- lvm(y~1) distribution(m,~z1) <- Binary.lvm(0.5) distribution(m,~z2) <- binomial.lvm(p=0.5) #variance(m,~m1+m2) <- 0 #regression(m,m1[m1:0] ~ z1) <- log(0.5) #regression(m,m2[m2:0] ~ z1) <- log(0.3) regression(m,m1 ~ z1,variance=0) <- log(0.5) regression(m,m2 ~ z1,variance=0) <- log(0.3) intercept(m,~m1+m2) <- c(-0.5,0) m <- timedep(m,y~m1+m2,timecut=c(0,5))  if (FALSE) { # \\dontrun{ d <- sim(m,1e5); d$status <- TRUE dd <- mets::lifetable(Surv(y,status)~z1,data=d,breaks=c(0,5,Inf)) exp(coef(glm(events ~ offset(log(atrisk)) + -1 + interval + interval:z1, dd, family=poisson))) } # }"},{"path":"/reference/toformula.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts strings to formula — toformula","title":"Converts strings to formula — toformula","text":"Converts vector predictors vector responses (characters) #nto formula expression.","code":""},{"path":"/reference/toformula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts strings to formula — toformula","text":"","code":"toformula(y = \".\", x = \".\")"},{"path":"/reference/toformula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts strings to formula — toformula","text":"y vector predictors x vector responses","code":""},{"path":"/reference/toformula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts strings to formula — toformula","text":"object class formula","code":""},{"path":[]},{"path":"/reference/toformula.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Converts strings to formula — toformula","text":"Klaus K. Holst","code":""},{"path":"/reference/toformula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts strings to formula — toformula","text":"","code":"toformula(c(\"age\",\"gender\"), \"weight\") #> c(age, gender) ~ weight #> <environment: 0x561792e706f0>"},{"path":"/reference/tr.html","id":null,"dir":"Reference","previous_headings":"","what":"Trace operator — tr","title":"Trace operator — tr","text":"Calculates trace square matrix.","code":""},{"path":"/reference/tr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trace operator — tr","text":"","code":"tr(x, ...)"},{"path":"/reference/tr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trace operator — tr","text":"x Square numeric matrix ... Additional arguments lower level functions","code":""},{"path":"/reference/tr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trace operator — tr","text":"numeric","code":""},{"path":[]},{"path":"/reference/tr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Trace operator — tr","text":"Klaus K. Holst","code":""},{"path":"/reference/tr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trace operator — tr","text":"","code":"tr(diag(1:5)) #> [1] 15"},{"path":"/reference/trim.html","id":null,"dir":"Reference","previous_headings":"","what":"Trim string of (leading/trailing/all) white spaces — trim","title":"Trim string of (leading/trailing/all) white spaces — trim","text":"Trim string (leading/trailing/) white spaces","code":""},{"path":"/reference/trim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trim string of (leading/trailing/all) white spaces — trim","text":"","code":"trim(x, all = FALSE, ...)"},{"path":"/reference/trim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trim string of (leading/trailing/all) white spaces — trim","text":"x String Trim whitespaces? ... additional arguments lower level functions","code":""},{"path":"/reference/trim.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Trim string of (leading/trailing/all) white spaces — trim","text":"Klaus K. Holst","code":""},{"path":"/reference/twindata.html","id":null,"dir":"Reference","previous_headings":"","what":"Twin menarche data — twindata","title":"Twin menarche data — twindata","text":"Simulated data","code":""},{"path":"/reference/twindata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Twin menarche data — twindata","text":"data.frame","code":""},{"path":"/reference/twindata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Twin menarche data — twindata","text":"Simulated","code":""},{"path":"/reference/twostage.html","id":null,"dir":"Reference","previous_headings":"","what":"Two-stage estimator — twostage","title":"Two-stage estimator — twostage","text":"Generic function.","code":""},{"path":"/reference/twostage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two-stage estimator — twostage","text":"","code":"twostage(object, ...)"},{"path":"/reference/twostage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two-stage estimator — twostage","text":"object Model object ... Additional arguments lower level functions","code":""},{"path":[]},{"path":"/reference/twostage.lvmfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Two-stage estimator (non-linear SEM) — twostage.lvmfit","title":"Two-stage estimator (non-linear SEM) — twostage.lvmfit","text":"Two-stage estimator non-linear structural equation models","code":""},{"path":"/reference/twostage.lvmfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two-stage estimator (non-linear SEM) — twostage.lvmfit","text":"","code":"# S3 method for class 'lvmfit' twostage(   object,   model2,   data = NULL,   predict.fun = NULL,   id1 = NULL,   id2 = NULL,   all = FALSE,   formula = NULL,   std.err = TRUE,   ... )"},{"path":"/reference/twostage.lvmfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two-stage estimator (non-linear SEM) — twostage.lvmfit","text":"object Stage 1 measurement model model2 Stage 2 SEM data data.frame predict.fun Prediction latent variable id1 Optional id-variable (stage 1 model) id2 Optional id-variable (stage 2 model) TRUE return additional output (naive estimates) formula optional formula specifying non-linear relation std.err FALSE calculations standard errors skipped ... Additional arguments lower level functions","code":""},{"path":"/reference/twostage.lvmfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two-stage estimator (non-linear SEM) — twostage.lvmfit","text":"","code":"m <- lvm(c(x1,x2,x3)~f1,f1~z,          c(y1,y2,y3)~f2,f2~f1+z) latent(m) <- ~f1+f2 d <- simulate(m,100,p=c(\"f2,f2\"=2,\"f1,f1\"=0.5),seed=1)  ## Full MLE ee <- estimate(m,d)  ## Manual two-stage if (FALSE) { # \\dontrun{ m1 <- lvm(c(x1,x2,x3)~f1,f1~z); latent(m1) <- ~f1 e1 <- estimate(m1,d) pp1 <- predict(e1,f1~x1+x2+x3)  d$u1 <- pp1[,] d$u2 <- pp1[,]^2+attr(pp1,\"cond.var\")[1] m2 <- lvm(c(y1,y2,y3)~eta,c(y1,eta)~u1+u2+z); latent(m2) <- ~eta e2 <- estimate(m2,d) } # }  ## Two-stage m1 <- lvm(c(x1,x2,x3)~f1,f1~z); latent(m1) <- ~f1 m2 <- lvm(c(y1,y2,y3)~eta,c(y1,eta)~u1+u2+z); latent(m2) <- ~eta pred <- function(mu,var,data,...)     cbind(\"u1\"=mu[,1],\"u2\"=mu[,1]^2+var[1]) (mm <- twostage(m1,model2=m2,data=d,predict.fun=pred)) #>                     Estimate Std. Error  Z-value   P-value #> Measurements:                                              #>    y2~eta            0.96270    0.12462  7.72525    <1e-12 #>    y3~eta            0.97886    0.12477  7.84516    <1e-12 #> Regressions:                                               #>    y1~u1            -0.10923    0.24754 -0.44125     0.659 #>    y1~u2            -0.00916    0.02941 -0.31149    0.7554 #>    y1~z             -0.09088    0.25697 -0.35364    0.7236 #>     eta~u1           1.23462    0.24891  4.96011 7.045e-07 #>     eta~u2           0.00912    0.02417  0.37737    0.7059 #>     eta~z            0.84531    0.27943  3.02508  0.002486 #> Intercepts:                                                #>    y2               -0.19048    0.16526 -1.15257    0.2491 #>    y3                0.00979    0.18282  0.05354    0.9573 #>    eta              -0.16805    0.22950 -0.73226     0.464 #> Residual Variances:                                        #>    y1                1.15103    0.24219  4.75250           #>    y2                0.97707    0.20212  4.83411           #>    y3                1.13661    0.20506  5.54289           #>    eta               1.58985    0.37736  4.21312            if (interactive()) {     pf <- function(p) p[\"eta\"]+p[\"eta~u1\"]*u + p[\"eta~u2\"]*u^2     plot(mm,f=pf,data=data.frame(u=seq(-2,2,length.out=100)),lwd=2) }   ## Reduce test timing ## Splines f <- function(x) cos(2*x)+x+-0.25*x^2 m <- lvm(x1+x2+x3~eta1, y1+y2+y3~eta2, latent=~eta1+eta2) functional(m, eta2~eta1) <- f d <- sim(m,500,seed=1,latent=TRUE) m1 <- lvm(x1+x2+x3~eta1,latent=~eta1) m2 <- lvm(y1+y2+y3~eta2,latent=~eta2) mm <- twostage(m1,m2,formula=eta2~eta1,type=\"spline\") if (interactive()) plot(mm)  nonlinear(m2,type=\"quadratic\") <- eta2~eta1 a <- twostage(m1,m2,data=d) if (interactive()) plot(a)  kn <- c(-1,0,1) nonlinear(m2,type=\"spline\",knots=kn) <- eta2~eta1 a <- twostage(m1,m2,data=d) x <- seq(-3,3,by=0.1) y <- predict(a, newdata=data.frame(eta1=x))  if (interactive()) {   plot(eta2~eta1, data=d)   lines(x,y, col=\"red\", lwd=5)    p <- estimate(a,f=function(p) predict(a,p=p,newdata=x))$coefmat   plot(eta2~eta1, data=d)   lines(x,p[,1], col=\"red\", lwd=5)   confband(x,lower=p[,3],upper=p[,4],center=p[,1], polygon=TRUE, col=Col(2,0.2))    l1 <- lm(eta2~splines::ns(eta1,knots=kn),data=d)   p1 <- predict(l1,newdata=data.frame(eta1=x),interval=\"confidence\")   lines(x,p1[,1],col=\"green\",lwd=5)   confband(x,lower=p1[,2],upper=p1[,3],center=p1[,1], polygon=TRUE, col=Col(3,0.2)) }  ## Reduce test timing  if (FALSE)  ## Reduce timing  ## Cross-validation example  ma <- lvm(c(x1,x2,x3)~u,latent=~u)  ms <- functional(ma, y~u, value=function(x) -.4*x^2) #> Error: object 'ma' not found  d <- sim(ms,500)#,seed=1) #> Error: object 'ms' not found  ea <- estimate(ma,d) #> Error: object 'ma' not found   mb <- lvm()  mb1 <- nonlinear(mb,type=\"linear\",y~u)  mb2 <- nonlinear(mb,type=\"quadratic\",y~u)  mb3 <- nonlinear(mb,type=\"spline\",knots=c(-3,-1,0,1,3),y~u)  mb4 <- nonlinear(mb,type=\"spline\",knots=c(-3,-2,-1,0,1,2,3),y~u)  ff <- lapply(list(mb1,mb2,mb3,mb4),       function(m) function(data,...) twostage(ma,m,data=data,st.derr=FALSE))  a <- cv(ff,data=d,rep=1) #> Error in cv(ff, data = d, rep = 1): could not find function \"cv\"  a #>                     Estimate Std. Error  Z-value  P-value #> Measurements:                                             #>    y2~eta2           1.03076    0.03876 26.59191   <1e-12 #>    y3~eta2           0.99635    0.04036 24.68596   <1e-12 #> Regressions:                                              #>    eta2~eta1_1       2.47344    0.22699 10.89681   <1e-12 #>    eta2~eta1_2      -0.48653    0.05555 -8.75771   <1e-12 #> Intercepts:                                               #>    y2                0.02005    0.06568  0.30528   0.7602 #>    y3                0.07986    0.06779  1.17797   0.2388 #>    eta2              1.16241    0.16093  7.22290   <1e-12 #> Residual Variances:                                       #>    y1                1.11229    0.10786 10.31201          #>    y2                1.00927    0.09818 10.28011          #>    y3                1.09169    0.09757 11.18840          #>    eta2              1.81941    0.18188 10.00346           # \\dontrun{}"},{"path":"/reference/twostageCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validated two-stage estimator — twostageCV","title":"Cross-validated two-stage estimator — twostageCV","text":"Cross-validated two-stage estimator non-linear SEM","code":""},{"path":"/reference/twostageCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validated two-stage estimator — twostageCV","text":"","code":"twostageCV(   model1,   model2,   data,   control1 = list(trace = 0),   control2 = list(trace = 0),   knots.boundary,   nmix = 1:4,   df = 1:9,   fix = TRUE,   std.err = TRUE,   nfolds = 5,   rep = 1,   messages = 0,   ... )"},{"path":"/reference/twostageCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validated two-stage estimator — twostageCV","text":"model1 model 1 (exposure measurement error model) model2 model 2 data data.frame control1 optimization parameters model 1 control2 optimization parameters model 1 knots.boundary boundary points natural cubic spline basis nmix number mixture components df spline degrees freedom fix automatically fix parameters identification (TRUE) std.err calculation standard errors (TRUE) nfolds Number folds (cross-validation) rep Number repeats cross-validation messages print information (>0) ... additional arguments lower","code":""},{"path":"/reference/twostageCV.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validated two-stage estimator — twostageCV","text":"","code":"## Reduce Ex.Timings##' m1 <- lvm( x1+x2+x3 ~ u, latent= ~u) m2 <- lvm( y ~ 1 ) m <- functional(merge(m1,m2), y ~ u, value=function(x) sin(x)+x) distribution(m, ~u1) <- uniform.lvm(-6,6) d <- sim(m,n=500,seed=1) nonlinear(m2) <- y~u1 if (requireNamespace('mets', quietly=TRUE)) {   set.seed(1)   val <- twostageCV(m1, m2, data=d, std.err=FALSE, df=2:6, nmix=1:2,                   nfolds=2)   val } #> ──────────────────────────────────────────────────────────────────────────────── #> Selected mixture model: 1 component #>       AIC1 #> 1 5130.210 #> 2 5132.707 #> ──────────────────────────────────────────────────────────────────────────────── #> Selected spline model degrees of freedom: 3 #> Knots: -2.674 -0.7956 1.082 2.96  #>  #>      RMSE(nfolds=2, rep=1) #> df:1              5.353550 #> df:2              5.260141 #> df:3              4.851035 #> df:4              5.329716 #> df:5              6.220957 #> df:6              5.792509 #> ──────────────────────────────────────────────────────────────────────────────── #>  #>                     Estimate Std. Error Z-value P-value #> Regressions:                                            #>    y~u1_1            1.38092                            #>    y~u1_2            0.02123                            #>    y~u1_3           -0.08440                            #> Intercepts:                                             #>    y                -0.33435                            #> Residual Variances:                                     #>    y                 1.61964"},{"path":"/reference/vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract variable names from latent variable model — vars","title":"Extract variable names from latent variable model — vars","text":"Extract exogenous variables (predictors), endogenous variables (outcomes), latent variables (random effects), manifest (observed) variables lvm object.","code":""},{"path":"/reference/vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract variable names from latent variable model — vars","text":"","code":"vars(x,...)  endogenous(x,...)  exogenous(x,...)  manifest(x,...)  latent(x,...)  # S3 method for class 'lvm' exogenous(x, xfree = TRUE, ...) <- value  # S3 method for class 'lvm' exogenous(x,variable,latent=FALSE,index=TRUE,...)  # S3 method for class 'lvm' latent(x, clear = FALSE, ...) <- value"},{"path":"/reference/vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract variable names from latent variable model — vars","text":"x lvm-object ... Additional arguments passed low level functions variable list variables alter latent Logical defining whether latent variables without parents included result index internal use clear Logical indicating whether add remove latent variable status xfree internal use value Formula character vector variable names.","code":""},{"path":"/reference/vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract variable names from latent variable model — vars","text":"Vector variable names.","code":""},{"path":"/reference/vars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract variable names from latent variable model — vars","text":"vars returns variables lvm-object including manifest latent variables. Similarily manifest latent returns observered resp. latent variables model. exogenous returns manifest variables without parents, e.g. covariates model, however argument latent=TRUE can used also include latent variables without parents result. Pr. default lava include parameters exogenous variables optimisation routine estimation (likelihood remaining observered variables conditional covariates), however behaviour can altered via assignment function exogenous<- telling lava subset (valid) variables condition .  Finally latent returns vector names latent variables x. assigment function latent<- can used change latent status variables model.","code":""},{"path":[]},{"path":"/reference/vars.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract variable names from latent variable model — vars","text":"Klaus K. Holst","code":""},{"path":"/reference/vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract variable names from latent variable model — vars","text":"","code":"g <- lvm(eta1 ~ x1+x2) regression(g) <- c(y1,y2,y3) ~ eta1 latent(g) <- ~eta1 endogenous(g) #> [1] \"y1\" \"y2\" \"y3\" exogenous(g) #> [1] \"x1\" \"x2\" identical(latent(g), setdiff(vars(g),manifest(g))) #> [1] TRUE"},{"path":"/reference/vec.html","id":null,"dir":"Reference","previous_headings":"","what":"vec operator — vec","title":"vec operator — vec","text":"vec operator","code":""},{"path":"/reference/vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"vec operator — vec","text":"","code":"vec(x, matrix = FALSE, sep = \".\", ...)"},{"path":"/reference/vec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"vec operator — vec","text":"x Array matrix TRUE row vector (matrix) returned sep Seperator ... Additional arguments","code":""},{"path":"/reference/vec.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"vec operator — vec","text":"Convert array vector","code":""},{"path":"/reference/vec.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"vec operator — vec","text":"Klaus Holst","code":""},{"path":"/reference/wait.html","id":null,"dir":"Reference","previous_headings":"","what":"Wait for user input (keyboard or mouse) — wait","title":"Wait for user input (keyboard or mouse) — wait","text":"Wait user input (keyboard mouse)","code":""},{"path":"/reference/wait.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wait for user input (keyboard or mouse) — wait","text":"","code":"wait()"},{"path":"/reference/wait.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Wait for user input (keyboard or mouse) — wait","text":"Klaus K. Holst","code":""},{"path":"/reference/wkm.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted K-means — wkm","title":"Weighted K-means — wkm","text":"Weighted K-means via Lloyd's algorithm","code":""},{"path":"/reference/wkm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted K-means — wkm","text":"","code":"wkm(   x,   mu,   data,   weights = rep(1, NROW(x)),   iter.max = 20,   n.start = 5,   init = \"kmpp\",   ... )"},{"path":"/reference/wkm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted K-means — wkm","text":"x Data (formula) mu Initial centers (number centers chosen randomly among x) data optional data frmae weights Optional weights iter.max Max number iterations n.start Number restarts init method create initial centres (default kmeans++) ... Additional arguments lower level functions","code":""},{"path":"/reference/wkm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Weighted K-means — wkm","text":"Klaus K. Holst","code":""},{"path":"/reference/wrapvec.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrap vector — wrapvec","title":"Wrap vector — wrapvec","text":"Wrap vector","code":""},{"path":"/reference/wrapvec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrap vector — wrapvec","text":"","code":"wrapvec(x, delta = 0L, ...)"},{"path":"/reference/wrapvec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrap vector — wrapvec","text":"x Vector integer delta Shift ... Additional parameters","code":""},{"path":"/reference/wrapvec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrap vector — wrapvec","text":"","code":"wrapvec(5,2) #> [1] 3 4 5 1 2"},{"path":"/reference/zibreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression model for binomial data with unkown group of immortals — zibreg","title":"Regression model for binomial data with unkown group of immortals — zibreg","text":"Regression model binomial data unkown group immortals (zero-inflated binomial regression)","code":""},{"path":"/reference/zibreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression model for binomial data with unkown group of immortals — zibreg","text":"","code":"zibreg(   formula,   formula.p = ~1,   data,   family = stats::binomial(),   offset = NULL,   start,   var = \"hessian\",   ... )"},{"path":"/reference/zibreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression model for binomial data with unkown group of immortals — zibreg","text":"formula Formula specifying formula.p Formula model disease prevalence data data frame family Distribution family (see help page family) offset Optional offset start Optional starting values var Type variance (robust, expected, hessian, outer) ... Additional arguments lower level functions","code":""},{"path":"/reference/zibreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Regression model for binomial data with unkown group of immortals — zibreg","text":"Klaus K. Holst","code":""},{"path":"/reference/zibreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression model for binomial data with unkown group of immortals — zibreg","text":"","code":"## Simulation n <- 2e3 x <- runif(n,0,20) age <- runif(n,10,30) z0 <- rnorm(n,mean=-1+0.05*age) z <- cut(z0,breaks=c(-Inf,-1,0,1,Inf)) p0 <- lava:::expit(model.matrix(~z+age) %*% c(-.4, -.4, 0.2, 2, -0.05)) y <- (runif(n)<lava:::tigol(-1+0.25*x-0*age))*1 u <- runif(n)<p0 y[u==0] <- 0 d <- data.frame(y=y,x=x,u=u*1,z=z,age=age) head(d) #>   y          x u        z      age #> 1 0 15.6619534 0   (-1,0] 21.65935 #> 2 0  8.7631479 0   (-1,0] 14.06870 #> 3 0  8.6291196 1 (1, Inf] 21.59505 #> 4 0  0.5499576 0    (0,1] 21.81296 #> 5 0  2.9312369 1    (0,1] 29.54373 #> 6 0  8.4519032 0   (-1,0] 14.15076  ## Estimation e0 <- zibreg(y~x*z,~1+z+age,data=d) e <- zibreg(y~x,~1+z+age,data=d) compare(e,e0) #>  #> \t- Likelihood ratio test - #>  #> data:   #> chisq = 12.278, df = 6, p-value = 0.05606 #> sample estimates: #> log likelihood (model 1) log likelihood (model 2)  #>                -846.4202                -840.2815  #>  e #>                   Estimate         2.5%       97.5%      P-value #> (Intercept)    -1.28441289 -1.900385245 -0.66844054 4.372195e-05 #> x               0.33928559  0.160300206  0.51827098 2.029487e-04 #> pr:(Intercept) -0.11215262 -0.659438960  0.43513372 6.879449e-01 #> pr:z(-1,0]     -0.33975924 -0.763691542  0.08417306 1.162275e-01 #> pr:z(0,1]       0.40405512 -0.005142301  0.81325254 5.294938e-02 #> pr:z(1, Inf]    2.20163957  1.712058845  2.69122029 1.208246e-18 #> pr:age         -0.07630284 -0.100635280 -0.05197041 7.938579e-10 #>  #> Prevalence probabilities: #>                              Estimate      2.5%     97.5% #> {(Intercept)}               0.4719912 0.3408657 0.6070989 #> {(Intercept)} + {z(-1,0]}   0.3889063 0.2729729 0.5189329 #> {(Intercept)} + {z(0,1]}    0.5724618 0.4345205 0.6999870 #> {(Intercept)} + {z(1, Inf]} 0.8898772 0.7998351 0.9423350 #> {(Intercept)} + {age}       0.4530251 0.3278957 0.5843865 PD(e0,intercept=c(1,3),slope=c(2,6)) #>     Estimate  Std.Err      2.5%    97.5% #> 50% 2.128146 4.370486 -6.437849 10.69414 #> attr(,\"b\") #> [1] -0.3705218  0.1741055  B <- rbind(c(1,0,0,0,20),            c(1,1,0,0,20),            c(1,0,1,0,20),            c(1,0,0,1,20)) prev <- summary(e,pr.contrast=B)$prevalence  x <- seq(0,100,length.out=100) newdata <- expand.grid(x=x,age=20,z=levels(d$z)) fit <- predict(e,newdata=newdata) plot(0,0,type=\"n\",xlim=c(0,101),ylim=c(0,1),xlab=\"x\",ylab=\"Probability(Event)\") count <- 0 for (i in levels(newdata$z)) {   count <- count+1   lines(x,fit[which(newdata$z==i)],col=\"darkblue\",lty=count) } abline(h=prev[3:4,1],lty=3:4,col=\"gray\") abline(h=prev[3:4,2],lty=3:4,col=\"lightgray\") abline(h=prev[3:4,3],lty=3:4,col=\"lightgray\") legend(\"topleft\",levels(d$z),col=\"darkblue\",lty=seq_len(length(levels(d$z))))"},{"path":"/news/index.html","id":"lava-182-development-version","dir":"Changelog","previous_headings":"","what":"lava 1.8.2 (development version)","title":"lava 1.8.2 (development version)","text":"Improved closed testing procedure closed_testing (depr. closed.testing) tests documentation New data deprdiag","code":""},{"path":"/news/index.html","id":"lava-181","dir":"Changelog","previous_headings":"","what":"lava 1.8.1","title":"lava 1.8.1","text":"CRAN release: 2025-01-12 sim.default now accepts argument R list (lists) arguments. New methods subset.estimate, transform.estimate, labels.estimate","code":""},{"path":"/news/index.html","id":"lava-180","dir":"Changelog","previous_headings":"","what":"lava 1.8.0","title":"lava 1.8.0","text":"CRAN release: 2024-03-05 New methods estimate.mlm, IC.mlm, pars.mlm, estimate.array, estimate.data.frame Print method tabular data (matrix, data.frame, data.table) merge now supports regular expressions IC returns row-names (default id) obtained model.matrix similar New vignette: Influence Functions operators %.open%, %.closed% checking elements within range 3 %.open% c(0,1)) estimate(..., estimator='glm') now works formulas just intercept .data.frame.sim, .matrix.sim fixed issues quasi* families negative binomial regr (MASS:glm.nb)","code":""},{"path":"/news/index.html","id":"lava-173","dir":"Changelog","previous_headings":"","what":"lava 1.7.3","title":"lava 1.7.3","text":"CRAN release: 2023-11-04 parameter.estimate method extract matrix estimates, standard errors, confidence limits estimate object (coefmat element) pairwise difference '-'.estimate pairwise.diff Optional mc.cores arguments cv bootstrap parameter.lvm now automatically removes previously variables lvm object name new added parameters. Print function deals gracefully non-rectangular objects bug-fix stack.estimate (wrong stand-errors twostage since version 1.7.0)","code":""},{"path":"/news/index.html","id":"lava-1721","dir":"Changelog","previous_headings":"","what":"lava 1.7.2.1","title":"lava 1.7.2.1","text":"CRAN release: 2023-02-27 Maintenance release version 1.7.2 broke compatibility R<4.1.","code":""},{"path":"/news/index.html","id":"lava-172","dir":"Changelog","previous_headings":"","what":"lava 1.7.2","title":"lava 1.7.2","text":"CRAN release: 2023-02-23 Compatibility issues development version R fixed. cluster.index now also works loading package (directly calling lava::estimate) weibull.lvm coxExponential.lvm now uses default parametrizations similar rweibull, rexp. weibull.lvm now arguments “intercept”,“sigma” directly relates accelerated failure time formulation. Packages gof, lava.tobit removed Suggested packages.","code":""},{"path":"/news/index.html","id":"lava-171","dir":"Changelog","previous_headings":"","what":"lava 1.7.1","title":"lava 1.7.1","text":"CRAN release: 2023-01-06 Fixed bug variance estimates estimate clustered observations. Discrete uniform distributions can now specified uniform.lvm(value=...).","code":""},{"path":"/news/index.html","id":"lava-170","dir":"Changelog","previous_headings":"","what":"lava 1.7.0","title":"lava 1.7.0","text":"CRAN release: 2022-10-25 cv method moved ‘targeted’ package New IC method returns influence function model object. iid argument iid estimate method now replaced argument IC (user supplied matrix must now actual influence function sample-size scaled version returned iid method). fixed bug calls like regression(\"y\", value=function(x) x) work. merge.estimate now works without IC element","code":""},{"path":"/news/index.html","id":"lava-1610","dir":"Changelog","previous_headings":"","what":"lava 1.6.10","title":"lava 1.6.10","text":"CRAN release: 2021-09-02 Improved starting values MLE optimization. New simulation distributions: multinomial.lvm, none.lvm, constant.lvm, id.lvm. regression, regression.lvm: ‘value’ argument can now (non-linear) function specifying functional relationship outcomes covariates (simulation sim method). New intervention method applying interventions lvm-objects Progress updates now done via progressr library (enabled progressr::handlers(global=TRUE)). Parallelization now controlled via future library. enable multicore parallelization: future::plan(\"multicore\"). New plot_region function adding confidence regions plots.","code":""},{"path":"/news/index.html","id":"lava-169","dir":"Changelog","previous_headings":"","what":"lava 1.6.9","title":"lava 1.6.9","text":"CRAN release: 2021-03-11 idplot: now accepts matrix data.frame 1st argument. New argument: return.data. Unit tests updated Bug fixes: cv: rmse output fixed. score: Fixed bug linear Gaussian model argument ‘indiv=TRUE’. estimate.formula: call object initialized correctly. plot.lvm: ‘noplot’ argument now works plot engines.","code":""},{"path":"/news/index.html","id":"lava-1681","dir":"Changelog","previous_headings":"","what":"lava 1.6.8.1","title":"lava 1.6.8.1","text":"CRAN release: 2020-11-04 Maintenance release confpred: split-conformal prediction method updated","code":""},{"path":"/news/index.html","id":"lava-168","dir":"Changelog","previous_headings":"","what":"lava 1.6.8","title":"lava 1.6.8","text":"CRAN release: 2020-09-26 Bug-fix: parameter(m,x) now returns lvm object just x profile likelihood confidence intervals tobit/censored observations. Estimating partial correlations Non-linear latent variable omdels Pseudo-inverse used “normal” estimator Starting values mixture fixed","code":""},{"path":"/news/index.html","id":"lava-167","dir":"Changelog","previous_headings":"","what":"lava 1.6.7","title":"lava 1.6.7","text":"CRAN release: 2020-03-05 Fixed bug composite likelihood complik used censored variables (Surv objects). Fixed regular expression ‘spaghetti’ function plot.sim: ‘rug’ argument now default FALSE ‘auto.layout’ disabled nr=nc=1. base::sequence() now generic function consequence sequence.lvm renamed Sequence.lvm. function binary.lvm now alias ones.lvm.","code":""},{"path":"/news/index.html","id":"lava-166","dir":"Changelog","previous_headings":"","what":"lava 1.6.6","title":"lava 1.6.6","text":"CRAN release: 2019-08-01 Weighted kmeans++ (wkm). Gaussian mixture models (mvnmix) now initialized default using kmeans++. sim method implemented mvnmix models. Bug fix: Newton-Raphson method (lava::NR) used numerical approximation Hessian even submitted attribute objective function.","code":""},{"path":"/news/index.html","id":"lava-165","dir":"Changelog","previous_headings":"","what":"lava 1.6.5","title":"lava 1.6.5","text":"CRAN release: 2019-02-12 Maintenance release.","code":""},{"path":"/news/index.html","id":"lava-164","dir":"Changelog","previous_headings":"","what":"lava 1.6.4","title":"lava 1.6.4","text":"CRAN release: 2018-11-25 New simulation distributions: constant relative risk risk difference models Richardson, Robins Wang, 2017): binomial.rd, binomial.rr. Base new hook ‘simulate_multiple_inputs’ allows distribution depend non-linearly multiple different input variables. sim.lvm: ‘X’ argument can now fix (manipulate) variable exogenous variables. Summary function sim.default updated (‘estimate’ argument can now list element estimate position optionally standard error true value). Starting values updated mixture models. parameter names can obtained mixture(...,names=TRUE) set mixture(...,control=list(start=...))). Naming conventions multigroup parameters: ‘par@g’ (par: name parameter, g: first group number ‘par’ observed). Starting values can specified estimate(…,control(list(start=…))). New print summary methods mixture models. Renamed (weighted) K-means function ‘km’ wkm. Derivative method deriv.function based complex step derivatives. twostageCV: estimation mixture models now parallelized mc.cores>1.","code":""},{"path":"/news/index.html","id":"lava-163","dir":"Changelog","previous_headings":"","what":"lava 1.6.3","title":"lava 1.6.3","text":"CRAN release: 2018-08-10 Fixed problems plots (Rgraphviz) Better print method twostageCV Improved M-step mixture method","code":""},{"path":"/news/index.html","id":"lava-162","dir":"Changelog","previous_headings":"","what":"lava 1.6.2","title":"lava 1.6.2","text":"CRAN release: 2018-07-02 twostageCV: cross-validate two-stage estimator rmvn, dmvn moved mets package (C++ implementation, old versions renamed lava::rmvn0, lava::dmvn0) mediation proportion handled correctly direct effect zero unit tests clean-(namespace) merge.lvm now correctly handles fixed covariance parameters","code":""},{"path":"/news/index.html","id":"lava-161","dir":"Changelog","previous_headings":"","what":"lava 1.6.1","title":"lava 1.6.1","text":"CRAN release: 2018-03-28 Newton-raphson algorithm made robust. New sim.method. plot.sim method now default plots density estimates Compatibility fix Matrix library","code":""},{"path":"/news/index.html","id":"lava-16","dir":"Changelog","previous_headings":"","what":"lava 1.6","title":"lava 1.6","text":"CRAN release: 2018-01-12 Mixture Latent variable models (mixture). Fast version requires ‘mets’ packages; Gaussian mixture models (mvnmix); weighted k-means (km) estimate.default: ‘keep’, ‘use’ arguments can specified regular expressions (argument regex=TRUE). Summary method now returns Wald test (null: parameters zero). makemissing: seed argument added. Global change: ‘silent’ argument renamed ‘messages’ New utility functions: Grep, Na2x, x2NA, wait, waitclick, rotation, Rot2d, Rot3d Condition numbers calculated via SVD na.pass0: returns data.frame original number rows zeros (first level factors) rows missing data. stack: ‘weights’ argument renamed ‘propensity’. propensity=TRUE, first argument (model) treated propensity score model (glm) ‘predict’ method used predictions. estimate.formula now default wraps glm iid method return matrix size full data (zero rows data missing). Updated output functions class ‘sim’ (print method plot).. Plot method: density.alpha applied standard error (‘se’) level. composite likelihood (complik) refactored + new example. ordinal method now cleans properly variables removed (rmvar, subset). twostage: fixed mixture model (class ‘lvm.mixture’). New help page + examples. Predict function updated (newdata argument covariate levels can specified).","code":""},{"path":"/news/index.html","id":"lava-151","dir":"Changelog","previous_headings":"","what":"lava 1.5.1","title":"lava 1.5.1","text":"CRAN release: 2017-09-27 conformal predictions: confpred warnings (char2num used instead coersion via .numeric) %++% function compositon New summary.effects methods mediation proportion output New hook: remove.hooks (see example ordinal.lvm) constrain methods now handled robustly sim.lvm allowing vectorized non-vectorized functions Non-linear associations can now specified nonlinear method. Estimation via twostage function. Robust standard errors added IV estimator (2SLS) New cross-validation function: cv (csplit function creating random sets).","code":""},{"path":"/news/index.html","id":"lava-15","dir":"Changelog","previous_headings":"","what":"lava 1.5","title":"lava 1.5","text":"CRAN release: 2017-03-16 lava.tobit longer required ordinal censored responses. Default now use implementation ‘mets’ package. Composite likelihood method (complik) updated weight argument renamed weights agreement lm, glm, coxph, … sim.default: new argument ‘arg’ passed simulation function sim.default: new argument ‘iter’. TRUE iteration number passed function call first argument (default FALSE) estimate.default: Wildcards/global expressions can now used specifying contrasts based syntax functions contr, parsedesign. See examples help-page. argument transform.ci renamed back.transform. correlation methods matrices data.frames (either pairwise full MLE). methods can now return influence functions. revdiag: dimnames kept Combine: output updated forestplot: point estimates shown default backdoor now works without conditioning set (yields possible conditioning sets) New formula syntax: y+x~v+z c(y,x)~v+z spaghetti: trend.formula can now contain factor statement rhs","code":""},{"path":"/news/index.html","id":"lava-147","dir":"Changelog","previous_headings":"","what":"lava 1.4.7","title":"lava 1.4.7","text":"CRAN release: 2017-01-27 Maintenance release models can now specified y1+y2~x1+x2 instead c(y1,2y)~x1+x2 sim method now seed argument","code":""},{"path":"/news/index.html","id":"lava-146","dir":"Changelog","previous_headings":"","what":"lava 1.4.6","title":"lava 1.4.6","text":"CRAN release: 2016-12-20 New backtrace algorithms Newton-Raphson optimization routine (NR). diagtest updated.","code":""},{"path":"/news/index.html","id":"lava-145","dir":"Changelog","previous_headings":"","what":"lava 1.4.5","title":"lava 1.4.5","text":"CRAN release: 2016-10-26 New graph functions: dsep: check d-separation (conditional independence). backdoor: check backdoor criterion graph (lvm-object). adjMat: return adjaceny matrix. edgeList: return edge list. ancestors: return ancenstors nodes. descendants: return descendants nodes. simple paths graph can now extracted : path(...,=TRUE) Covariance parameters now reference ~~ instead ,. Applies setting starting values estimate, parameters sim,compare,estimate,… use old syntax set lava.options(symbol=c(\"~\",\",\")). layout argument added lava.options (default ‘dot’) visNetwork support, new plot.engine argument added plot methods. bootstrap.lvmfit now default returns original estimates. print, transform methods updated (transform output). + operator overloaded lvm estimate objects (merge). New composite likelihood function: complik. New functions simple association measures: riskcomp, rdiff, rratio, … New argument ‘latent’ simulate method. FALSE latent variables dropped returned data.frame. modelsearch default now shows directional undirectional associations (type=‘’ vs type=‘cor’). sim.default now stores timings. New print functions (data.table like output). lvm model can now updated sim function, instance setting parameter values simulation : m <- sim(m,p=p,...), faster subsequent calls sim(m,n=n). estimate.default can now simulate p-values (‘R’ argument). Returns object can also used input estimate. Bug fixes: NR optimization back-tracing; fixed matrices.lvm called without variance parameters; fixed bug r-square computations. Contrast matrix can specified function contr.","code":""},{"path":"/news/index.html","id":"lava-144","dir":"Changelog","previous_headings":"","what":"lava 1.4.4","title":"lava 1.4.4","text":"CRAN release: 2016-08-13 estimate.default now use id-variable ‘estimate’ object ‘id’ argument left unspecified. multinomial,gkgamma,kappa additional arguments (…) now parsed ‘estimate.default’ (including id). Updated print/summary methods ‘estimate.default’. Sample/cluster-size added output. Code clean-optimization. Smarter calculations kronecker products, regular expressions updated. New function ‘predictlvm’ return jacobian. Intercepts can now specified via parantheses, e.g., y ~ (-2) + x ‘getoutcome’ sep argument splitting ‘|’ statements formulas. Partial gamma, gkgamma, updated (probability interpretation, homogeneity tests removed) ‘moments’ function now returns conditional mean multiple rows. Side effect fixed across multiple functions twostage function support mixture models Beta (Beta.lvm) Finite Gaussian (GM2.lvm,GM3.lvm) Mixtures added. ‘sim’: parameters can now specified part ‘…’ summary.sim: calculate Wald CI confint=TRUE, otherwise use user supplied confidence limits. Clopper-pearson intervals exact binomial tests added ‘diagtest’. Interval censoring ‘normal’ estimator, now also works ‘binary’ definitions. default plot style updated.","code":""},{"path":"/news/index.html","id":"lava-143","dir":"Changelog","previous_headings":"","what":"lava 1.4.3","title":"lava 1.4.3","text":"CRAN release: 2016-04-11 partial gamma coefficients (gkgamma) Unit tests works new testthat version Avoid trying fork new processes windows (bootstrap,sim.default)","code":""},{"path":"/news/index.html","id":"lava-142","dir":"Changelog","previous_headings":"","what":"lava 1.4.2","title":"lava 1.4.2","text":"CRAN release: 2016-04-05 Code optimization minor bug fixes Travis-CI, unit-tests glm estimator update (censored regression) polychoric correlations (pcor) New utility functions: wrapvec, offdiag simulation: regression design parameters (see weibull + variance hetereogeneity example help(‘sim’)) Byte compile default","code":""},{"path":"/news/index.html","id":"lava-141","dir":"Changelog","previous_headings":"","what":"lava 1.4.1","title":"lava 1.4.1","text":"CRAN release: 2015-06-22 New plot.estimate method Documentation examples updated","code":""},{"path":"/news/index.html","id":"lava-140","dir":"Changelog","previous_headings":"","what":"lava 1.4.0","title":"lava 1.4.0","text":"CRAN release: 2015-02-17 Linear measurement error model: ‘measurement.error’ Diagnostic tests: ‘diagtest’ ‘plotConf’ updated support special function terms (, poly, ns, …). Old version available (namespace) lava:::plotConf0 Pareto distribution: ‘pareto.lvm’ Code clean-/optimization: ‘EventTime’, ‘stack’ ‘estimate.default’ new syntax contrast specification (parsedesign) ‘regression.lvm’ y,x argument (alias ,) plot longitudinal data: ‘spaghetti’ Examples updated","code":""},{"path":"/news/index.html","id":"lava-13","dir":"Changelog","previous_headings":"","what":"lava 1.3","title":"lava 1.3","text":"CRAN release: 2014-11-18 New syntax categorical predictors (method ‘categorical’ argument ‘additive=FALSE’ ’regression method) Argument ‘intervals’ added ‘ones.lvm’ piece-wise constant effects Argument ‘average=TRUE’ now needed empirical averages estimate.default Fixed bug score.glm (weights offset) introduced version 1.2.6 small-sample corrections Default id row names estimate.default (used merge method) iid decompostion also returned hypothesis contrasts keep argument added estimate.default merge labels argument added estimate.default ‘images’ function visualization tabular data added namespace ‘ksmooth’ ‘surface’ surface estimation visualization bivariate data functions ‘dsort’: Sort data.frames general multivariate distributions simulations. see example ‘sim’ ‘or2prob’, ‘tetrachoric’ conversion probabilities (tetrachoric correlations). ‘prob.normal’: calculates probabilities threshold model given thresholds variance See also mets:::assoc calculations kappa, gamma, uncer.coef. ‘normal.threshold’: returns thresholds,variance,mu model categorical outcomes. Multiple testing routines: closed.testing, p.correct, … ‘Missing’ method updated simple ‘suffix’ argument Back-tracing updated Newton-Raphson routine","code":""},{"path":"/news/index.html","id":"lava-126","dir":"Changelog","previous_headings":"","what":"lava 1.2.6","title":"lava 1.2.6","text":"CRAN release: 2014-05-07 New ‘stack’ function two-stage estimation (via ‘estimate’ objects) New ‘blocksample’ function resampling clustered data. New function ‘Missing’ generate complex missing data patterns Weibull parametrization ‘coxWeibull.lvm’ rolled back (ver. 1.2.4). function ‘weibull.lvm’ now leads Accelerated Failure Time model (see examples ‘eventTime’) iid function cleanup (new ‘bread’ attribute). iid.glm now gives correct estimated influence functions ‘quasi’ link (constant variance) Parameter constraints (co)variance parameters now possible syntax lvm(…,y~~*x) (corresponding covariance(…,y~x)<-“”) additional utilities: pdfconvert, scheffe, images, click. confband updated ‘polygon’ argument. New function getMplus: Import results Mplus New function getSAS: Import SAS ODS New ‘edgecolor’ argument plot-function","code":""},{"path":"/news/index.html","id":"lava-125","dir":"Changelog","previous_headings":"","what":"lava 1.2.5","title":"lava 1.2.5","text":"CRAN release: 2014-03-14 ‘merge’ method added combining ‘estimate’ objects Adjustments starting values Function ‘categorical’ adding categorical predictors simulation model Improved flexibility simulations ‘transform’,‘constrain’ (ex: categorical predictors) Added ‘dataid’ argument estimate.default allowing different id ‘data’ ..d. decomposition model parameter estimates. argument ‘stack=FALSE’ influence functions within clusters stacked together. R-squared values (+ approximate standard errors/..d. decomposition) via ‘rsq(model,TRUE)’ New infrastructure adding additional parameters models (user-visible changes). multinomial function calculating influence curves multinomial probabilities. ‘gammagk’ ‘kappa’ methods calculating Goodman-Kruskals gamma Cohens kappa coefficients. ordreg function univariate ordinal regression models iid methods data.frames/matrices (empirical mean variance) Support using ‘mets::cluster.index’ GEE-type models (much faster). plotConf updated (vcov argument added graphical arguments parsed plotting functions) Additional unit-tests implemented New ‘forestplot’ ‘Combine’ functions Covariance structure may now specified using ‘’, e.g. ’lvm(c(y,v)z+u)’ specifies correlation residuals (y,z),(y,u),(v,z),(v,u).","code":""},{"path":"/news/index.html","id":"lava-124","dir":"Changelog","previous_headings":"","what":"lava 1.2.4","title":"lava 1.2.4","text":"CRAN release: 2013-12-17 Avoid estimating IC ‘estimate.default’ ‘vcov’ argument given. New default starting values Time-varying effects via ‘timedep’ R-squared added summary alias: covariance->variance added size argument binomial.lvm;","code":""},{"path":"/news/index.html","id":"lava-123","dir":"Changelog","previous_headings":"","what":"lava 1.2.3","title":"lava 1.2.3","text":"CRAN release: 2013-10-28 ‘subset’ argument added estimate.default. Calculates empirical averages conditional subsets data Improved output compare/estimate functions Minor bug fixes (plot, predict) sim: Piecewise constant rates coxEponential.lvm. New aalenExponential.lvm function additive models. Functions ones.lvm sequence.lvm deterministic variables.","code":""},{"path":"/news/index.html","id":"lava-122","dir":"Changelog","previous_headings":"","what":"lava 1.2.2","title":"lava 1.2.2","text":"CRAN release: 2013-07-12 Regression parameters now default referenced using ‘~’, e.g. “y~x” instead “y<-x”. Applies setting starting values ‘estimate’, parameters ‘sim’,‘compare’,‘estimate’,…. use old syntax set ‘lava.options(symbol=c(“<-”,“<->”))’ Newton-Raphson/scoring procedure updated Search-interval profile likelihood CI improved (variance parameters) ‘estimate.default’ updated (LRT) ‘iid’ updated (variance now obtained tensor product result) progress bar ‘bootstrap’ ‘modelsearch’ various minor bug fixes new functions: Expand (expand.grid wrapper), (wrapper)","code":""},{"path":"/news/index.html","id":"lava-121","dir":"Changelog","previous_headings":"","what":"lava 1.2.1","title":"lava 1.2.1","text":"CRAN release: 2013-05-21 Optimization + minor bug fixes","code":""},{"path":"/news/index.html","id":"lava-120","dir":"Changelog","previous_headings":"","what":"lava 1.2.0","title":"lava 1.2.0","text":"CRAN release: 2013-04-24 New method ‘iid’ extracting ..d. decomposition (influence functions) model objects (e.g. glm, lvm, …) Method ‘estimate’ can now used model objects transform parameters (Delta method) conduct Wald tests. Average effects, .e. averaging functionals empirical distribution also possible including calculation standard errors. ‘curereg’ function estimating mixtures binary data. Instrumental Variable (IV) estimator (two-stage least-squares) optimized. New distributions: Gamma.lvm, coxWeibull.lvm, coxExponential.lvm, coxGompertz.lvm. New method ‘eventTime’ (simulation competing risks data)","code":""}]
